{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport random, os\nfrom PIL import Image\nfrom typing import List, Dict, Any, Tuple\nimport timm\nfrom einops import rearrange\nimport pandas as pd\n\n# ========= CONFIG =========\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 32\nNUM_EPOCHS_PER_TASK = 5\nLEARNING_RATE = 0.001\nLAMBDA_CASSLE = 0.8\nNUM_CLASSES_PER_TASK = 20  # 5 tasks Ã— 20 classes\nNUM_TOTAL_CLASSES = 100\nNUM_ROT_CLASSES = 4\nLINEAR_EVAL_EPOCHS = 10\nLINEAR_EVAL_BATCH_SIZE = 128\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\nset_seed(42)\ntorch.cuda.empty_cache()\n\n# ========= DATA TRANSFORMS =========\ncnn_transform = transforms.Compose([\n    transforms.RandomResizedCrop(32, scale=(0.7, 1.0), ratio=(0.9, 1.1)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\nvit_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# ========= DATASETS =========\nclass RotNetCifar100TaskDataset(Dataset):\n    def __init__(self, cifar100_dataset, class_list, base_transform):\n        self.data, self.targets = [], []\n        for i in range(len(cifar100_dataset)):\n            img, label = cifar100_dataset[i]\n            if label in class_list:\n                if isinstance(img, np.ndarray):\n                    img = Image.fromarray(img)\n                self.data.append(img)\n                self.targets.append(label)\n        self.base_transform = base_transform\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        rotated_imgs, rotation_labels = [], []\n        for angle, rot_label in zip([0, 90, 180, 270], range(4)):\n            rotated_img = transforms.functional.rotate(img, angle)\n            rotated_img = self.base_transform(rotated_img)\n            rotated_imgs.append(rotated_img)\n            rotation_labels.append(torch.tensor(rot_label, dtype=torch.long))\n        return torch.stack(rotated_imgs), torch.stack(rotation_labels), self.targets[idx]\n\nclass MAECifar100TaskDataset(Dataset):\n    def __init__(self, cifar100_dataset, class_list, base_transform, mask_ratio=0.75):\n        self.data, self.targets = [], []\n        self.base_transform = base_transform\n        self.mask_ratio = mask_ratio\n        for i in range(len(cifar100_dataset)):\n            img, label = cifar100_dataset[i]\n            if label in class_list:\n                if isinstance(img, np.ndarray):\n                    img = Image.fromarray(img)\n                self.data.append(img)\n                self.targets.append(label)\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx):\n        img = self.base_transform(self.data[idx])\n        B, H, W = img.shape\n        patch_size = 16  # ViT-B/16\n        num_patches = (H // patch_size) * (W // patch_size)\n        mask = torch.randperm(num_patches) < int(self.mask_ratio * num_patches)\n        return img, mask, self.targets[idx]\n\nclass PairCifar100TaskDataset(Dataset):\n    def __init__(self, cifar100_dataset, class_list, base_transform, pair_transform=None):\n        self.data, self.targets = [], []\n        self.base_transform = base_transform\n        self.pair_transform = pair_transform if pair_transform else base_transform\n        for i in range(len(cifar100_dataset)):\n            img, label = cifar100_dataset[i]\n            if label in class_list:\n                if isinstance(img, np.ndarray):\n                    img = Image.fromarray(img)\n                self.data.append(img)\n                self.targets.append(label)\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        return self.base_transform(img), self.pair_transform(img), self.targets[idx]\n\nclass DenoisingCifar100TaskDataset(Dataset):\n    def __init__(self, cifar100_dataset, class_list, base_transform, noise_std=0.2):\n        self.data, self.targets = [], []\n        self.base_transform = base_transform\n        self.noise_std = noise_std\n        for i in range(len(cifar100_dataset)):\n            img, label = cifar100_dataset[i]\n            if label in class_list:\n                if isinstance(img, np.ndarray):\n                    img = Image.fromarray(img)\n                self.data.append(img)\n                self.targets.append(label)\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx):\n        img = self.base_transform(self.data[idx])\n        noisy_img = img + torch.randn_like(img) * self.noise_std\n        noisy_img = torch.clamp(noisy_img, 0., 1.)\n        return noisy_img, img, self.targets[idx]\n\n# ========= BACKBONES =========\nclass CustomCNNBackbone(nn.Module):\n    def __init__(self, input_channels=3, base_channels=64, dropout_p=0.1):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(input_channels, base_channels, 3, 1, 1),\n            nn.BatchNorm2d(base_channels), nn.ReLU(),\n            nn.Conv2d(base_channels, base_channels*2, 3, 1, 1),\n            nn.BatchNorm2d(base_channels*2), nn.ReLU(),\n            nn.MaxPool2d(2), nn.Dropout(p=dropout_p),\n            nn.Conv2d(base_channels*2, base_channels*4, 3, 1, 1),\n            nn.BatchNorm2d(base_channels*4), nn.ReLU(),\n            nn.Conv2d(base_channels*4, base_channels*4, 3, 1, 1),\n            nn.BatchNorm2d(base_channels*4), nn.ReLU(),\n            nn.MaxPool2d(2), nn.Dropout(p=dropout_p),\n            nn.AdaptiveAvgPool2d(1), nn.Flatten()\n        )\n        dummy_input = torch.randn(1, input_channels, 32, 32)\n        with torch.no_grad():\n            features_dim = self.features(dummy_input).shape[1]\n        self.features_dim = features_dim\n    def forward(self, x): return self.features(x)\n\ndef get_backbone(method):\n    if method in [\"dino\", \"mae\"]:\n        vit = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=0)\n        vit.features_dim = vit.embed_dim\n        return vit\n    else:\n        return CustomCNNBackbone()\n\n# ========= SSL MODELS =========\nclass RotNetModel(nn.Module):\n    def __init__(self, backbone, num_rot_classes=4):\n        super().__init__()\n        self.backbone = backbone\n        self.features_dim = backbone.features_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(self.features_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_rot_classes)\n        )\n    def forward(self, x):\n        features = self.backbone(x)\n        logits = self.classifier(features)\n        return {'logits': logits, 'features': features}\n    def calculate_ssl_loss(self, logits, rot_labels):\n        return F.cross_entropy(logits, rot_labels.long())\n\nclass SimSiamModel(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        self.features_dim = backbone.features_dim\n        self.projector = nn.Sequential(\n            nn.Linear(self.features_dim, 2048),\n            nn.BatchNorm1d(2048),\n            nn.ReLU(),\n            nn.Linear(2048, 2048),\n            nn.BatchNorm1d(2048),\n            nn.ReLU(),\n            nn.Linear(2048, 2048),\n            nn.BatchNorm1d(2048)\n        )\n        self.predictor = nn.Sequential(\n            nn.Linear(2048, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Linear(512, 2048)\n        )\n    def forward(self, x):\n        features = self.backbone(x)\n        z = self.projector(features)\n        p = self.predictor(z)\n        return {'features': features, 'projected': z, 'predicted': p}\n    def calculate_ssl_loss(self, p1, z2, p2, z1):\n        return -(F.cosine_similarity(p1, z2.detach(), dim=-1).mean() +\n                 F.cosine_similarity(p2, z1.detach(), dim=-1).mean()) * 0.5\n\nclass DinoHead(nn.Module):\n    def __init__(self, in_dim, out_dim=2048, nlayers=3, hidden_dim=2048, bottleneck_dim=256):\n        super().__init__()\n        nlayers = max(nlayers, 1)\n        if nlayers == 1:\n            self.mlp = nn.Linear(in_dim, bottleneck_dim)\n        else:\n            layers = [nn.Linear(in_dim, hidden_dim), nn.GELU()]\n            for _ in range(nlayers - 2):\n                layers += [nn.Linear(hidden_dim, hidden_dim), nn.GELU()]\n            layers += [nn.Linear(hidden_dim, bottleneck_dim)]\n            self.mlp = nn.Sequential(*layers)\n        self.last_layer = nn.utils.weight_norm(nn.Linear(bottleneck_dim, out_dim, bias=False))\n    def forward(self, x):\n        x = self.mlp(x)\n        x = F.normalize(x, dim=-1, p=2)\n        return self.last_layer(x), x\n\nclass DINOModel(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        embed_dim = backbone.features_dim\n        self.head = DinoHead(embed_dim)\n        self.teacher = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=0)\n        self.teacher.eval()\n        for p in self.teacher.parameters(): p.requires_grad = False\n    def forward(self, x1, x2):\n        y1 = self.backbone(x1)\n        y2 = self.backbone(x2)\n        out1, _ = self.head(y1)\n        out2, _ = self.head(y2)\n        with torch.no_grad():\n            t1 = self.teacher(x1)\n            t2 = self.teacher(x2)\n            t1_out, _ = self.head(t1)\n            t2_out, _ = self.head(t2)\n        return {\"student\": (out1, out2), \"teacher\": (t1_out, t2_out)}\n    def calculate_ssl_loss(self, student_out, teacher_out):\n        loss = 0.\n        for s, t in zip(student_out, teacher_out):\n            t = t.detach()\n            loss += - (F.softmax(t, dim=-1) * F.log_softmax(s, dim=-1)).sum(dim=-1).mean()\n        return loss / len(student_out)\n\nclass PatchMAEEncoder(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        self.features_dim = backbone.features_dim\n    def forward(self, x, mask):\n        features = self.backbone.patch_embed(x)\n        features[0][mask] = 0\n        pooled = features.mean(dim=1)\n        return pooled\n\nclass MAEDecoder(nn.Module):\n    def __init__(self, embed_dim=768, patch_dim=768):\n        super().__init__()\n        self.decoder = nn.Sequential(\n            nn.Linear(embed_dim, embed_dim), nn.GELU(), nn.Linear(embed_dim, patch_dim)\n        )\n    def forward(self, x): return self.decoder(x)\n\nclass MAEModel(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.encoder = PatchMAEEncoder(backbone)\n        self.decoder = MAEDecoder(embed_dim=backbone.features_dim, patch_dim=backbone.features_dim)\n        self.features_dim = backbone.features_dim\n    def forward(self, x, mask):\n        encoded = self.encoder(x, mask)\n        recon_patches = self.decoder(encoded)\n        return {\"recon_patches\": recon_patches}\n    def calculate_ssl_loss(self, x, recon_patches, mask):\n        return F.mse_loss(recon_patches, x.view(x.size(0), -1))\n\nclass SdAEModel(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        self.features_dim = backbone.features_dim\n        self.decoder = nn.Linear(self.features_dim, 3 * 32 * 32)\n    def forward(self, x):\n        features = self.backbone(x)\n        recon = self.decoder(features)\n        return {\"features\": features, \"recon\": recon}\n    def calculate_ssl_loss(self, x, recon):\n        return F.mse_loss(recon, x.view(x.size(0), -1))\n\n# ========= SSL MODEL WRAPPER =========\nclass SSLModelWrapper(nn.Module):\n    def __init__(self, method=\"RotNet\", backbone=None, **kwargs):\n        super().__init__()\n        self.method = method.lower()\n        if backbone is None:\n            raise ValueError(\"You must provide a backbone!\")\n        if self.method == \"rotnet\":\n            self.model = RotNetModel(backbone=backbone, num_rot_classes=kwargs.get('num_rot_classes', 4))\n        elif self.method == \"simsiam\":\n            self.model = SimSiamModel(backbone=backbone)\n        elif self.method == \"dino\":\n            self.model = DINOModel(backbone=backbone)\n        elif self.method == \"mae\":\n            self.model = MAEModel(backbone=backbone)\n        elif self.method == \"sdae\":\n            self.model = SdAEModel(backbone=backbone)\n        else:\n            raise NotImplementedError(f\"SSL method '{method}' not implemented.\")\n        self.ssl_loss_fn = self.model.calculate_ssl_loss\n    def forward(self, *args, **kwargs): return self.model(*args, **kwargs)\n    def get_representation(self, x): return self.model.backbone(x)\n    def calculate_ssl_loss(self, *args, **kwargs): return self.ssl_loss_fn(*args, **kwargs)\n    @property\n    def backbone(self): return self.model.backbone\n    @property\n    def features_dim(self): return self.model.features_dim\n\n# ========= CaSSLe Predictor/Trainer =========\nclass CaSSLePredictor(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, output_dim)\n        )\n    def forward(self, x): return self.net(x)\n\nclass CaSSleTrainer:\n    def __init__(self, base_ssl_model, ca_predictor_hidden_dim, learning_rate, lambda_cassle, device='cuda'):\n        self.base_ssl_model = base_ssl_model.to(device)\n        self.lambda_cassle = lambda_cassle\n        self.device = device\n        self.ca_predictor_hidden_dim = ca_predictor_hidden_dim\n        self.learning_rate = learning_rate\n        self.f_frozen_teacher = None\n        self.g_current = None\n        self.optimizer = None\n    def set_previous_frozen_encoder(self, encoder_state):\n        backbone_class, state_dict = encoder_state\n        self.f_frozen_teacher = backbone_class()\n        self.f_frozen_teacher.load_state_dict(state_dict)\n        self.f_frozen_teacher.to(self.device)\n        for param in self.f_frozen_teacher.parameters(): param.requires_grad = False\n    def train_task(self, data_loader, epochs, ssl_method):\n        first_batch = next(iter(data_loader))\n        with torch.no_grad():\n            if ssl_method == \"rotnet\":\n                rotated_imgs, rotation_labels, _ = first_batch\n                imgs_flat = rotated_imgs.view(-1, *rotated_imgs.shape[2:]).to(self.device)\n                ssl_output = self.base_ssl_model(imgs_flat)\n                features_for_distill = ssl_output['features']\n            elif ssl_method == \"simsiam\":\n                img1, img2, _ = first_batch\n                img1 = img1.to(self.device)\n                out1 = self.base_ssl_model(img1)\n                features_for_distill = out1['features']\n            elif ssl_method == \"dino\":\n                img1, img2, _ = first_batch\n                img1 = img1.to(self.device)\n                dino_out = self.base_ssl_model(img1, img1)\n                features_for_distill = dino_out[\"student\"][0]\n            elif ssl_method == \"mae\":\n                imgs, masks, _ = first_batch\n                imgs = imgs.to(self.device)\n                mae_out = self.base_ssl_model(imgs, masks)\n                features_for_distill = mae_out['recon_patches'].view(imgs.size(0), -1)\n            elif ssl_method == \"sdae\":\n                noisy_imgs, clean_imgs, _ = first_batch\n                noisy_imgs = noisy_imgs.to(self.device)\n                sdae_out = self.base_ssl_model(noisy_imgs)\n                features_for_distill = sdae_out['features']\n            else: raise NotImplementedError\n            feature_dim = features_for_distill.shape[1]\n        self.g_current = CaSSLePredictor(feature_dim, self.ca_predictor_hidden_dim, feature_dim).to(self.device)\n        self.optimizer = torch.optim.AdamW(\n            list(self.base_ssl_model.parameters()) + list(self.g_current.parameters()),\n            lr=self.learning_rate, weight_decay=0.01\n        )\n        self.base_ssl_model.train(); self.g_current.train()\n        if self.f_frozen_teacher: self.f_frozen_teacher.eval()\n        best_loss, patience, patience_counter, min_delta = float('inf'), 10, 0, 0.001\n        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.1)\n        for epoch in range(epochs):\n            total_ssl_loss, total_cassle_loss, total_loss = 0, 0, 0\n            for batch in data_loader:\n                self.optimizer.zero_grad()\n                if ssl_method == \"rotnet\":\n                    rotated_imgs, rotation_labels, _ = batch\n                    imgs_flat = rotated_imgs.view(-1, *rotated_imgs.shape[2:]).to(self.device)\n                    labels_flat = rotation_labels.view(-1).to(self.device)\n                    ssl_output = self.base_ssl_model(imgs_flat)\n                    loss_ssl = self.base_ssl_model.calculate_ssl_loss(ssl_output['logits'], labels_flat)\n                    features_for_distill = ssl_output['features']\n                elif ssl_method == \"simsiam\":\n                    img1, img2, _ = batch\n                    img1, img2 = img1.to(self.device), img2.to(self.device)\n                    out1 = self.base_ssl_model(img1)\n                    out2 = self.base_ssl_model(img2)\n                    loss_ssl = self.base_ssl_model.calculate_ssl_loss(\n                        out1['predicted'], out2['projected'],\n                        out2['predicted'], out1['projected']\n                    )\n                    features_for_distill = out1['features']\n                elif ssl_method == \"dino\":\n                    img1, img2, _ = batch\n                    img1, img2 = img1.to(self.device), img2.to(self.device)\n                    dino_out = self.base_ssl_model(img1, img2)\n                    loss_ssl = self.base_ssl_model.calculate_ssl_loss(\n                        dino_out[\"student\"], dino_out[\"teacher\"]\n                    )\n                    features_for_distill = dino_out[\"student\"][0]\n                elif ssl_method == \"mae\":\n                    imgs, masks, _ = batch\n                    imgs, masks = imgs.to(self.device), masks.to(self.device)\n                    mae_out = self.base_ssl_model(imgs, masks)\n                    loss_ssl = self.base_ssl_model.calculate_ssl_loss(imgs, mae_out['recon_patches'], masks)\n                    features_for_distill = mae_out['recon_patches'].view(imgs.size(0), -1)\n                elif ssl_method == \"sdae\":\n                    noisy_imgs, clean_imgs, _ = batch\n                    noisy_imgs = noisy_imgs.to(self.device)\n                    clean_imgs = clean_imgs.to(self.device)\n                    sdae_out = self.base_ssl_model(noisy_imgs)\n                    loss_ssl = self.base_ssl_model.calculate_ssl_loss(clean_imgs, sdae_out['recon'])\n                    features_for_distill = sdae_out['features']\n                else: raise NotImplementedError\n                loss_cassle = torch.tensor(0.0).to(self.device)\n                if self.f_frozen_teacher:\n                    with torch.no_grad():\n                        if ssl_method == \"rotnet\": teacher_input = imgs_flat\n                        elif ssl_method in [\"simsiam\", \"dino\"]: teacher_input = img1\n                        elif ssl_method == \"mae\": teacher_input = imgs\n                        elif ssl_method == \"sdae\": teacher_input = noisy_imgs\n                        else: raise NotImplementedError\n                        frozen_features = self.f_frozen_teacher(teacher_input)\n                        frozen_features = frozen_features.view(teacher_input.size(0), -1)\n                    student_features = features_for_distill\n                    student_pred = self.g_current(student_features)\n                    loss_cassle = 1 - F.cosine_similarity(student_pred, frozen_features, dim=-1).mean()\n                loss = loss_ssl + self.lambda_cassle * loss_cassle\n                loss.backward()\n                self.optimizer.step()\n                total_ssl_loss += loss_ssl.item()\n                total_cassle_loss += loss_cassle.item()\n                total_loss += loss.item()\n            avg_loss = total_loss / len(data_loader)\n            self.scheduler.step()\n            if avg_loss < best_loss - min_delta: best_loss, patience_counter = avg_loss, 0\n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    print(\"Early stopping triggered.\"); break\n            print(f\"Epoch {epoch+1}/{epochs} - SSL Loss: {total_ssl_loss / len(data_loader):.4f}, \"\n                  f\"CaSSle Loss: {total_cassle_loss / len(data_loader):.4f}, \"\n                  f\"Total Loss: {total_loss / len(data_loader):.4f}\")\n        return (type(self.base_ssl_model.backbone), self.base_ssl_model.backbone.state_dict())\n\n# ========= Utility: Linear Eval, Random Accuracy =========\ndef evaluate_model(feature_extractor, all_seen_classes, cifar100_train_full, cifar100_test_full, base_transform, batch_size=128, linear_eval_epochs=10, device=DEVICE):\n    feature_extractor.eval()\n    for param in feature_extractor.parameters(): param.requires_grad = False\n    class LinearEvalDataset(Dataset):\n        def __init__(self, original_dataset, class_list, transform):\n            self.data, self.targets = [], []\n            self.transform = transform\n            for i in range(len(original_dataset)):\n                img, label = original_dataset[i]\n                if label in class_list:\n                    if isinstance(img, np.ndarray):\n                        img = Image.fromarray(img)\n                    self.data.append(img)\n                    self.targets.append(label)\n        def __len__(self): return len(self.data)\n        def __getitem__(self, idx):\n            img = self.data[idx]\n            label = self.targets[idx]\n            img = self.transform(img)\n            return img, label\n    train_linear_dataset = LinearEvalDataset(cifar100_train_full, all_seen_classes, base_transform)\n    train_linear_loader = DataLoader(train_linear_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n    dummy_input = torch.randn(1, 3, train_linear_loader.dataset[0][0].shape[1], train_linear_loader.dataset[0][0].shape[2]).to(device)\n    with torch.no_grad():\n        features_dim = feature_extractor(dummy_input).view(dummy_input.size(0), -1).shape[1]\n    num_output_classes = len(all_seen_classes)\n    linear_classifier = nn.Linear(features_dim, num_output_classes).to(device)\n    label_to_contiguous_map = {label: i for i, label in enumerate(sorted(all_seen_classes))}\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(linear_classifier.parameters(), lr=0.001)\n    linear_classifier.train()\n    for epoch in range(linear_eval_epochs):\n        for img_batch, label_batch in train_linear_loader:\n            img_batch = img_batch.to(device)\n            label_batch = torch.tensor([label_to_contiguous_map[l.item()] for l in label_batch]).to(device)\n            optimizer.zero_grad()\n            with torch.no_grad():\n                features = feature_extractor(img_batch).view(img_batch.size(0), -1)\n            outputs = linear_classifier(features)\n            loss = criterion(outputs, label_batch)\n            loss.backward()\n            optimizer.step()\n    linear_classifier.eval()\n    total_correct, total_samples = 0, 0\n    test_linear_dataset = LinearEvalDataset(cifar100_test_full, all_seen_classes, base_transform)\n    test_linear_loader = DataLoader(test_linear_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n    with torch.no_grad():\n        for img_batch, label_batch in test_linear_loader:\n            img_batch = img_batch.to(device)\n            label_batch = torch.tensor([label_to_contiguous_map[l.item()] for l in label_batch]).to(device)\n            features = feature_extractor(img_batch).view(img_batch.size(0), -1)\n            outputs = linear_classifier(features)\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += label_batch.size(0)\n            total_correct += (predicted == label_batch).sum().item()\n    accuracy = 100 * total_correct / total_samples\n    for param in feature_extractor.parameters(): param.requires_grad = True\n    feature_extractor.train()\n    return accuracy\n\ndef get_random_accuracy(num_classes_in_task, cifar100_train_full, cifar100_test_full, base_transform, target_class_list, batch_size=128, linear_eval_epochs=10, device=DEVICE):\n    random_backbone = CustomCNNBackbone()\n    random_backbone.to(device)\n    return evaluate_model(random_backbone, target_class_list, cifar100_train_full, cifar100_test_full, base_transform, batch_size, linear_eval_epochs, device)\n\n# ========== DATA LOADING ==========\ncifar100_train_full = datasets.CIFAR100(root='./data', train=True, download=True)\ncifar100_test_full = datasets.CIFAR100(root='./data', train=False, download=True)\nall_classes_shuffled = list(range(NUM_TOTAL_CLASSES))\nrandom.shuffle(all_classes_shuffled)\ntask_class_splits = [all_classes_shuffled[i:i + NUM_CLASSES_PER_TASK] for i in range(0, NUM_TOTAL_CLASSES, NUM_CLASSES_PER_TASK)]\n\ndef prepare_task_datasets(model_type):\n    if model_type in [\"dino\", \"mae\"]:\n        transform = vit_transform\n    else:\n        transform = cnn_transform\n    tasks = []\n    for class_list in task_class_splits:\n        if model_type == \"rotnet\":\n            tasks.append(RotNetCifar100TaskDataset(cifar100_train_full, class_list, transform))\n        elif model_type == \"simsiam\" or model_type == \"dino\":\n            tasks.append(PairCifar100TaskDataset(cifar100_train_full, class_list, transform))\n        elif model_type == \"mae\":\n            tasks.append(MAECifar100TaskDataset(cifar100_train_full, class_list, transform))\n        elif model_type == \"sdae\":\n            tasks.append(DenoisingCifar100TaskDataset(cifar100_train_full, class_list, transform))\n        else:\n            raise NotImplementedError\n    return tasks\n\n# ========== MAIN TRAIN LOOP ==========\nssl_methods = [\"rotnet\", \"simsiam\", \"sdae\"]\nresults = {}\nfor ssl_method in ssl_methods:\n    print(\"\\n\" + \"=\"*60)\n    print(f\"Starting continual learning for SSL method: {ssl_method.upper()}\")\n    print(\"=\"*60)\n    backbone = get_backbone(ssl_method).to(DEVICE)\n    base_ssl_model_instance = SSLModelWrapper(method=ssl_method, backbone=backbone, num_rot_classes=NUM_ROT_CLASSES)\n    prev_encoder_state = None\n    all_task_accuracies = []\n    random_accuracies_Ri = {}\n    task_datasets = prepare_task_datasets(ssl_method)\n    for task_id, current_task_dataset in enumerate(task_datasets):\n        print(f\"\\n===== Training Task {task_id + 1}/{len(task_datasets)} =====\")\n        current_task_loader = DataLoader(current_task_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n        trainer = CaSSleTrainer(base_ssl_model=base_ssl_model_instance,\n                                ca_predictor_hidden_dim=256,\n                                learning_rate=LEARNING_RATE,\n                                lambda_cassle=LAMBDA_CASSLE,\n                                device=DEVICE)\n        if prev_encoder_state:\n            trainer.set_previous_frozen_encoder(prev_encoder_state)\n        prev_encoder_state = trainer.train_task(current_task_loader, NUM_EPOCHS_PER_TASK, ssl_method)\n        print(f\"\\n--- Evaluating after Task {task_id + 1} ---\")\n        current_seen_classes = sorted(set().union(*task_class_splits[:task_id + 1]))\n        accuracies_after_this_task = []\n        for eval_task_idx in range(task_id + 1):\n            eval_task_classes = task_class_splits[eval_task_idx]\n            acc_jk = evaluate_model(\n                base_ssl_model_instance.backbone,\n                eval_task_classes,\n                cifar100_train_full,\n                cifar100_test_full,\n                vit_transform if ssl_method in [\"dino\", \"mae\"] else cnn_transform,\n                LINEAR_EVAL_BATCH_SIZE,\n                LINEAR_EVAL_EPOCHS,\n                DEVICE\n            )\n            accuracies_after_this_task.append(acc_jk)\n            print(f\"  Eval Task {eval_task_idx+1}: {acc_jk:.2f}%\")\n            if eval_task_idx not in random_accuracies_Ri:\n                random_accuracies_Ri[eval_task_idx] = get_random_accuracy(\n                    NUM_CLASSES_PER_TASK,\n                    cifar100_train_full,\n                    cifar100_test_full,\n                    vit_transform if ssl_method in [\"dino\", \"mae\"] else cnn_transform,\n                    eval_task_classes,\n                    LINEAR_EVAL_BATCH_SIZE,\n                    LINEAR_EVAL_EPOCHS,\n                    DEVICE\n                )\n        all_task_accuracies.append(accuracies_after_this_task)\n    T = len(task_datasets)\n    final_accuracies_row = all_task_accuracies[T-1]\n    avg_accuracy = sum(final_accuracies_row) / T\n    print(f\"\\nFinal Average Accuracy (A) for {ssl_method.upper()}: {avg_accuracy:.2f}%\")\n    forgetting = 0\n    if T > 1:\n        for i in range(T - 1):\n            max_acc = max(all_task_accuracies[t][i] for t in range(T) if i < len(all_task_accuracies[t]))\n            final_acc = all_task_accuracies[T-1][i]\n            forgetting += (max_acc - final_acc)\n        forgetting /= (T - 1)\n    print(f\"Final Forgetting (F) for {ssl_method.upper()}: {forgetting:.2f}%\")\n    backward_transfer = 0\n    count = 0\n    if T > 1:\n        for new_task in range(1, T):\n            for old_task in range(new_task):\n                if old_task < len(all_task_accuracies[new_task - 1]) and old_task < len(all_task_accuracies[new_task]):\n                    acc_before = all_task_accuracies[new_task - 1][old_task]\n                    acc_after = all_task_accuracies[new_task][old_task]\n                    backward_transfer += (acc_after - acc_before)\n                    count += 1\n        backward_transfer /= count if count > 0 else 1\n    else:\n        backward_transfer = 0\n    print(f\"Final Backward Transfer (BT) for {ssl_method.upper()}: {backward_transfer:.2f}%\")\n    results[ssl_method] = {\n        \"average_accuracy\": avg_accuracy,\n        \"forgetting\": forgetting,\n        \"backward_transfer\": backward_transfer\n    }\n\nprint(\"\\n==== ALL SSL MODEL RESULTS ====\")\nfor model, res in results.items():\n    print(f\"{model.upper()}: Accuracy={res['average_accuracy']:.2f}% | Forgetting={res['forgetting']:.2f}% | Backward Transfer={res['backward_transfer']:.2f}%\")\npd.DataFrame(results).T.to_csv(\"all_ssl_results.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T14:06:09.061858Z","iopub.execute_input":"2025-07-31T14:06:09.062109Z","iopub.status.idle":"2025-07-31T15:11:03.528072Z","shell.execute_reply.started":"2025-07-31T14:06:09.062070Z","shell.execute_reply":"2025-07-31T15:11:03.527318Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169M/169M [00:02<00:00, 78.1MB/s] \n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nStarting continual learning for SSL method: ROTNET\n============================================================\n\n===== Training Task 1/5 =====\nEpoch 1/5 - SSL Loss: 1.2226, CaSSle Loss: 0.0000, Total Loss: 1.2226\nEpoch 2/5 - SSL Loss: 1.1364, CaSSle Loss: 0.0000, Total Loss: 1.1364\nEpoch 3/5 - SSL Loss: 1.0862, CaSSle Loss: 0.0000, Total Loss: 1.0862\nEpoch 4/5 - SSL Loss: 1.0456, CaSSle Loss: 0.0000, Total Loss: 1.0456\nEpoch 5/5 - SSL Loss: 1.0084, CaSSle Loss: 0.0000, Total Loss: 1.0084\n\n--- Evaluating after Task 1 ---\n  Eval Task 1: 36.10%\n\n===== Training Task 2/5 =====\nEpoch 1/5 - SSL Loss: 0.8888, CaSSle Loss: 0.0475, Total Loss: 0.9268\nEpoch 2/5 - SSL Loss: 0.8304, CaSSle Loss: 0.0211, Total Loss: 0.8473\nEpoch 3/5 - SSL Loss: 0.7953, CaSSle Loss: 0.0197, Total Loss: 0.8111\nEpoch 4/5 - SSL Loss: 0.7618, CaSSle Loss: 0.0192, Total Loss: 0.7771\nEpoch 5/5 - SSL Loss: 0.7446, CaSSle Loss: 0.0182, Total Loss: 0.7592\n\n--- Evaluating after Task 2 ---\n  Eval Task 1: 39.50%\n  Eval Task 2: 42.95%\n\n===== Training Task 3/5 =====\nEpoch 1/5 - SSL Loss: 1.0991, CaSSle Loss: 0.0516, Total Loss: 1.1404\nEpoch 2/5 - SSL Loss: 1.0381, CaSSle Loss: 0.0226, Total Loss: 1.0562\nEpoch 3/5 - SSL Loss: 1.0007, CaSSle Loss: 0.0207, Total Loss: 1.0172\nEpoch 4/5 - SSL Loss: 0.9709, CaSSle Loss: 0.0194, Total Loss: 0.9864\nEpoch 5/5 - SSL Loss: 0.9416, CaSSle Loss: 0.0184, Total Loss: 0.9563\n\n--- Evaluating after Task 3 ---\n  Eval Task 1: 42.75%\n  Eval Task 2: 45.05%\n  Eval Task 3: 45.25%\n\n===== Training Task 4/5 =====\nEpoch 1/5 - SSL Loss: 0.9154, CaSSle Loss: 0.0534, Total Loss: 0.9581\nEpoch 2/5 - SSL Loss: 0.8349, CaSSle Loss: 0.0226, Total Loss: 0.8530\nEpoch 3/5 - SSL Loss: 0.7929, CaSSle Loss: 0.0199, Total Loss: 0.8088\nEpoch 4/5 - SSL Loss: 0.7566, CaSSle Loss: 0.0185, Total Loss: 0.7714\nEpoch 5/5 - SSL Loss: 0.7234, CaSSle Loss: 0.0182, Total Loss: 0.7379\n\n--- Evaluating after Task 4 ---\n  Eval Task 1: 43.45%\n  Eval Task 2: 45.25%\n  Eval Task 3: 46.30%\n  Eval Task 4: 49.40%\n\n===== Training Task 5/5 =====\nEpoch 1/5 - SSL Loss: 0.9113, CaSSle Loss: 0.0465, Total Loss: 0.9485\nEpoch 2/5 - SSL Loss: 0.8170, CaSSle Loss: 0.0201, Total Loss: 0.8331\nEpoch 3/5 - SSL Loss: 0.7652, CaSSle Loss: 0.0183, Total Loss: 0.7799\nEpoch 4/5 - SSL Loss: 0.7315, CaSSle Loss: 0.0178, Total Loss: 0.7457\nEpoch 5/5 - SSL Loss: 0.6935, CaSSle Loss: 0.0170, Total Loss: 0.7071\n\n--- Evaluating after Task 5 ---\n  Eval Task 1: 45.20%\n  Eval Task 2: 47.90%\n  Eval Task 3: 48.15%\n  Eval Task 4: 51.80%\n  Eval Task 5: 47.85%\n\nFinal Average Accuracy (A) for ROTNET: 48.18%\nFinal Forgetting (F) for ROTNET: 0.00%\nFinal Backward Transfer (BT) for ROTNET: 1.93%\n\n============================================================\nStarting continual learning for SSL method: SIMSIAM\n============================================================\n\n===== Training Task 1/5 =====\nEpoch 1/5 - SSL Loss: -0.9373, CaSSle Loss: 0.0000, Total Loss: -0.9373\nEpoch 2/5 - SSL Loss: -0.9710, CaSSle Loss: 0.0000, Total Loss: -0.9710\nEpoch 3/5 - SSL Loss: -0.9774, CaSSle Loss: 0.0000, Total Loss: -0.9774\nEpoch 4/5 - SSL Loss: -0.9754, CaSSle Loss: 0.0000, Total Loss: -0.9754\nEpoch 5/5 - SSL Loss: -0.9747, CaSSle Loss: 0.0000, Total Loss: -0.9747\n\n--- Evaluating after Task 1 ---\n  Eval Task 1: 21.55%\n\n===== Training Task 2/5 =====\nEpoch 1/5 - SSL Loss: -0.9756, CaSSle Loss: 0.0429, Total Loss: -0.9413\nEpoch 2/5 - SSL Loss: -0.9799, CaSSle Loss: 0.0217, Total Loss: -0.9626\nEpoch 3/5 - SSL Loss: -0.9813, CaSSle Loss: 0.0193, Total Loss: -0.9658\nEpoch 4/5 - SSL Loss: -0.9814, CaSSle Loss: 0.0188, Total Loss: -0.9664\nEpoch 5/5 - SSL Loss: -0.9827, CaSSle Loss: 0.0191, Total Loss: -0.9674\n\n--- Evaluating after Task 2 ---\n  Eval Task 1: 24.75%\n  Eval Task 2: 27.80%\n\n===== Training Task 3/5 =====\nEpoch 1/5 - SSL Loss: -0.9843, CaSSle Loss: 0.0509, Total Loss: -0.9436\nEpoch 2/5 - SSL Loss: -0.9848, CaSSle Loss: 0.0252, Total Loss: -0.9646\nEpoch 3/5 - SSL Loss: -0.9871, CaSSle Loss: 0.0216, Total Loss: -0.9698\nEpoch 4/5 - SSL Loss: -0.9870, CaSSle Loss: 0.0213, Total Loss: -0.9700\nEpoch 5/5 - SSL Loss: -0.9859, CaSSle Loss: 0.0214, Total Loss: -0.9688\n\n--- Evaluating after Task 3 ---\n  Eval Task 1: 26.80%\n  Eval Task 2: 29.10%\n  Eval Task 3: 25.35%\n\n===== Training Task 4/5 =====\nEpoch 1/5 - SSL Loss: -0.9831, CaSSle Loss: 0.0614, Total Loss: -0.9340\nEpoch 2/5 - SSL Loss: -0.9855, CaSSle Loss: 0.0274, Total Loss: -0.9635\nEpoch 3/5 - SSL Loss: -0.9874, CaSSle Loss: 0.0250, Total Loss: -0.9674\nEpoch 4/5 - SSL Loss: -0.9880, CaSSle Loss: 0.0255, Total Loss: -0.9677\nEpoch 5/5 - SSL Loss: -0.9878, CaSSle Loss: 0.0237, Total Loss: -0.9688\n\n--- Evaluating after Task 4 ---\n  Eval Task 1: 28.20%\n  Eval Task 2: 31.90%\n  Eval Task 3: 27.95%\n  Eval Task 4: 35.70%\n\n===== Training Task 5/5 =====\nEpoch 1/5 - SSL Loss: -0.9846, CaSSle Loss: 0.0620, Total Loss: -0.9350\nEpoch 2/5 - SSL Loss: -0.9825, CaSSle Loss: 0.0282, Total Loss: -0.9599\nEpoch 3/5 - SSL Loss: -0.9842, CaSSle Loss: 0.0241, Total Loss: -0.9649\nEpoch 4/5 - SSL Loss: -0.9837, CaSSle Loss: 0.0240, Total Loss: -0.9645\nEpoch 5/5 - SSL Loss: -0.9836, CaSSle Loss: 0.0232, Total Loss: -0.9650\n\n--- Evaluating after Task 5 ---\n  Eval Task 1: 29.75%\n  Eval Task 2: 31.55%\n  Eval Task 3: 29.25%\n  Eval Task 4: 36.20%\n  Eval Task 5: 30.00%\n\nFinal Average Accuracy (A) for SIMSIAM: 31.35%\nFinal Forgetting (F) for SIMSIAM: 0.09%\nFinal Backward Transfer (BT) for SIMSIAM: 1.63%\n\n============================================================\nStarting continual learning for SSL method: SDAE\n============================================================\n\n===== Training Task 1/5 =====\nEpoch 1/5 - SSL Loss: 0.1599, CaSSle Loss: 0.0000, Total Loss: 0.1599\nEpoch 2/5 - SSL Loss: 0.1172, CaSSle Loss: 0.0000, Total Loss: 0.1172\nEpoch 3/5 - SSL Loss: 0.1053, CaSSle Loss: 0.0000, Total Loss: 0.1053\nEpoch 4/5 - SSL Loss: 0.0967, CaSSle Loss: 0.0000, Total Loss: 0.0967\nEpoch 5/5 - SSL Loss: 0.0904, CaSSle Loss: 0.0000, Total Loss: 0.0904\n\n--- Evaluating after Task 1 ---\n  Eval Task 1: 33.35%\n\n===== Training Task 2/5 =====\nEpoch 1/5 - SSL Loss: 0.0766, CaSSle Loss: 0.0365, Total Loss: 0.1058\nEpoch 2/5 - SSL Loss: 0.0721, CaSSle Loss: 0.0102, Total Loss: 0.0802\nEpoch 3/5 - SSL Loss: 0.0690, CaSSle Loss: 0.0079, Total Loss: 0.0753\nEpoch 4/5 - SSL Loss: 0.0667, CaSSle Loss: 0.0072, Total Loss: 0.0725\nEpoch 5/5 - SSL Loss: 0.0650, CaSSle Loss: 0.0063, Total Loss: 0.0700\n\n--- Evaluating after Task 2 ---\n  Eval Task 1: 33.80%\n  Eval Task 2: 35.00%\n\n===== Training Task 3/5 =====\nEpoch 1/5 - SSL Loss: 0.0707, CaSSle Loss: 0.0470, Total Loss: 0.1083\nEpoch 2/5 - SSL Loss: 0.0673, CaSSle Loss: 0.0142, Total Loss: 0.0786\nEpoch 3/5 - SSL Loss: 0.0655, CaSSle Loss: 0.0113, Total Loss: 0.0745\nEpoch 4/5 - SSL Loss: 0.0642, CaSSle Loss: 0.0098, Total Loss: 0.0721\nEpoch 5/5 - SSL Loss: 0.0628, CaSSle Loss: 0.0088, Total Loss: 0.0699\n\n--- Evaluating after Task 3 ---\n  Eval Task 1: 35.35%\n  Eval Task 2: 36.05%\n  Eval Task 3: 34.95%\n\n===== Training Task 4/5 =====\nEpoch 1/5 - SSL Loss: 0.0646, CaSSle Loss: 0.0509, Total Loss: 0.1053\nEpoch 2/5 - SSL Loss: 0.0617, CaSSle Loss: 0.0157, Total Loss: 0.0742\nEpoch 3/5 - SSL Loss: 0.0605, CaSSle Loss: 0.0123, Total Loss: 0.0703\nEpoch 4/5 - SSL Loss: 0.0592, CaSSle Loss: 0.0105, Total Loss: 0.0676\nEpoch 5/5 - SSL Loss: 0.0583, CaSSle Loss: 0.0098, Total Loss: 0.0661\n\n--- Evaluating after Task 4 ---\n  Eval Task 1: 34.75%\n  Eval Task 2: 37.20%\n  Eval Task 3: 34.60%\n  Eval Task 4: 41.15%\n\n===== Training Task 5/5 =====\nEpoch 1/5 - SSL Loss: 0.0638, CaSSle Loss: 0.0583, Total Loss: 0.1104\nEpoch 2/5 - SSL Loss: 0.0613, CaSSle Loss: 0.0176, Total Loss: 0.0754\nEpoch 3/5 - SSL Loss: 0.0602, CaSSle Loss: 0.0131, Total Loss: 0.0707\nEpoch 4/5 - SSL Loss: 0.0590, CaSSle Loss: 0.0113, Total Loss: 0.0680\nEpoch 5/5 - SSL Loss: 0.0582, CaSSle Loss: 0.0103, Total Loss: 0.0664\n\n--- Evaluating after Task 5 ---\n  Eval Task 1: 35.20%\n  Eval Task 2: 35.90%\n  Eval Task 3: 34.60%\n  Eval Task 4: 40.35%\n  Eval Task 5: 35.00%\n\nFinal Average Accuracy (A) for SDAE: 36.21%\nFinal Forgetting (F) for SDAE: 0.65%\nFinal Backward Transfer (BT) for SDAE: 0.16%\n\n==== ALL SSL MODEL RESULTS ====\nROTNET: Accuracy=48.18% | Forgetting=0.00% | Backward Transfer=1.93%\nSIMSIAM: Accuracy=31.35% | Forgetting=0.09% | Backward Transfer=1.63%\nSDAE: Accuracy=36.21% | Forgetting=0.65% | Backward Transfer=0.16%\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}