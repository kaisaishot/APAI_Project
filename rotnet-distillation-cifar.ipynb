{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T02:03:17.736908Z",
     "iopub.status.busy": "2025-07-21T02:03:17.736610Z",
     "iopub.status.idle": "2025-07-21T02:03:17.762574Z",
     "shell.execute_reply": "2025-07-21T02:03:17.761957Z",
     "shell.execute_reply.started": "2025-07-21T02:03:17.736884Z"
    },
    "id": "K-SwNkXaMGPF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = 32  # CIFAR-100 image size\n",
    "BATCH_SIZE = 32  # 4 rotations × 32 = 128 processed images\n",
    "NUM_EPOCHS_PER_TASK = 200\n",
    "LEARNING_RATE = 0.001\n",
    "LAMBDA_CASSLE = 0.8 # Weight for CaSSle loss\n",
    "NUM_CLASSES_PER_TASK = 10\n",
    "NUM_TOTAL_CLASSES = 100  # Total CIFAR-100 classes\n",
    "NUM_ROT_CLASSES = 4  # 0°, 90°, 180°, 270°\n",
    "LINEAR_EVAL_EPOCHS = 10\n",
    "LINEAR_EVAL_BATCH_SIZE = 128\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#Custom Dataset for RotNet\n",
    "class RotNetCifar100TaskDataset(Dataset):\n",
    "    def __init__(self, cifar100_dataset, class_list: List[int], base_transform):\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        # Filter CIFAR-100 data based on the provided class_list\n",
    "        for i in range(len(cifar100_dataset)):\n",
    "            img, label = cifar100_dataset[i]\n",
    "            if label in class_list:\n",
    "                if isinstance(img, np.ndarray):\n",
    "                    img = Image.fromarray(img)\n",
    "                self.data.append(img)\n",
    "                self.targets.append(label)\n",
    "\n",
    "        self.base_transform = base_transform # Applied before rotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        original_label = self.targets[idx] # Original label, not used for SSL\n",
    "\n",
    "        # 4 rotated versions and their labels (0, 1, 2, 3)\n",
    "        # We need to perform rotation on the Tensor after base_transform\n",
    "        rotated_imgs = []\n",
    "        rotation_labels = []\n",
    "\n",
    "\n",
    "        #Rotations\n",
    "        for angle, rot_label in zip([0, 90, 180, 270], range(4)):\n",
    "          rotated_img = transforms.functional.rotate(img, angle)\n",
    "          rotated_img = self.base_transform(rotated_img)\n",
    "          rotated_imgs.append(rotated_img)\n",
    "          rotation_labels.append(torch.tensor(rot_label, dtype=torch.long))\n",
    "\n",
    "        # Stack all 4 rotated images and labels for batching\n",
    "        return torch.stack(rotated_imgs), torch.stack(rotation_labels), original_label\n",
    "\n",
    "\n",
    "class CustomBackbone(nn.Module):\n",
    "    def __init__(self, input_channels: int = 3, base_channels: int = 64, dropout_p: float = 0.1): # Added dropout_p parameter\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, base_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(base_channels, base_channels * 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            \n",
    "            nn.Conv2d(base_channels * 2, base_channels * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels * 4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(base_channels * 4, base_channels * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels * 4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Dummy pass to infer flattened feature size\n",
    "        dummy_input = torch.randn(1, input_channels, INPUT_SIZE, INPUT_SIZE)\n",
    "        with torch.no_grad():\n",
    "            features_dim = self.features(dummy_input).shape[1]\n",
    "        self.features_dim = features_dim\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.features(x)\n",
    "\n",
    "# --- RotNet Model using Custom Backbone (no changes needed here) ---\n",
    "class RotNetModel(nn.Module):\n",
    "    def __init__(self, num_rot_classes: int = 4, dropout_p: float = 0.1, input_channels: int = 3, base_channels: int = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = CustomBackbone(input_channels, base_channels, dropout_p=dropout_p) # Pass dropout_p\n",
    "        self.features_dim = self.backbone.features_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.features_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_rot_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, Any]:\n",
    "        features = self.backbone(x)\n",
    "        features_flat = features.view(features.size(0), -1)\n",
    "        logits = self.classifier(features_flat)\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'features': features_flat\n",
    "        }\n",
    "\n",
    "    def calculate_ssl_loss(self, logits: torch.Tensor, rot_labels: torch.Tensor) -> torch.Tensor:\n",
    "        # Use F.cross_entropy and ensure labels are long type\n",
    "        return F.cross_entropy(logits, rot_labels.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T02:03:17.764124Z",
     "iopub.status.busy": "2025-07-21T02:03:17.763936Z",
     "iopub.status.idle": "2025-07-21T02:03:17.768525Z",
     "shell.execute_reply": "2025-07-21T02:03:17.767774Z",
     "shell.execute_reply.started": "2025-07-21T02:03:17.764109Z"
    },
    "id": "_wVKJ8yidnll",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CaSSLePredictor(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        # input_dim and output_dim will both be the backbone's feature dimension\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T02:03:17.839842Z",
     "iopub.status.busy": "2025-07-21T02:03:17.839633Z",
     "iopub.status.idle": "2025-07-21T02:03:17.851650Z",
     "shell.execute_reply": "2025-07-21T02:03:17.850892Z",
     "shell.execute_reply.started": "2025-07-21T02:03:17.839827Z"
    },
    "id": "cPD7AnI1dqza",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CaSSleTrainer:\n",
    "    def __init__(self, base_ssl_model: RotNetModel,\n",
    "                 ca_predictor_hidden_dim: int,\n",
    "                 learning_rate, lambda_cassle, device: str = 'cuda'):\n",
    "\n",
    "        self.base_ssl_model = base_ssl_model.to(device) # This is f_t + rotation_head\n",
    "        self.lambda_cassle = lambda_cassle\n",
    "        self.device = device\n",
    "\n",
    "        # Input and output dimensions for CaSSLe Predictor are the backbone's feature dimension\n",
    "        predictor_input_output_dim = self.base_ssl_model.features_dim\n",
    "\n",
    "        # Initialize the current CaSSLe predictor\n",
    "        self.g_current = CaSSLePredictor(\n",
    "            predictor_input_output_dim,\n",
    "            ca_predictor_hidden_dim,\n",
    "            predictor_input_output_dim\n",
    "        ).to(device)\n",
    "\n",
    "        # Optimizer for ALL trainable parameters: current RotNet model (f_t + head) AND predictor g\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            list(self.base_ssl_model.parameters()) + list(self.g_current.parameters()),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # This will hold the frozen previous encoder (f_{t-1}^{frozen})\n",
    "        self.f_frozen_teacher = None\n",
    "\n",
    "    def set_previous_frozen_encoder(self, encoder_state_dict: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Loads the state of the previous encoder (f_{t-1}) and freezes it.\n",
    "        This becomes the 'teacher' encoder for distillation.\n",
    "        \"\"\"\n",
    "        # A new backbone for the frozen teacher\n",
    "        self.f_frozen_teacher = CustomBackbone(input_channels=3, base_channels=64, dropout_p=0.1).to(self.device)\n",
    "        self.f_frozen_teacher.load_state_dict(encoder_state_dict)\n",
    "\n",
    "\n",
    "        # Freeze the parameters\n",
    "        for param in self.f_frozen_teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        print(f\"Frozen encoder (f_t-1) loaded and parameters frozen: {all(not p.requires_grad for p in self.f_frozen_teacher.parameters())}\")\n",
    "\n",
    "\n",
    "    def train_task(self, data_loader: torch.utils.data.DataLoader, epochs: int):\n",
    "        self.base_ssl_model.train() # f_t + rotation_head is trainable\n",
    "        self.g_current.train() # g is trainable\n",
    "\n",
    "        # Set f_frozen_teacher to eval mode to disable dropout/batchnorm updates for teacher\n",
    "        if self.f_frozen_teacher:\n",
    "            self.f_frozen_teacher.eval()\n",
    "\n",
    "        print(f\"Distilling from frozen teacher encoder (f_t-1): {self.f_frozen_teacher is not None}\")\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        min_delta = 0.001\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.1)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_ssl_loss = 0\n",
    "            total_cassle_loss = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for batch_idx, (rotated_imgs, rotation_labels, _) in enumerate(data_loader): # _ for original_label\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # rotated_imgs: (batch_size, 4, C, H, W)\n",
    "                # rotation_labels: (batch_size, 4)\n",
    "\n",
    "                # Flatten the batch and rotation dimensions for model input\n",
    "                imgs_flat = rotated_imgs.view(-1, *rotated_imgs.shape[2:]).to(self.device)\n",
    "                labels_flat = rotation_labels.view(-1).to(self.device)\n",
    "\n",
    "                #  Forward Pass through the current trainable RotNet model (f_t + head)\n",
    "                ssl_output = self.base_ssl_model(imgs_flat)\n",
    "\n",
    "                # Calculate Base Self-Supervised Loss  (Cross-Entropy)\n",
    "                loss_ssl = self.base_ssl_model.calculate_ssl_loss(ssl_output['logits'], labels_flat)\n",
    "\n",
    "                # Calculate CaSSle Distillation Loss (L_D)\n",
    "                loss_cassle = torch.tensor(0.0).to(self.device) # Initialize to 0 for the first task\n",
    "\n",
    "                if self.f_frozen_teacher:\n",
    "                    # Get features from the *frozen previous encoder* (f_{t-1}^{frozen})\n",
    "                    with torch.no_grad():\n",
    "                        features_from_frozen = self.f_frozen_teacher(imgs_flat)\n",
    "\n",
    "                    # Student predictions from current trainable 'g'\n",
    "                    # g takes features from current f_t\n",
    "                    student_pred = self.g_current(ssl_output['features'])\n",
    "                    #student_pred = F.normalize(student_pred, dim=-1)  # Normalize student predictions\n",
    "\n",
    "                    # Teacher targets (from frozen f_t-1).\n",
    "                    teacher_target = features_from_frozen\n",
    "\n",
    "                    # Compute distillation loss using MSE\n",
    "                    loss_cassle = 1-F.cosine_similarity(student_pred, teacher_target,dim=-1).mean()\n",
    "\n",
    "                # --- Total Loss and Optimization ---\n",
    "                loss = loss_ssl + self.lambda_cassle * loss_cassle\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "\n",
    "                total_ssl_loss += loss_ssl.item()\n",
    "                total_cassle_loss += loss_cassle.item()\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                \n",
    "\n",
    "            #Early stopping\n",
    "            avg_loss = total_loss / len(data_loader)\n",
    "            self.scheduler.step()\n",
    "            if avg_loss < best_loss - min_delta:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - SSL Loss: {total_ssl_loss / len(data_loader):.4f}, \"\n",
    "                  f\"CaSSle Loss: {total_cassle_loss / len(data_loader):.4f}, \"\n",
    "                  f\"Total Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "        # State_dict of the current RotNet model's backbone (f_t).\n",
    "        return self.base_ssl_model.backbone.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-21T02:03:17.852953Z",
     "iopub.status.busy": "2025-07-21T02:03:17.852751Z",
     "iopub.status.idle": "2025-07-21T05:44:22.887346Z",
     "shell.execute_reply": "2025-07-21T05:44:22.886617Z",
     "shell.execute_reply.started": "2025-07-21T02:03:17.852938Z"
    },
    "id": "2sXlPeLTdyf7",
    "outputId": "51e47a3f-4b6b-4e5c-e1e9-41a30ca4eaa6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n",
      "Task 1 includes classes: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Task 2 includes classes: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Task 3 includes classes: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Task 4 includes classes: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Task 5 includes classes: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Task 6 includes classes: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Task 7 includes classes: [24, 5, 6, 67, 82, 19, 79, 43, 90, 20]\n",
      "Task 8 includes classes: [0, 95, 57, 93, 53, 89, 25, 71, 84, 77]\n",
      "Task 9 includes classes: [64, 29, 27, 88, 97, 4, 54, 75, 11, 69]\n",
      "Task 10 includes classes: [86, 13, 17, 28, 31, 35, 94, 3, 14, 81]\n",
      "\n",
      "===== Training Task 1/10 =====\n",
      "Distilling from frozen teacher encoder (f_t-1): False\n",
      "Epoch 1/200 - SSL Loss: 1.6184, CaSSle Loss: 0.0000, Total Loss: 1.6184\n",
      "Epoch 2/200 - SSL Loss: 1.2912, CaSSle Loss: 0.0000, Total Loss: 1.2912\n",
      "Epoch 3/200 - SSL Loss: 1.2624, CaSSle Loss: 0.0000, Total Loss: 1.2624\n",
      "Epoch 4/200 - SSL Loss: 1.2458, CaSSle Loss: 0.0000, Total Loss: 1.2458\n",
      "Epoch 5/200 - SSL Loss: 1.2268, CaSSle Loss: 0.0000, Total Loss: 1.2268\n",
      "Epoch 6/200 - SSL Loss: 1.2178, CaSSle Loss: 0.0000, Total Loss: 1.2178\n",
      "Epoch 7/200 - SSL Loss: 1.2112, CaSSle Loss: 0.0000, Total Loss: 1.2112\n",
      "Epoch 8/200 - SSL Loss: 1.1934, CaSSle Loss: 0.0000, Total Loss: 1.1934\n",
      "Epoch 9/200 - SSL Loss: 1.1853, CaSSle Loss: 0.0000, Total Loss: 1.1853\n",
      "Epoch 10/200 - SSL Loss: 1.1722, CaSSle Loss: 0.0000, Total Loss: 1.1722\n",
      "Epoch 11/200 - SSL Loss: 1.1619, CaSSle Loss: 0.0000, Total Loss: 1.1619\n",
      "Epoch 12/200 - SSL Loss: 1.1433, CaSSle Loss: 0.0000, Total Loss: 1.1433\n",
      "Epoch 13/200 - SSL Loss: 1.1159, CaSSle Loss: 0.0000, Total Loss: 1.1159\n",
      "Epoch 14/200 - SSL Loss: 1.0934, CaSSle Loss: 0.0000, Total Loss: 1.0934\n",
      "Epoch 15/200 - SSL Loss: 1.0678, CaSSle Loss: 0.0000, Total Loss: 1.0678\n",
      "Epoch 16/200 - SSL Loss: 1.0489, CaSSle Loss: 0.0000, Total Loss: 1.0489\n",
      "Epoch 17/200 - SSL Loss: 1.0186, CaSSle Loss: 0.0000, Total Loss: 1.0186\n",
      "Epoch 18/200 - SSL Loss: 1.0077, CaSSle Loss: 0.0000, Total Loss: 1.0077\n",
      "Epoch 19/200 - SSL Loss: 0.9809, CaSSle Loss: 0.0000, Total Loss: 0.9809\n",
      "Epoch 20/200 - SSL Loss: 0.9662, CaSSle Loss: 0.0000, Total Loss: 0.9662\n",
      "Epoch 21/200 - SSL Loss: 0.9470, CaSSle Loss: 0.0000, Total Loss: 0.9470\n",
      "Epoch 22/200 - SSL Loss: 0.9255, CaSSle Loss: 0.0000, Total Loss: 0.9255\n",
      "Epoch 23/200 - SSL Loss: 0.9161, CaSSle Loss: 0.0000, Total Loss: 0.9161\n",
      "Epoch 24/200 - SSL Loss: 0.8767, CaSSle Loss: 0.0000, Total Loss: 0.8767\n",
      "Epoch 25/200 - SSL Loss: 0.8599, CaSSle Loss: 0.0000, Total Loss: 0.8599\n",
      "Epoch 26/200 - SSL Loss: 0.8420, CaSSle Loss: 0.0000, Total Loss: 0.8420\n",
      "Epoch 27/200 - SSL Loss: 0.8163, CaSSle Loss: 0.0000, Total Loss: 0.8163\n",
      "Epoch 28/200 - SSL Loss: 0.7999, CaSSle Loss: 0.0000, Total Loss: 0.7999\n",
      "Epoch 29/200 - SSL Loss: 0.7813, CaSSle Loss: 0.0000, Total Loss: 0.7813\n",
      "Epoch 30/200 - SSL Loss: 0.7582, CaSSle Loss: 0.0000, Total Loss: 0.7582\n",
      "Epoch 31/200 - SSL Loss: 0.7364, CaSSle Loss: 0.0000, Total Loss: 0.7364\n",
      "Epoch 32/200 - SSL Loss: 0.7111, CaSSle Loss: 0.0000, Total Loss: 0.7111\n",
      "Epoch 33/200 - SSL Loss: 0.6876, CaSSle Loss: 0.0000, Total Loss: 0.6876\n",
      "Epoch 34/200 - SSL Loss: 0.6704, CaSSle Loss: 0.0000, Total Loss: 0.6704\n",
      "Epoch 35/200 - SSL Loss: 0.6514, CaSSle Loss: 0.0000, Total Loss: 0.6514\n",
      "Epoch 36/200 - SSL Loss: 0.6261, CaSSle Loss: 0.0000, Total Loss: 0.6261\n",
      "Epoch 37/200 - SSL Loss: 0.6068, CaSSle Loss: 0.0000, Total Loss: 0.6068\n",
      "Epoch 38/200 - SSL Loss: 0.5890, CaSSle Loss: 0.0000, Total Loss: 0.5890\n",
      "Epoch 39/200 - SSL Loss: 0.5710, CaSSle Loss: 0.0000, Total Loss: 0.5710\n",
      "Epoch 40/200 - SSL Loss: 0.5555, CaSSle Loss: 0.0000, Total Loss: 0.5555\n",
      "Epoch 41/200 - SSL Loss: 0.5332, CaSSle Loss: 0.0000, Total Loss: 0.5332\n",
      "Epoch 42/200 - SSL Loss: 0.5177, CaSSle Loss: 0.0000, Total Loss: 0.5177\n",
      "Epoch 43/200 - SSL Loss: 0.4950, CaSSle Loss: 0.0000, Total Loss: 0.4950\n",
      "Epoch 44/200 - SSL Loss: 0.4642, CaSSle Loss: 0.0000, Total Loss: 0.4642\n",
      "Epoch 45/200 - SSL Loss: 0.4561, CaSSle Loss: 0.0000, Total Loss: 0.4561\n",
      "Epoch 46/200 - SSL Loss: 0.4356, CaSSle Loss: 0.0000, Total Loss: 0.4356\n",
      "Epoch 47/200 - SSL Loss: 0.4289, CaSSle Loss: 0.0000, Total Loss: 0.4289\n",
      "Epoch 48/200 - SSL Loss: 0.4096, CaSSle Loss: 0.0000, Total Loss: 0.4096\n",
      "Epoch 49/200 - SSL Loss: 0.3925, CaSSle Loss: 0.0000, Total Loss: 0.3925\n",
      "Epoch 50/200 - SSL Loss: 0.3776, CaSSle Loss: 0.0000, Total Loss: 0.3776\n",
      "Epoch 51/200 - SSL Loss: 0.3553, CaSSle Loss: 0.0000, Total Loss: 0.3553\n",
      "Epoch 52/200 - SSL Loss: 0.3684, CaSSle Loss: 0.0000, Total Loss: 0.3684\n",
      "Epoch 53/200 - SSL Loss: 0.3385, CaSSle Loss: 0.0000, Total Loss: 0.3385\n",
      "Epoch 54/200 - SSL Loss: 0.3182, CaSSle Loss: 0.0000, Total Loss: 0.3182\n",
      "Epoch 55/200 - SSL Loss: 0.3161, CaSSle Loss: 0.0000, Total Loss: 0.3161\n",
      "Epoch 56/200 - SSL Loss: 0.3066, CaSSle Loss: 0.0000, Total Loss: 0.3066\n",
      "Epoch 57/200 - SSL Loss: 0.2916, CaSSle Loss: 0.0000, Total Loss: 0.2916\n",
      "Epoch 58/200 - SSL Loss: 0.2740, CaSSle Loss: 0.0000, Total Loss: 0.2740\n",
      "Epoch 59/200 - SSL Loss: 0.2794, CaSSle Loss: 0.0000, Total Loss: 0.2794\n",
      "Epoch 60/200 - SSL Loss: 0.2752, CaSSle Loss: 0.0000, Total Loss: 0.2752\n",
      "Epoch 61/200 - SSL Loss: 0.2774, CaSSle Loss: 0.0000, Total Loss: 0.2774\n",
      "Epoch 62/200 - SSL Loss: 0.2527, CaSSle Loss: 0.0000, Total Loss: 0.2527\n",
      "Epoch 63/200 - SSL Loss: 0.2366, CaSSle Loss: 0.0000, Total Loss: 0.2366\n",
      "Epoch 64/200 - SSL Loss: 0.2370, CaSSle Loss: 0.0000, Total Loss: 0.2370\n",
      "Epoch 65/200 - SSL Loss: 0.2306, CaSSle Loss: 0.0000, Total Loss: 0.2306\n",
      "Epoch 66/200 - SSL Loss: 0.2209, CaSSle Loss: 0.0000, Total Loss: 0.2209\n",
      "Epoch 67/200 - SSL Loss: 0.2136, CaSSle Loss: 0.0000, Total Loss: 0.2136\n",
      "Epoch 68/200 - SSL Loss: 0.2134, CaSSle Loss: 0.0000, Total Loss: 0.2134\n",
      "Epoch 69/200 - SSL Loss: 0.2051, CaSSle Loss: 0.0000, Total Loss: 0.2051\n",
      "Epoch 70/200 - SSL Loss: 0.2035, CaSSle Loss: 0.0000, Total Loss: 0.2035\n",
      "Epoch 71/200 - SSL Loss: 0.2032, CaSSle Loss: 0.0000, Total Loss: 0.2032\n",
      "Epoch 72/200 - SSL Loss: 0.1882, CaSSle Loss: 0.0000, Total Loss: 0.1882\n",
      "Epoch 73/200 - SSL Loss: 0.1919, CaSSle Loss: 0.0000, Total Loss: 0.1919\n",
      "Epoch 74/200 - SSL Loss: 0.1827, CaSSle Loss: 0.0000, Total Loss: 0.1827\n",
      "Epoch 75/200 - SSL Loss: 0.1787, CaSSle Loss: 0.0000, Total Loss: 0.1787\n",
      "Epoch 76/200 - SSL Loss: 0.1782, CaSSle Loss: 0.0000, Total Loss: 0.1782\n",
      "Epoch 77/200 - SSL Loss: 0.1663, CaSSle Loss: 0.0000, Total Loss: 0.1663\n",
      "Epoch 78/200 - SSL Loss: 0.1582, CaSSle Loss: 0.0000, Total Loss: 0.1582\n",
      "Epoch 79/200 - SSL Loss: 0.1633, CaSSle Loss: 0.0000, Total Loss: 0.1633\n",
      "Epoch 80/200 - SSL Loss: 0.1581, CaSSle Loss: 0.0000, Total Loss: 0.1581\n",
      "Epoch 81/200 - SSL Loss: 0.1595, CaSSle Loss: 0.0000, Total Loss: 0.1595\n",
      "Epoch 82/200 - SSL Loss: 0.1530, CaSSle Loss: 0.0000, Total Loss: 0.1530\n",
      "Epoch 83/200 - SSL Loss: 0.1655, CaSSle Loss: 0.0000, Total Loss: 0.1655\n",
      "Epoch 84/200 - SSL Loss: 0.1517, CaSSle Loss: 0.0000, Total Loss: 0.1517\n",
      "Epoch 85/200 - SSL Loss: 0.1526, CaSSle Loss: 0.0000, Total Loss: 0.1526\n",
      "Epoch 86/200 - SSL Loss: 0.1480, CaSSle Loss: 0.0000, Total Loss: 0.1480\n",
      "Epoch 87/200 - SSL Loss: 0.1397, CaSSle Loss: 0.0000, Total Loss: 0.1397\n",
      "Epoch 88/200 - SSL Loss: 0.1419, CaSSle Loss: 0.0000, Total Loss: 0.1419\n",
      "Epoch 89/200 - SSL Loss: 0.1350, CaSSle Loss: 0.0000, Total Loss: 0.1350\n",
      "Epoch 90/200 - SSL Loss: 0.1354, CaSSle Loss: 0.0000, Total Loss: 0.1354\n",
      "Epoch 91/200 - SSL Loss: 0.1353, CaSSle Loss: 0.0000, Total Loss: 0.1353\n",
      "Epoch 92/200 - SSL Loss: 0.1247, CaSSle Loss: 0.0000, Total Loss: 0.1247\n",
      "Epoch 93/200 - SSL Loss: 0.1284, CaSSle Loss: 0.0000, Total Loss: 0.1284\n",
      "Epoch 94/200 - SSL Loss: 0.1294, CaSSle Loss: 0.0000, Total Loss: 0.1294\n",
      "Epoch 95/200 - SSL Loss: 0.1282, CaSSle Loss: 0.0000, Total Loss: 0.1282\n",
      "Epoch 96/200 - SSL Loss: 0.1323, CaSSle Loss: 0.0000, Total Loss: 0.1323\n",
      "Epoch 97/200 - SSL Loss: 0.1292, CaSSle Loss: 0.0000, Total Loss: 0.1292\n",
      "Epoch 98/200 - SSL Loss: 0.1181, CaSSle Loss: 0.0000, Total Loss: 0.1181\n",
      "Epoch 99/200 - SSL Loss: 0.1207, CaSSle Loss: 0.0000, Total Loss: 0.1207\n",
      "Epoch 100/200 - SSL Loss: 0.1094, CaSSle Loss: 0.0000, Total Loss: 0.1094\n",
      "Epoch 101/200 - SSL Loss: 0.0832, CaSSle Loss: 0.0000, Total Loss: 0.0832\n",
      "Epoch 102/200 - SSL Loss: 0.0703, CaSSle Loss: 0.0000, Total Loss: 0.0703\n",
      "Epoch 103/200 - SSL Loss: 0.0669, CaSSle Loss: 0.0000, Total Loss: 0.0669\n",
      "Epoch 104/200 - SSL Loss: 0.0595, CaSSle Loss: 0.0000, Total Loss: 0.0595\n",
      "Epoch 105/200 - SSL Loss: 0.0536, CaSSle Loss: 0.0000, Total Loss: 0.0536\n",
      "Epoch 106/200 - SSL Loss: 0.0550, CaSSle Loss: 0.0000, Total Loss: 0.0550\n",
      "Epoch 107/200 - SSL Loss: 0.0550, CaSSle Loss: 0.0000, Total Loss: 0.0550\n",
      "Epoch 108/200 - SSL Loss: 0.0501, CaSSle Loss: 0.0000, Total Loss: 0.0501\n",
      "Epoch 109/200 - SSL Loss: 0.0490, CaSSle Loss: 0.0000, Total Loss: 0.0490\n",
      "Epoch 110/200 - SSL Loss: 0.0496, CaSSle Loss: 0.0000, Total Loss: 0.0496\n",
      "Epoch 111/200 - SSL Loss: 0.0498, CaSSle Loss: 0.0000, Total Loss: 0.0498\n",
      "Epoch 112/200 - SSL Loss: 0.0486, CaSSle Loss: 0.0000, Total Loss: 0.0486\n",
      "Epoch 113/200 - SSL Loss: 0.0451, CaSSle Loss: 0.0000, Total Loss: 0.0451\n",
      "Epoch 114/200 - SSL Loss: 0.0420, CaSSle Loss: 0.0000, Total Loss: 0.0420\n",
      "Epoch 115/200 - SSL Loss: 0.0488, CaSSle Loss: 0.0000, Total Loss: 0.0488\n",
      "Epoch 116/200 - SSL Loss: 0.0406, CaSSle Loss: 0.0000, Total Loss: 0.0406\n",
      "Epoch 117/200 - SSL Loss: 0.0385, CaSSle Loss: 0.0000, Total Loss: 0.0385\n",
      "Epoch 118/200 - SSL Loss: 0.0405, CaSSle Loss: 0.0000, Total Loss: 0.0405\n",
      "Epoch 119/200 - SSL Loss: 0.0430, CaSSle Loss: 0.0000, Total Loss: 0.0430\n",
      "Epoch 120/200 - SSL Loss: 0.0419, CaSSle Loss: 0.0000, Total Loss: 0.0419\n",
      "Epoch 121/200 - SSL Loss: 0.0417, CaSSle Loss: 0.0000, Total Loss: 0.0417\n",
      "Epoch 122/200 - SSL Loss: 0.0381, CaSSle Loss: 0.0000, Total Loss: 0.0381\n",
      "Epoch 123/200 - SSL Loss: 0.0400, CaSSle Loss: 0.0000, Total Loss: 0.0400\n",
      "Epoch 124/200 - SSL Loss: 0.0421, CaSSle Loss: 0.0000, Total Loss: 0.0421\n",
      "Epoch 125/200 - SSL Loss: 0.0385, CaSSle Loss: 0.0000, Total Loss: 0.0385\n",
      "Epoch 126/200 - SSL Loss: 0.0382, CaSSle Loss: 0.0000, Total Loss: 0.0382\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 1 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 71.90%\n",
      "Calculating R_i for task with classes: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 29.70%\n",
      "Random network accuracy on task: 29.70%\n",
      "\n",
      "===== Training Task 2/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.2478, CaSSle Loss: 0.5411, Total Loss: 1.6807\n",
      "Epoch 2/200 - SSL Loss: 0.9873, CaSSle Loss: 0.4686, Total Loss: 1.3622\n",
      "Epoch 3/200 - SSL Loss: 0.8661, CaSSle Loss: 0.4267, Total Loss: 1.2074\n",
      "Epoch 4/200 - SSL Loss: 0.7760, CaSSle Loss: 0.4019, Total Loss: 1.0976\n",
      "Epoch 5/200 - SSL Loss: 0.7172, CaSSle Loss: 0.3867, Total Loss: 1.0265\n",
      "Epoch 6/200 - SSL Loss: 0.6701, CaSSle Loss: 0.3756, Total Loss: 0.9706\n",
      "Epoch 7/200 - SSL Loss: 0.6156, CaSSle Loss: 0.3685, Total Loss: 0.9104\n",
      "Epoch 8/200 - SSL Loss: 0.5753, CaSSle Loss: 0.3640, Total Loss: 0.8665\n",
      "Epoch 9/200 - SSL Loss: 0.5370, CaSSle Loss: 0.3602, Total Loss: 0.8252\n",
      "Epoch 10/200 - SSL Loss: 0.4969, CaSSle Loss: 0.3585, Total Loss: 0.7837\n",
      "Epoch 11/200 - SSL Loss: 0.4734, CaSSle Loss: 0.3567, Total Loss: 0.7588\n",
      "Epoch 12/200 - SSL Loss: 0.4349, CaSSle Loss: 0.3558, Total Loss: 0.7196\n",
      "Epoch 13/200 - SSL Loss: 0.4025, CaSSle Loss: 0.3549, Total Loss: 0.6865\n",
      "Epoch 14/200 - SSL Loss: 0.3775, CaSSle Loss: 0.3543, Total Loss: 0.6609\n",
      "Epoch 15/200 - SSL Loss: 0.3597, CaSSle Loss: 0.3540, Total Loss: 0.6429\n",
      "Epoch 16/200 - SSL Loss: 0.3373, CaSSle Loss: 0.3534, Total Loss: 0.6200\n",
      "Epoch 17/200 - SSL Loss: 0.3163, CaSSle Loss: 0.3527, Total Loss: 0.5984\n",
      "Epoch 18/200 - SSL Loss: 0.2958, CaSSle Loss: 0.3528, Total Loss: 0.5780\n",
      "Epoch 19/200 - SSL Loss: 0.2770, CaSSle Loss: 0.3520, Total Loss: 0.5586\n",
      "Epoch 20/200 - SSL Loss: 0.2597, CaSSle Loss: 0.3530, Total Loss: 0.5421\n",
      "Epoch 21/200 - SSL Loss: 0.2407, CaSSle Loss: 0.3524, Total Loss: 0.5226\n",
      "Epoch 22/200 - SSL Loss: 0.2379, CaSSle Loss: 0.3525, Total Loss: 0.5199\n",
      "Epoch 23/200 - SSL Loss: 0.2241, CaSSle Loss: 0.3520, Total Loss: 0.5057\n",
      "Epoch 24/200 - SSL Loss: 0.2165, CaSSle Loss: 0.3518, Total Loss: 0.4979\n",
      "Epoch 25/200 - SSL Loss: 0.2089, CaSSle Loss: 0.3521, Total Loss: 0.4906\n",
      "Epoch 26/200 - SSL Loss: 0.1988, CaSSle Loss: 0.3520, Total Loss: 0.4804\n",
      "Epoch 27/200 - SSL Loss: 0.1846, CaSSle Loss: 0.3520, Total Loss: 0.4663\n",
      "Epoch 28/200 - SSL Loss: 0.1716, CaSSle Loss: 0.3517, Total Loss: 0.4530\n",
      "Epoch 29/200 - SSL Loss: 0.1700, CaSSle Loss: 0.3520, Total Loss: 0.4516\n",
      "Epoch 30/200 - SSL Loss: 0.1739, CaSSle Loss: 0.3519, Total Loss: 0.4555\n",
      "Epoch 31/200 - SSL Loss: 0.1559, CaSSle Loss: 0.3514, Total Loss: 0.4370\n",
      "Epoch 32/200 - SSL Loss: 0.1532, CaSSle Loss: 0.3511, Total Loss: 0.4341\n",
      "Epoch 33/200 - SSL Loss: 0.1500, CaSSle Loss: 0.3520, Total Loss: 0.4316\n",
      "Epoch 34/200 - SSL Loss: 0.1500, CaSSle Loss: 0.3515, Total Loss: 0.4313\n",
      "Epoch 35/200 - SSL Loss: 0.1284, CaSSle Loss: 0.3514, Total Loss: 0.4095\n",
      "Epoch 36/200 - SSL Loss: 0.1398, CaSSle Loss: 0.3517, Total Loss: 0.4211\n",
      "Epoch 37/200 - SSL Loss: 0.1401, CaSSle Loss: 0.3519, Total Loss: 0.4216\n",
      "Epoch 38/200 - SSL Loss: 0.1336, CaSSle Loss: 0.3513, Total Loss: 0.4147\n",
      "Epoch 39/200 - SSL Loss: 0.1285, CaSSle Loss: 0.3517, Total Loss: 0.4098\n",
      "Epoch 40/200 - SSL Loss: 0.1241, CaSSle Loss: 0.3517, Total Loss: 0.4054\n",
      "Epoch 41/200 - SSL Loss: 0.1232, CaSSle Loss: 0.3517, Total Loss: 0.4046\n",
      "Epoch 42/200 - SSL Loss: 0.1146, CaSSle Loss: 0.3512, Total Loss: 0.3956\n",
      "Epoch 43/200 - SSL Loss: 0.1144, CaSSle Loss: 0.3517, Total Loss: 0.3958\n",
      "Epoch 44/200 - SSL Loss: 0.1155, CaSSle Loss: 0.3513, Total Loss: 0.3966\n",
      "Epoch 45/200 - SSL Loss: 0.1142, CaSSle Loss: 0.3516, Total Loss: 0.3955\n",
      "Epoch 46/200 - SSL Loss: 0.1070, CaSSle Loss: 0.3511, Total Loss: 0.3878\n",
      "Epoch 47/200 - SSL Loss: 0.1113, CaSSle Loss: 0.3515, Total Loss: 0.3925\n",
      "Epoch 48/200 - SSL Loss: 0.1082, CaSSle Loss: 0.3512, Total Loss: 0.3892\n",
      "Epoch 49/200 - SSL Loss: 0.0906, CaSSle Loss: 0.3508, Total Loss: 0.3713\n",
      "Epoch 50/200 - SSL Loss: 0.0984, CaSSle Loss: 0.3508, Total Loss: 0.3790\n",
      "Epoch 51/200 - SSL Loss: 0.0870, CaSSle Loss: 0.3511, Total Loss: 0.3679\n",
      "Epoch 52/200 - SSL Loss: 0.0957, CaSSle Loss: 0.3507, Total Loss: 0.3762\n",
      "Epoch 53/200 - SSL Loss: 0.0982, CaSSle Loss: 0.3513, Total Loss: 0.3792\n",
      "Epoch 54/200 - SSL Loss: 0.0910, CaSSle Loss: 0.3514, Total Loss: 0.3721\n",
      "Epoch 55/200 - SSL Loss: 0.0992, CaSSle Loss: 0.3515, Total Loss: 0.3803\n",
      "Epoch 56/200 - SSL Loss: 0.0922, CaSSle Loss: 0.3514, Total Loss: 0.3734\n",
      "Epoch 57/200 - SSL Loss: 0.0881, CaSSle Loss: 0.3513, Total Loss: 0.3692\n",
      "Epoch 58/200 - SSL Loss: 0.0845, CaSSle Loss: 0.3512, Total Loss: 0.3655\n",
      "Epoch 59/200 - SSL Loss: 0.0830, CaSSle Loss: 0.3511, Total Loss: 0.3638\n",
      "Epoch 60/200 - SSL Loss: 0.0811, CaSSle Loss: 0.3509, Total Loss: 0.3618\n",
      "Epoch 61/200 - SSL Loss: 0.0859, CaSSle Loss: 0.3512, Total Loss: 0.3669\n",
      "Epoch 62/200 - SSL Loss: 0.0823, CaSSle Loss: 0.3515, Total Loss: 0.3635\n",
      "Epoch 63/200 - SSL Loss: 0.0845, CaSSle Loss: 0.3513, Total Loss: 0.3655\n",
      "Epoch 64/200 - SSL Loss: 0.0755, CaSSle Loss: 0.3515, Total Loss: 0.3567\n",
      "Epoch 65/200 - SSL Loss: 0.0833, CaSSle Loss: 0.3509, Total Loss: 0.3640\n",
      "Epoch 66/200 - SSL Loss: 0.0810, CaSSle Loss: 0.3508, Total Loss: 0.3617\n",
      "Epoch 67/200 - SSL Loss: 0.0747, CaSSle Loss: 0.3505, Total Loss: 0.3550\n",
      "Epoch 68/200 - SSL Loss: 0.0757, CaSSle Loss: 0.3507, Total Loss: 0.3562\n",
      "Epoch 69/200 - SSL Loss: 0.0732, CaSSle Loss: 0.3512, Total Loss: 0.3542\n",
      "Epoch 70/200 - SSL Loss: 0.0681, CaSSle Loss: 0.3508, Total Loss: 0.3488\n",
      "Epoch 71/200 - SSL Loss: 0.0762, CaSSle Loss: 0.3511, Total Loss: 0.3571\n",
      "Epoch 72/200 - SSL Loss: 0.0718, CaSSle Loss: 0.3509, Total Loss: 0.3525\n",
      "Epoch 73/200 - SSL Loss: 0.0697, CaSSle Loss: 0.3511, Total Loss: 0.3506\n",
      "Epoch 74/200 - SSL Loss: 0.0697, CaSSle Loss: 0.3511, Total Loss: 0.3505\n",
      "Epoch 75/200 - SSL Loss: 0.0832, CaSSle Loss: 0.3511, Total Loss: 0.3641\n",
      "Epoch 76/200 - SSL Loss: 0.0717, CaSSle Loss: 0.3514, Total Loss: 0.3528\n",
      "Epoch 77/200 - SSL Loss: 0.0736, CaSSle Loss: 0.3511, Total Loss: 0.3545\n",
      "Epoch 78/200 - SSL Loss: 0.0716, CaSSle Loss: 0.3510, Total Loss: 0.3524\n",
      "Epoch 79/200 - SSL Loss: 0.0634, CaSSle Loss: 0.3505, Total Loss: 0.3438\n",
      "Epoch 80/200 - SSL Loss: 0.0707, CaSSle Loss: 0.3508, Total Loss: 0.3513\n",
      "Epoch 81/200 - SSL Loss: 0.0685, CaSSle Loss: 0.3510, Total Loss: 0.3493\n",
      "Epoch 82/200 - SSL Loss: 0.0631, CaSSle Loss: 0.3510, Total Loss: 0.3439\n",
      "Epoch 83/200 - SSL Loss: 0.0692, CaSSle Loss: 0.3507, Total Loss: 0.3498\n",
      "Epoch 84/200 - SSL Loss: 0.0616, CaSSle Loss: 0.3509, Total Loss: 0.3423\n",
      "Epoch 85/200 - SSL Loss: 0.0640, CaSSle Loss: 0.3507, Total Loss: 0.3446\n",
      "Epoch 86/200 - SSL Loss: 0.0677, CaSSle Loss: 0.3507, Total Loss: 0.3482\n",
      "Epoch 87/200 - SSL Loss: 0.0632, CaSSle Loss: 0.3507, Total Loss: 0.3437\n",
      "Epoch 88/200 - SSL Loss: 0.0630, CaSSle Loss: 0.3509, Total Loss: 0.3438\n",
      "Epoch 89/200 - SSL Loss: 0.0637, CaSSle Loss: 0.3509, Total Loss: 0.3444\n",
      "Epoch 90/200 - SSL Loss: 0.0599, CaSSle Loss: 0.3505, Total Loss: 0.3403\n",
      "Epoch 91/200 - SSL Loss: 0.0635, CaSSle Loss: 0.3507, Total Loss: 0.3441\n",
      "Epoch 92/200 - SSL Loss: 0.0646, CaSSle Loss: 0.3507, Total Loss: 0.3452\n",
      "Epoch 93/200 - SSL Loss: 0.0601, CaSSle Loss: 0.3506, Total Loss: 0.3406\n",
      "Epoch 94/200 - SSL Loss: 0.0608, CaSSle Loss: 0.3509, Total Loss: 0.3415\n",
      "Epoch 95/200 - SSL Loss: 0.0590, CaSSle Loss: 0.3508, Total Loss: 0.3396\n",
      "Epoch 96/200 - SSL Loss: 0.0570, CaSSle Loss: 0.3507, Total Loss: 0.3375\n",
      "Epoch 97/200 - SSL Loss: 0.0587, CaSSle Loss: 0.3501, Total Loss: 0.3388\n",
      "Epoch 98/200 - SSL Loss: 0.0613, CaSSle Loss: 0.3505, Total Loss: 0.3417\n",
      "Epoch 99/200 - SSL Loss: 0.0569, CaSSle Loss: 0.3508, Total Loss: 0.3375\n",
      "Epoch 100/200 - SSL Loss: 0.0550, CaSSle Loss: 0.3503, Total Loss: 0.3352\n",
      "Epoch 101/200 - SSL Loss: 0.0415, CaSSle Loss: 0.3472, Total Loss: 0.3193\n",
      "Epoch 102/200 - SSL Loss: 0.0329, CaSSle Loss: 0.3464, Total Loss: 0.3101\n",
      "Epoch 103/200 - SSL Loss: 0.0305, CaSSle Loss: 0.3460, Total Loss: 0.3074\n",
      "Epoch 104/200 - SSL Loss: 0.0284, CaSSle Loss: 0.3459, Total Loss: 0.3051\n",
      "Epoch 105/200 - SSL Loss: 0.0253, CaSSle Loss: 0.3457, Total Loss: 0.3018\n",
      "Epoch 106/200 - SSL Loss: 0.0281, CaSSle Loss: 0.3457, Total Loss: 0.3046\n",
      "Epoch 107/200 - SSL Loss: 0.0243, CaSSle Loss: 0.3453, Total Loss: 0.3005\n",
      "Epoch 108/200 - SSL Loss: 0.0234, CaSSle Loss: 0.3452, Total Loss: 0.2995\n",
      "Epoch 109/200 - SSL Loss: 0.0211, CaSSle Loss: 0.3452, Total Loss: 0.2972\n",
      "Epoch 110/200 - SSL Loss: 0.0229, CaSSle Loss: 0.3450, Total Loss: 0.2989\n",
      "Epoch 111/200 - SSL Loss: 0.0213, CaSSle Loss: 0.3454, Total Loss: 0.2975\n",
      "Epoch 112/200 - SSL Loss: 0.0197, CaSSle Loss: 0.3449, Total Loss: 0.2956\n",
      "Epoch 113/200 - SSL Loss: 0.0196, CaSSle Loss: 0.3447, Total Loss: 0.2954\n",
      "Epoch 114/200 - SSL Loss: 0.0186, CaSSle Loss: 0.3446, Total Loss: 0.2943\n",
      "Epoch 115/200 - SSL Loss: 0.0171, CaSSle Loss: 0.3445, Total Loss: 0.2928\n",
      "Epoch 116/200 - SSL Loss: 0.0177, CaSSle Loss: 0.3446, Total Loss: 0.2933\n",
      "Epoch 117/200 - SSL Loss: 0.0171, CaSSle Loss: 0.3444, Total Loss: 0.2926\n",
      "Epoch 118/200 - SSL Loss: 0.0186, CaSSle Loss: 0.3444, Total Loss: 0.2941\n",
      "Epoch 119/200 - SSL Loss: 0.0187, CaSSle Loss: 0.3443, Total Loss: 0.2941\n",
      "Epoch 120/200 - SSL Loss: 0.0197, CaSSle Loss: 0.3444, Total Loss: 0.2952\n",
      "Epoch 121/200 - SSL Loss: 0.0193, CaSSle Loss: 0.3443, Total Loss: 0.2947\n",
      "Epoch 122/200 - SSL Loss: 0.0163, CaSSle Loss: 0.3442, Total Loss: 0.2917\n",
      "Epoch 123/200 - SSL Loss: 0.0183, CaSSle Loss: 0.3441, Total Loss: 0.2936\n",
      "Epoch 124/200 - SSL Loss: 0.0180, CaSSle Loss: 0.3444, Total Loss: 0.2936\n",
      "Epoch 125/200 - SSL Loss: 0.0142, CaSSle Loss: 0.3439, Total Loss: 0.2893\n",
      "Epoch 126/200 - SSL Loss: 0.0162, CaSSle Loss: 0.3438, Total Loss: 0.2913\n",
      "Epoch 127/200 - SSL Loss: 0.0180, CaSSle Loss: 0.3441, Total Loss: 0.2933\n",
      "Epoch 128/200 - SSL Loss: 0.0164, CaSSle Loss: 0.3439, Total Loss: 0.2915\n",
      "Epoch 129/200 - SSL Loss: 0.0145, CaSSle Loss: 0.3439, Total Loss: 0.2896\n",
      "Epoch 130/200 - SSL Loss: 0.0145, CaSSle Loss: 0.3440, Total Loss: 0.2897\n",
      "Epoch 131/200 - SSL Loss: 0.0146, CaSSle Loss: 0.3438, Total Loss: 0.2896\n",
      "Epoch 132/200 - SSL Loss: 0.0164, CaSSle Loss: 0.3438, Total Loss: 0.2915\n",
      "Epoch 133/200 - SSL Loss: 0.0147, CaSSle Loss: 0.3438, Total Loss: 0.2898\n",
      "Epoch 134/200 - SSL Loss: 0.0131, CaSSle Loss: 0.3434, Total Loss: 0.2878\n",
      "Epoch 135/200 - SSL Loss: 0.0135, CaSSle Loss: 0.3436, Total Loss: 0.2884\n",
      "Epoch 136/200 - SSL Loss: 0.0128, CaSSle Loss: 0.3435, Total Loss: 0.2876\n",
      "Epoch 137/200 - SSL Loss: 0.0156, CaSSle Loss: 0.3436, Total Loss: 0.2905\n",
      "Epoch 138/200 - SSL Loss: 0.0162, CaSSle Loss: 0.3433, Total Loss: 0.2908\n",
      "Epoch 139/200 - SSL Loss: 0.0141, CaSSle Loss: 0.3435, Total Loss: 0.2889\n",
      "Epoch 140/200 - SSL Loss: 0.0147, CaSSle Loss: 0.3436, Total Loss: 0.2896\n",
      "Epoch 141/200 - SSL Loss: 0.0131, CaSSle Loss: 0.3436, Total Loss: 0.2880\n",
      "Epoch 142/200 - SSL Loss: 0.0136, CaSSle Loss: 0.3436, Total Loss: 0.2885\n",
      "Epoch 143/200 - SSL Loss: 0.0133, CaSSle Loss: 0.3435, Total Loss: 0.2881\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 2 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 76.80%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 75.90%\n",
      "Calculating R_i for task with classes: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 36.00%\n",
      "Random network accuracy on task: 36.00%\n",
      "\n",
      "===== Training Task 3/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.2239, CaSSle Loss: 0.6151, Total Loss: 1.7160\n",
      "Epoch 2/200 - SSL Loss: 0.9550, CaSSle Loss: 0.5371, Total Loss: 1.3847\n",
      "Epoch 3/200 - SSL Loss: 0.8571, CaSSle Loss: 0.4993, Total Loss: 1.2565\n",
      "Epoch 4/200 - SSL Loss: 0.7721, CaSSle Loss: 0.4775, Total Loss: 1.1541\n",
      "Epoch 5/200 - SSL Loss: 0.7108, CaSSle Loss: 0.4634, Total Loss: 1.0815\n",
      "Epoch 6/200 - SSL Loss: 0.6500, CaSSle Loss: 0.4541, Total Loss: 1.0133\n",
      "Epoch 7/200 - SSL Loss: 0.5880, CaSSle Loss: 0.4475, Total Loss: 0.9461\n",
      "Epoch 8/200 - SSL Loss: 0.5415, CaSSle Loss: 0.4431, Total Loss: 0.8960\n",
      "Epoch 9/200 - SSL Loss: 0.5020, CaSSle Loss: 0.4394, Total Loss: 0.8535\n",
      "Epoch 10/200 - SSL Loss: 0.4649, CaSSle Loss: 0.4367, Total Loss: 0.8142\n",
      "Epoch 11/200 - SSL Loss: 0.4314, CaSSle Loss: 0.4344, Total Loss: 0.7789\n",
      "Epoch 12/200 - SSL Loss: 0.3920, CaSSle Loss: 0.4323, Total Loss: 0.7379\n",
      "Epoch 13/200 - SSL Loss: 0.3605, CaSSle Loss: 0.4304, Total Loss: 0.7049\n",
      "Epoch 14/200 - SSL Loss: 0.3367, CaSSle Loss: 0.4295, Total Loss: 0.6803\n",
      "Epoch 15/200 - SSL Loss: 0.3147, CaSSle Loss: 0.4290, Total Loss: 0.6579\n",
      "Epoch 16/200 - SSL Loss: 0.2850, CaSSle Loss: 0.4282, Total Loss: 0.6276\n",
      "Epoch 17/200 - SSL Loss: 0.2694, CaSSle Loss: 0.4277, Total Loss: 0.6116\n",
      "Epoch 18/200 - SSL Loss: 0.2611, CaSSle Loss: 0.4283, Total Loss: 0.6037\n",
      "Epoch 19/200 - SSL Loss: 0.2367, CaSSle Loss: 0.4275, Total Loss: 0.5787\n",
      "Epoch 20/200 - SSL Loss: 0.2336, CaSSle Loss: 0.4275, Total Loss: 0.5757\n",
      "Epoch 21/200 - SSL Loss: 0.2147, CaSSle Loss: 0.4271, Total Loss: 0.5564\n",
      "Epoch 22/200 - SSL Loss: 0.1990, CaSSle Loss: 0.4268, Total Loss: 0.5405\n",
      "Epoch 23/200 - SSL Loss: 0.1929, CaSSle Loss: 0.4267, Total Loss: 0.5343\n",
      "Epoch 24/200 - SSL Loss: 0.1756, CaSSle Loss: 0.4265, Total Loss: 0.5168\n",
      "Epoch 25/200 - SSL Loss: 0.1739, CaSSle Loss: 0.4262, Total Loss: 0.5149\n",
      "Epoch 26/200 - SSL Loss: 0.1727, CaSSle Loss: 0.4271, Total Loss: 0.5144\n",
      "Epoch 27/200 - SSL Loss: 0.1635, CaSSle Loss: 0.4264, Total Loss: 0.5046\n",
      "Epoch 28/200 - SSL Loss: 0.1555, CaSSle Loss: 0.4264, Total Loss: 0.4966\n",
      "Epoch 29/200 - SSL Loss: 0.1388, CaSSle Loss: 0.4260, Total Loss: 0.4795\n",
      "Epoch 30/200 - SSL Loss: 0.1379, CaSSle Loss: 0.4264, Total Loss: 0.4790\n",
      "Epoch 31/200 - SSL Loss: 0.1340, CaSSle Loss: 0.4262, Total Loss: 0.4749\n",
      "Epoch 32/200 - SSL Loss: 0.1295, CaSSle Loss: 0.4263, Total Loss: 0.4705\n",
      "Epoch 33/200 - SSL Loss: 0.1282, CaSSle Loss: 0.4261, Total Loss: 0.4692\n",
      "Epoch 34/200 - SSL Loss: 0.1236, CaSSle Loss: 0.4264, Total Loss: 0.4647\n",
      "Epoch 35/200 - SSL Loss: 0.1221, CaSSle Loss: 0.4259, Total Loss: 0.4628\n",
      "Epoch 36/200 - SSL Loss: 0.1077, CaSSle Loss: 0.4260, Total Loss: 0.4485\n",
      "Epoch 37/200 - SSL Loss: 0.1119, CaSSle Loss: 0.4258, Total Loss: 0.4525\n",
      "Epoch 38/200 - SSL Loss: 0.1043, CaSSle Loss: 0.4257, Total Loss: 0.4448\n",
      "Epoch 39/200 - SSL Loss: 0.1071, CaSSle Loss: 0.4258, Total Loss: 0.4478\n",
      "Epoch 40/200 - SSL Loss: 0.1054, CaSSle Loss: 0.4260, Total Loss: 0.4462\n",
      "Epoch 41/200 - SSL Loss: 0.0992, CaSSle Loss: 0.4255, Total Loss: 0.4396\n",
      "Epoch 42/200 - SSL Loss: 0.0971, CaSSle Loss: 0.4255, Total Loss: 0.4375\n",
      "Epoch 43/200 - SSL Loss: 0.1002, CaSSle Loss: 0.4261, Total Loss: 0.4410\n",
      "Epoch 44/200 - SSL Loss: 0.0923, CaSSle Loss: 0.4257, Total Loss: 0.4328\n",
      "Epoch 45/200 - SSL Loss: 0.0945, CaSSle Loss: 0.4259, Total Loss: 0.4352\n",
      "Epoch 46/200 - SSL Loss: 0.0868, CaSSle Loss: 0.4259, Total Loss: 0.4276\n",
      "Epoch 47/200 - SSL Loss: 0.0969, CaSSle Loss: 0.4260, Total Loss: 0.4377\n",
      "Epoch 48/200 - SSL Loss: 0.0823, CaSSle Loss: 0.4258, Total Loss: 0.4230\n",
      "Epoch 49/200 - SSL Loss: 0.0816, CaSSle Loss: 0.4255, Total Loss: 0.4220\n",
      "Epoch 50/200 - SSL Loss: 0.0877, CaSSle Loss: 0.4258, Total Loss: 0.4283\n",
      "Epoch 51/200 - SSL Loss: 0.0866, CaSSle Loss: 0.4256, Total Loss: 0.4270\n",
      "Epoch 52/200 - SSL Loss: 0.0814, CaSSle Loss: 0.4260, Total Loss: 0.4222\n",
      "Epoch 53/200 - SSL Loss: 0.0768, CaSSle Loss: 0.4255, Total Loss: 0.4172\n",
      "Epoch 54/200 - SSL Loss: 0.0749, CaSSle Loss: 0.4253, Total Loss: 0.4151\n",
      "Epoch 55/200 - SSL Loss: 0.0695, CaSSle Loss: 0.4254, Total Loss: 0.4098\n",
      "Epoch 56/200 - SSL Loss: 0.0751, CaSSle Loss: 0.4258, Total Loss: 0.4157\n",
      "Epoch 57/200 - SSL Loss: 0.0649, CaSSle Loss: 0.4252, Total Loss: 0.4051\n",
      "Epoch 58/200 - SSL Loss: 0.0692, CaSSle Loss: 0.4254, Total Loss: 0.4095\n",
      "Epoch 59/200 - SSL Loss: 0.0667, CaSSle Loss: 0.4255, Total Loss: 0.4071\n",
      "Epoch 60/200 - SSL Loss: 0.0755, CaSSle Loss: 0.4257, Total Loss: 0.4160\n",
      "Epoch 61/200 - SSL Loss: 0.0747, CaSSle Loss: 0.4258, Total Loss: 0.4153\n",
      "Epoch 62/200 - SSL Loss: 0.0673, CaSSle Loss: 0.4261, Total Loss: 0.4081\n",
      "Epoch 63/200 - SSL Loss: 0.0708, CaSSle Loss: 0.4258, Total Loss: 0.4115\n",
      "Epoch 64/200 - SSL Loss: 0.0727, CaSSle Loss: 0.4260, Total Loss: 0.4134\n",
      "Epoch 65/200 - SSL Loss: 0.0785, CaSSle Loss: 0.4263, Total Loss: 0.4196\n",
      "Epoch 66/200 - SSL Loss: 0.0739, CaSSle Loss: 0.4259, Total Loss: 0.4146\n",
      "Epoch 67/200 - SSL Loss: 0.0627, CaSSle Loss: 0.4254, Total Loss: 0.4030\n",
      "Epoch 68/200 - SSL Loss: 0.0647, CaSSle Loss: 0.4258, Total Loss: 0.4053\n",
      "Epoch 69/200 - SSL Loss: 0.0651, CaSSle Loss: 0.4256, Total Loss: 0.4055\n",
      "Epoch 70/200 - SSL Loss: 0.0701, CaSSle Loss: 0.4257, Total Loss: 0.4107\n",
      "Epoch 71/200 - SSL Loss: 0.0649, CaSSle Loss: 0.4256, Total Loss: 0.4054\n",
      "Epoch 72/200 - SSL Loss: 0.0640, CaSSle Loss: 0.4256, Total Loss: 0.4045\n",
      "Epoch 73/200 - SSL Loss: 0.0612, CaSSle Loss: 0.4256, Total Loss: 0.4017\n",
      "Epoch 74/200 - SSL Loss: 0.0628, CaSSle Loss: 0.4256, Total Loss: 0.4032\n",
      "Epoch 75/200 - SSL Loss: 0.0577, CaSSle Loss: 0.4253, Total Loss: 0.3979\n",
      "Epoch 76/200 - SSL Loss: 0.0647, CaSSle Loss: 0.4256, Total Loss: 0.4052\n",
      "Epoch 77/200 - SSL Loss: 0.0574, CaSSle Loss: 0.4252, Total Loss: 0.3976\n",
      "Epoch 78/200 - SSL Loss: 0.0537, CaSSle Loss: 0.4253, Total Loss: 0.3939\n",
      "Epoch 79/200 - SSL Loss: 0.0601, CaSSle Loss: 0.4255, Total Loss: 0.4005\n",
      "Epoch 80/200 - SSL Loss: 0.0603, CaSSle Loss: 0.4252, Total Loss: 0.4005\n",
      "Epoch 81/200 - SSL Loss: 0.0559, CaSSle Loss: 0.4253, Total Loss: 0.3962\n",
      "Epoch 82/200 - SSL Loss: 0.0624, CaSSle Loss: 0.4253, Total Loss: 0.4026\n",
      "Epoch 83/200 - SSL Loss: 0.0620, CaSSle Loss: 0.4254, Total Loss: 0.4023\n",
      "Epoch 84/200 - SSL Loss: 0.0578, CaSSle Loss: 0.4255, Total Loss: 0.3982\n",
      "Epoch 85/200 - SSL Loss: 0.0589, CaSSle Loss: 0.4255, Total Loss: 0.3993\n",
      "Epoch 86/200 - SSL Loss: 0.0515, CaSSle Loss: 0.4253, Total Loss: 0.3918\n",
      "Epoch 87/200 - SSL Loss: 0.0608, CaSSle Loss: 0.4253, Total Loss: 0.4010\n",
      "Epoch 88/200 - SSL Loss: 0.0664, CaSSle Loss: 0.4260, Total Loss: 0.4072\n",
      "Epoch 89/200 - SSL Loss: 0.0478, CaSSle Loss: 0.4250, Total Loss: 0.3878\n",
      "Epoch 90/200 - SSL Loss: 0.0504, CaSSle Loss: 0.4250, Total Loss: 0.3904\n",
      "Epoch 91/200 - SSL Loss: 0.0536, CaSSle Loss: 0.4252, Total Loss: 0.3938\n",
      "Epoch 92/200 - SSL Loss: 0.0538, CaSSle Loss: 0.4252, Total Loss: 0.3940\n",
      "Epoch 93/200 - SSL Loss: 0.0560, CaSSle Loss: 0.4255, Total Loss: 0.3964\n",
      "Epoch 94/200 - SSL Loss: 0.0573, CaSSle Loss: 0.4252, Total Loss: 0.3975\n",
      "Epoch 95/200 - SSL Loss: 0.0528, CaSSle Loss: 0.4252, Total Loss: 0.3930\n",
      "Epoch 96/200 - SSL Loss: 0.0529, CaSSle Loss: 0.4251, Total Loss: 0.3930\n",
      "Epoch 97/200 - SSL Loss: 0.0501, CaSSle Loss: 0.4254, Total Loss: 0.3904\n",
      "Epoch 98/200 - SSL Loss: 0.0549, CaSSle Loss: 0.4253, Total Loss: 0.3951\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 3 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 75.80%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 76.40%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 81.20%\n",
      "Calculating R_i for task with classes: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 38.20%\n",
      "Random network accuracy on task: 38.20%\n",
      "\n",
      "===== Training Task 4/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 0.9368, CaSSle Loss: 0.6484, Total Loss: 1.4556\n",
      "Epoch 2/200 - SSL Loss: 0.7008, CaSSle Loss: 0.5665, Total Loss: 1.1540\n",
      "Epoch 3/200 - SSL Loss: 0.6082, CaSSle Loss: 0.5276, Total Loss: 1.0302\n",
      "Epoch 4/200 - SSL Loss: 0.5352, CaSSle Loss: 0.5061, Total Loss: 0.9400\n",
      "Epoch 5/200 - SSL Loss: 0.4788, CaSSle Loss: 0.4930, Total Loss: 0.8732\n",
      "Epoch 6/200 - SSL Loss: 0.4389, CaSSle Loss: 0.4845, Total Loss: 0.8264\n",
      "Epoch 7/200 - SSL Loss: 0.3826, CaSSle Loss: 0.4777, Total Loss: 0.7648\n",
      "Epoch 8/200 - SSL Loss: 0.3485, CaSSle Loss: 0.4728, Total Loss: 0.7268\n",
      "Epoch 9/200 - SSL Loss: 0.3153, CaSSle Loss: 0.4692, Total Loss: 0.6906\n",
      "Epoch 10/200 - SSL Loss: 0.2820, CaSSle Loss: 0.4667, Total Loss: 0.6554\n",
      "Epoch 11/200 - SSL Loss: 0.2541, CaSSle Loss: 0.4645, Total Loss: 0.6257\n",
      "Epoch 12/200 - SSL Loss: 0.2408, CaSSle Loss: 0.4631, Total Loss: 0.6113\n",
      "Epoch 13/200 - SSL Loss: 0.2163, CaSSle Loss: 0.4614, Total Loss: 0.5854\n",
      "Epoch 14/200 - SSL Loss: 0.1994, CaSSle Loss: 0.4606, Total Loss: 0.5679\n",
      "Epoch 15/200 - SSL Loss: 0.1834, CaSSle Loss: 0.4599, Total Loss: 0.5513\n",
      "Epoch 16/200 - SSL Loss: 0.1768, CaSSle Loss: 0.4590, Total Loss: 0.5440\n",
      "Epoch 17/200 - SSL Loss: 0.1600, CaSSle Loss: 0.4583, Total Loss: 0.5266\n",
      "Epoch 18/200 - SSL Loss: 0.1449, CaSSle Loss: 0.4578, Total Loss: 0.5111\n",
      "Epoch 19/200 - SSL Loss: 0.1400, CaSSle Loss: 0.4573, Total Loss: 0.5059\n",
      "Epoch 20/200 - SSL Loss: 0.1347, CaSSle Loss: 0.4573, Total Loss: 0.5006\n",
      "Epoch 21/200 - SSL Loss: 0.1136, CaSSle Loss: 0.4569, Total Loss: 0.4791\n",
      "Epoch 22/200 - SSL Loss: 0.1056, CaSSle Loss: 0.4563, Total Loss: 0.4706\n",
      "Epoch 23/200 - SSL Loss: 0.1074, CaSSle Loss: 0.4567, Total Loss: 0.4728\n",
      "Epoch 24/200 - SSL Loss: 0.1071, CaSSle Loss: 0.4566, Total Loss: 0.4724\n",
      "Epoch 25/200 - SSL Loss: 0.1017, CaSSle Loss: 0.4569, Total Loss: 0.4672\n",
      "Epoch 26/200 - SSL Loss: 0.0888, CaSSle Loss: 0.4559, Total Loss: 0.4535\n",
      "Epoch 27/200 - SSL Loss: 0.0884, CaSSle Loss: 0.4558, Total Loss: 0.4531\n",
      "Epoch 28/200 - SSL Loss: 0.0879, CaSSle Loss: 0.4558, Total Loss: 0.4525\n",
      "Epoch 29/200 - SSL Loss: 0.0896, CaSSle Loss: 0.4560, Total Loss: 0.4544\n",
      "Epoch 30/200 - SSL Loss: 0.0827, CaSSle Loss: 0.4560, Total Loss: 0.4475\n",
      "Epoch 31/200 - SSL Loss: 0.0746, CaSSle Loss: 0.4555, Total Loss: 0.4390\n",
      "Epoch 32/200 - SSL Loss: 0.0725, CaSSle Loss: 0.4559, Total Loss: 0.4372\n",
      "Epoch 33/200 - SSL Loss: 0.0729, CaSSle Loss: 0.4555, Total Loss: 0.4374\n",
      "Epoch 34/200 - SSL Loss: 0.0610, CaSSle Loss: 0.4554, Total Loss: 0.4253\n",
      "Epoch 35/200 - SSL Loss: 0.0631, CaSSle Loss: 0.4557, Total Loss: 0.4277\n",
      "Epoch 36/200 - SSL Loss: 0.0633, CaSSle Loss: 0.4557, Total Loss: 0.4278\n",
      "Epoch 37/200 - SSL Loss: 0.0617, CaSSle Loss: 0.4553, Total Loss: 0.4260\n",
      "Epoch 38/200 - SSL Loss: 0.0693, CaSSle Loss: 0.4556, Total Loss: 0.4338\n",
      "Epoch 39/200 - SSL Loss: 0.0602, CaSSle Loss: 0.4554, Total Loss: 0.4245\n",
      "Epoch 40/200 - SSL Loss: 0.0571, CaSSle Loss: 0.4558, Total Loss: 0.4217\n",
      "Epoch 41/200 - SSL Loss: 0.0586, CaSSle Loss: 0.4556, Total Loss: 0.4231\n",
      "Epoch 42/200 - SSL Loss: 0.0572, CaSSle Loss: 0.4556, Total Loss: 0.4217\n",
      "Epoch 43/200 - SSL Loss: 0.0558, CaSSle Loss: 0.4556, Total Loss: 0.4203\n",
      "Epoch 44/200 - SSL Loss: 0.0481, CaSSle Loss: 0.4553, Total Loss: 0.4124\n",
      "Epoch 45/200 - SSL Loss: 0.0530, CaSSle Loss: 0.4553, Total Loss: 0.4173\n",
      "Epoch 46/200 - SSL Loss: 0.0494, CaSSle Loss: 0.4547, Total Loss: 0.4132\n",
      "Epoch 47/200 - SSL Loss: 0.0510, CaSSle Loss: 0.4551, Total Loss: 0.4151\n",
      "Epoch 48/200 - SSL Loss: 0.0546, CaSSle Loss: 0.4551, Total Loss: 0.4187\n",
      "Epoch 49/200 - SSL Loss: 0.0525, CaSSle Loss: 0.4554, Total Loss: 0.4168\n",
      "Epoch 50/200 - SSL Loss: 0.0442, CaSSle Loss: 0.4552, Total Loss: 0.4084\n",
      "Epoch 51/200 - SSL Loss: 0.0466, CaSSle Loss: 0.4551, Total Loss: 0.4106\n",
      "Epoch 52/200 - SSL Loss: 0.0445, CaSSle Loss: 0.4545, Total Loss: 0.4081\n",
      "Epoch 53/200 - SSL Loss: 0.0527, CaSSle Loss: 0.4547, Total Loss: 0.4164\n",
      "Epoch 54/200 - SSL Loss: 0.0454, CaSSle Loss: 0.4554, Total Loss: 0.4097\n",
      "Epoch 55/200 - SSL Loss: 0.0486, CaSSle Loss: 0.4549, Total Loss: 0.4126\n",
      "Epoch 56/200 - SSL Loss: 0.0475, CaSSle Loss: 0.4551, Total Loss: 0.4116\n",
      "Epoch 57/200 - SSL Loss: 0.0475, CaSSle Loss: 0.4548, Total Loss: 0.4113\n",
      "Epoch 58/200 - SSL Loss: 0.0460, CaSSle Loss: 0.4549, Total Loss: 0.4099\n",
      "Epoch 59/200 - SSL Loss: 0.0476, CaSSle Loss: 0.4547, Total Loss: 0.4114\n",
      "Epoch 60/200 - SSL Loss: 0.0400, CaSSle Loss: 0.4544, Total Loss: 0.4035\n",
      "Epoch 61/200 - SSL Loss: 0.0396, CaSSle Loss: 0.4540, Total Loss: 0.4028\n",
      "Epoch 62/200 - SSL Loss: 0.0387, CaSSle Loss: 0.4544, Total Loss: 0.4022\n",
      "Epoch 63/200 - SSL Loss: 0.0372, CaSSle Loss: 0.4545, Total Loss: 0.4008\n",
      "Epoch 64/200 - SSL Loss: 0.0402, CaSSle Loss: 0.4545, Total Loss: 0.4038\n",
      "Epoch 65/200 - SSL Loss: 0.0445, CaSSle Loss: 0.4550, Total Loss: 0.4086\n",
      "Epoch 66/200 - SSL Loss: 0.0407, CaSSle Loss: 0.4548, Total Loss: 0.4045\n",
      "Epoch 67/200 - SSL Loss: 0.0370, CaSSle Loss: 0.4546, Total Loss: 0.4007\n",
      "Epoch 68/200 - SSL Loss: 0.0436, CaSSle Loss: 0.4543, Total Loss: 0.4070\n",
      "Epoch 69/200 - SSL Loss: 0.0372, CaSSle Loss: 0.4541, Total Loss: 0.4005\n",
      "Epoch 70/200 - SSL Loss: 0.0381, CaSSle Loss: 0.4546, Total Loss: 0.4017\n",
      "Epoch 71/200 - SSL Loss: 0.0361, CaSSle Loss: 0.4543, Total Loss: 0.3996\n",
      "Epoch 72/200 - SSL Loss: 0.0346, CaSSle Loss: 0.4546, Total Loss: 0.3982\n",
      "Epoch 73/200 - SSL Loss: 0.0335, CaSSle Loss: 0.4541, Total Loss: 0.3968\n",
      "Epoch 74/200 - SSL Loss: 0.0355, CaSSle Loss: 0.4537, Total Loss: 0.3985\n",
      "Epoch 75/200 - SSL Loss: 0.0372, CaSSle Loss: 0.4546, Total Loss: 0.4009\n",
      "Epoch 76/200 - SSL Loss: 0.0332, CaSSle Loss: 0.4540, Total Loss: 0.3965\n",
      "Epoch 77/200 - SSL Loss: 0.0337, CaSSle Loss: 0.4541, Total Loss: 0.3970\n",
      "Epoch 78/200 - SSL Loss: 0.0357, CaSSle Loss: 0.4543, Total Loss: 0.3992\n",
      "Epoch 79/200 - SSL Loss: 0.0280, CaSSle Loss: 0.4540, Total Loss: 0.3912\n",
      "Epoch 80/200 - SSL Loss: 0.0307, CaSSle Loss: 0.4539, Total Loss: 0.3938\n",
      "Epoch 81/200 - SSL Loss: 0.0300, CaSSle Loss: 0.4540, Total Loss: 0.3932\n",
      "Epoch 82/200 - SSL Loss: 0.0353, CaSSle Loss: 0.4543, Total Loss: 0.3987\n",
      "Epoch 83/200 - SSL Loss: 0.0377, CaSSle Loss: 0.4542, Total Loss: 0.4010\n",
      "Epoch 84/200 - SSL Loss: 0.0378, CaSSle Loss: 0.4545, Total Loss: 0.4015\n",
      "Epoch 85/200 - SSL Loss: 0.0278, CaSSle Loss: 0.4540, Total Loss: 0.3910\n",
      "Epoch 86/200 - SSL Loss: 0.0332, CaSSle Loss: 0.4540, Total Loss: 0.3964\n",
      "Epoch 87/200 - SSL Loss: 0.0382, CaSSle Loss: 0.4541, Total Loss: 0.4015\n",
      "Epoch 88/200 - SSL Loss: 0.0314, CaSSle Loss: 0.4542, Total Loss: 0.3947\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 4 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 74.90%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 76.40%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 81.80%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 72.90%\n",
      "Calculating R_i for task with classes: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 35.80%\n",
      "Random network accuracy on task: 35.80%\n",
      "\n",
      "===== Training Task 5/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.3069, CaSSle Loss: 0.6495, Total Loss: 1.8265\n",
      "Epoch 2/200 - SSL Loss: 1.0540, CaSSle Loss: 0.5541, Total Loss: 1.4974\n",
      "Epoch 3/200 - SSL Loss: 0.9432, CaSSle Loss: 0.5138, Total Loss: 1.3542\n",
      "Epoch 4/200 - SSL Loss: 0.8532, CaSSle Loss: 0.4922, Total Loss: 1.2470\n",
      "Epoch 5/200 - SSL Loss: 0.7834, CaSSle Loss: 0.4776, Total Loss: 1.1655\n",
      "Epoch 6/200 - SSL Loss: 0.7079, CaSSle Loss: 0.4682, Total Loss: 1.0824\n",
      "Epoch 7/200 - SSL Loss: 0.6551, CaSSle Loss: 0.4614, Total Loss: 1.0243\n",
      "Epoch 8/200 - SSL Loss: 0.6074, CaSSle Loss: 0.4569, Total Loss: 0.9730\n",
      "Epoch 9/200 - SSL Loss: 0.5580, CaSSle Loss: 0.4529, Total Loss: 0.9203\n",
      "Epoch 10/200 - SSL Loss: 0.5157, CaSSle Loss: 0.4507, Total Loss: 0.8763\n",
      "Epoch 11/200 - SSL Loss: 0.4773, CaSSle Loss: 0.4486, Total Loss: 0.8361\n",
      "Epoch 12/200 - SSL Loss: 0.4451, CaSSle Loss: 0.4465, Total Loss: 0.8022\n",
      "Epoch 13/200 - SSL Loss: 0.4144, CaSSle Loss: 0.4450, Total Loss: 0.7704\n",
      "Epoch 14/200 - SSL Loss: 0.3834, CaSSle Loss: 0.4444, Total Loss: 0.7390\n",
      "Epoch 15/200 - SSL Loss: 0.3622, CaSSle Loss: 0.4440, Total Loss: 0.7174\n",
      "Epoch 16/200 - SSL Loss: 0.3438, CaSSle Loss: 0.4431, Total Loss: 0.6983\n",
      "Epoch 17/200 - SSL Loss: 0.3222, CaSSle Loss: 0.4427, Total Loss: 0.6764\n",
      "Epoch 18/200 - SSL Loss: 0.3014, CaSSle Loss: 0.4423, Total Loss: 0.6553\n",
      "Epoch 19/200 - SSL Loss: 0.2865, CaSSle Loss: 0.4416, Total Loss: 0.6398\n",
      "Epoch 20/200 - SSL Loss: 0.2793, CaSSle Loss: 0.4418, Total Loss: 0.6327\n",
      "Epoch 21/200 - SSL Loss: 0.2542, CaSSle Loss: 0.4412, Total Loss: 0.6072\n",
      "Epoch 22/200 - SSL Loss: 0.2501, CaSSle Loss: 0.4412, Total Loss: 0.6031\n",
      "Epoch 23/200 - SSL Loss: 0.2355, CaSSle Loss: 0.4411, Total Loss: 0.5884\n",
      "Epoch 24/200 - SSL Loss: 0.2324, CaSSle Loss: 0.4412, Total Loss: 0.5853\n",
      "Epoch 25/200 - SSL Loss: 0.2087, CaSSle Loss: 0.4407, Total Loss: 0.5613\n",
      "Epoch 26/200 - SSL Loss: 0.2008, CaSSle Loss: 0.4407, Total Loss: 0.5533\n",
      "Epoch 27/200 - SSL Loss: 0.1984, CaSSle Loss: 0.4409, Total Loss: 0.5511\n",
      "Epoch 28/200 - SSL Loss: 0.1890, CaSSle Loss: 0.4405, Total Loss: 0.5414\n",
      "Epoch 29/200 - SSL Loss: 0.1871, CaSSle Loss: 0.4404, Total Loss: 0.5394\n",
      "Epoch 30/200 - SSL Loss: 0.1768, CaSSle Loss: 0.4405, Total Loss: 0.5292\n",
      "Epoch 31/200 - SSL Loss: 0.1696, CaSSle Loss: 0.4405, Total Loss: 0.5221\n",
      "Epoch 32/200 - SSL Loss: 0.1644, CaSSle Loss: 0.4404, Total Loss: 0.5166\n",
      "Epoch 33/200 - SSL Loss: 0.1613, CaSSle Loss: 0.4406, Total Loss: 0.5138\n",
      "Epoch 34/200 - SSL Loss: 0.1607, CaSSle Loss: 0.4404, Total Loss: 0.5130\n",
      "Epoch 35/200 - SSL Loss: 0.1524, CaSSle Loss: 0.4403, Total Loss: 0.5046\n",
      "Epoch 36/200 - SSL Loss: 0.1459, CaSSle Loss: 0.4402, Total Loss: 0.4980\n",
      "Epoch 37/200 - SSL Loss: 0.1541, CaSSle Loss: 0.4408, Total Loss: 0.5067\n",
      "Epoch 38/200 - SSL Loss: 0.1406, CaSSle Loss: 0.4406, Total Loss: 0.4931\n",
      "Epoch 39/200 - SSL Loss: 0.1354, CaSSle Loss: 0.4399, Total Loss: 0.4873\n",
      "Epoch 40/200 - SSL Loss: 0.1365, CaSSle Loss: 0.4404, Total Loss: 0.4888\n",
      "Epoch 41/200 - SSL Loss: 0.1277, CaSSle Loss: 0.4401, Total Loss: 0.4798\n",
      "Epoch 42/200 - SSL Loss: 0.1253, CaSSle Loss: 0.4400, Total Loss: 0.4773\n",
      "Epoch 43/200 - SSL Loss: 0.1328, CaSSle Loss: 0.4401, Total Loss: 0.4849\n",
      "Epoch 44/200 - SSL Loss: 0.1276, CaSSle Loss: 0.4401, Total Loss: 0.4797\n",
      "Epoch 45/200 - SSL Loss: 0.1298, CaSSle Loss: 0.4403, Total Loss: 0.4821\n",
      "Epoch 46/200 - SSL Loss: 0.1154, CaSSle Loss: 0.4402, Total Loss: 0.4676\n",
      "Epoch 47/200 - SSL Loss: 0.1158, CaSSle Loss: 0.4399, Total Loss: 0.4678\n",
      "Epoch 48/200 - SSL Loss: 0.1159, CaSSle Loss: 0.4402, Total Loss: 0.4681\n",
      "Epoch 49/200 - SSL Loss: 0.1131, CaSSle Loss: 0.4402, Total Loss: 0.4652\n",
      "Epoch 50/200 - SSL Loss: 0.1104, CaSSle Loss: 0.4405, Total Loss: 0.4627\n",
      "Epoch 51/200 - SSL Loss: 0.1091, CaSSle Loss: 0.4405, Total Loss: 0.4615\n",
      "Epoch 52/200 - SSL Loss: 0.1097, CaSSle Loss: 0.4402, Total Loss: 0.4619\n",
      "Epoch 53/200 - SSL Loss: 0.1096, CaSSle Loss: 0.4403, Total Loss: 0.4618\n",
      "Epoch 54/200 - SSL Loss: 0.1058, CaSSle Loss: 0.4405, Total Loss: 0.4582\n",
      "Epoch 55/200 - SSL Loss: 0.1111, CaSSle Loss: 0.4403, Total Loss: 0.4634\n",
      "Epoch 56/200 - SSL Loss: 0.1001, CaSSle Loss: 0.4404, Total Loss: 0.4525\n",
      "Epoch 57/200 - SSL Loss: 0.0978, CaSSle Loss: 0.4402, Total Loss: 0.4500\n",
      "Epoch 58/200 - SSL Loss: 0.1013, CaSSle Loss: 0.4398, Total Loss: 0.4531\n",
      "Epoch 59/200 - SSL Loss: 0.1021, CaSSle Loss: 0.4402, Total Loss: 0.4543\n",
      "Epoch 60/200 - SSL Loss: 0.0971, CaSSle Loss: 0.4405, Total Loss: 0.4495\n",
      "Epoch 61/200 - SSL Loss: 0.0993, CaSSle Loss: 0.4399, Total Loss: 0.4512\n",
      "Epoch 62/200 - SSL Loss: 0.1034, CaSSle Loss: 0.4405, Total Loss: 0.4558\n",
      "Epoch 63/200 - SSL Loss: 0.0957, CaSSle Loss: 0.4402, Total Loss: 0.4478\n",
      "Epoch 64/200 - SSL Loss: 0.0883, CaSSle Loss: 0.4404, Total Loss: 0.4406\n",
      "Epoch 65/200 - SSL Loss: 0.1001, CaSSle Loss: 0.4407, Total Loss: 0.4527\n",
      "Epoch 66/200 - SSL Loss: 0.0922, CaSSle Loss: 0.4404, Total Loss: 0.4445\n",
      "Epoch 67/200 - SSL Loss: 0.0903, CaSSle Loss: 0.4404, Total Loss: 0.4426\n",
      "Epoch 68/200 - SSL Loss: 0.0911, CaSSle Loss: 0.4400, Total Loss: 0.4431\n",
      "Epoch 69/200 - SSL Loss: 0.0842, CaSSle Loss: 0.4396, Total Loss: 0.4359\n",
      "Epoch 70/200 - SSL Loss: 0.0866, CaSSle Loss: 0.4399, Total Loss: 0.4385\n",
      "Epoch 71/200 - SSL Loss: 0.0881, CaSSle Loss: 0.4405, Total Loss: 0.4405\n",
      "Epoch 72/200 - SSL Loss: 0.0914, CaSSle Loss: 0.4403, Total Loss: 0.4436\n",
      "Epoch 73/200 - SSL Loss: 0.0814, CaSSle Loss: 0.4399, Total Loss: 0.4333\n",
      "Epoch 74/200 - SSL Loss: 0.0810, CaSSle Loss: 0.4399, Total Loss: 0.4329\n",
      "Epoch 75/200 - SSL Loss: 0.0847, CaSSle Loss: 0.4400, Total Loss: 0.4367\n",
      "Epoch 76/200 - SSL Loss: 0.0768, CaSSle Loss: 0.4400, Total Loss: 0.4288\n",
      "Epoch 77/200 - SSL Loss: 0.0815, CaSSle Loss: 0.4403, Total Loss: 0.4337\n",
      "Epoch 78/200 - SSL Loss: 0.0754, CaSSle Loss: 0.4400, Total Loss: 0.4274\n",
      "Epoch 79/200 - SSL Loss: 0.0735, CaSSle Loss: 0.4399, Total Loss: 0.4254\n",
      "Epoch 80/200 - SSL Loss: 0.0740, CaSSle Loss: 0.4401, Total Loss: 0.4260\n",
      "Epoch 81/200 - SSL Loss: 0.0776, CaSSle Loss: 0.4396, Total Loss: 0.4293\n",
      "Epoch 82/200 - SSL Loss: 0.0789, CaSSle Loss: 0.4403, Total Loss: 0.4312\n",
      "Epoch 83/200 - SSL Loss: 0.0755, CaSSle Loss: 0.4399, Total Loss: 0.4274\n",
      "Epoch 84/200 - SSL Loss: 0.0712, CaSSle Loss: 0.4398, Total Loss: 0.4231\n",
      "Epoch 85/200 - SSL Loss: 0.0723, CaSSle Loss: 0.4402, Total Loss: 0.4244\n",
      "Epoch 86/200 - SSL Loss: 0.0673, CaSSle Loss: 0.4394, Total Loss: 0.4188\n",
      "Epoch 87/200 - SSL Loss: 0.0617, CaSSle Loss: 0.4394, Total Loss: 0.4132\n",
      "Epoch 88/200 - SSL Loss: 0.0740, CaSSle Loss: 0.4401, Total Loss: 0.4261\n",
      "Epoch 89/200 - SSL Loss: 0.0786, CaSSle Loss: 0.4403, Total Loss: 0.4308\n",
      "Epoch 90/200 - SSL Loss: 0.0765, CaSSle Loss: 0.4401, Total Loss: 0.4286\n",
      "Epoch 91/200 - SSL Loss: 0.0728, CaSSle Loss: 0.4397, Total Loss: 0.4245\n",
      "Epoch 92/200 - SSL Loss: 0.0704, CaSSle Loss: 0.4398, Total Loss: 0.4222\n",
      "Epoch 93/200 - SSL Loss: 0.0684, CaSSle Loss: 0.4401, Total Loss: 0.4205\n",
      "Epoch 94/200 - SSL Loss: 0.0705, CaSSle Loss: 0.4402, Total Loss: 0.4227\n",
      "Epoch 95/200 - SSL Loss: 0.0674, CaSSle Loss: 0.4403, Total Loss: 0.4196\n",
      "Epoch 96/200 - SSL Loss: 0.0599, CaSSle Loss: 0.4399, Total Loss: 0.4119\n",
      "Epoch 97/200 - SSL Loss: 0.0862, CaSSle Loss: 0.4409, Total Loss: 0.4388\n",
      "Epoch 98/200 - SSL Loss: 0.0723, CaSSle Loss: 0.4403, Total Loss: 0.4245\n",
      "Epoch 99/200 - SSL Loss: 0.0666, CaSSle Loss: 0.4401, Total Loss: 0.4187\n",
      "Epoch 100/200 - SSL Loss: 0.0641, CaSSle Loss: 0.4402, Total Loss: 0.4162\n",
      "Epoch 101/200 - SSL Loss: 0.0498, CaSSle Loss: 0.4361, Total Loss: 0.3987\n",
      "Epoch 102/200 - SSL Loss: 0.0459, CaSSle Loss: 0.4349, Total Loss: 0.3939\n",
      "Epoch 103/200 - SSL Loss: 0.0363, CaSSle Loss: 0.4342, Total Loss: 0.3837\n",
      "Epoch 104/200 - SSL Loss: 0.0371, CaSSle Loss: 0.4346, Total Loss: 0.3847\n",
      "Epoch 105/200 - SSL Loss: 0.0365, CaSSle Loss: 0.4341, Total Loss: 0.3838\n",
      "Epoch 106/200 - SSL Loss: 0.0340, CaSSle Loss: 0.4338, Total Loss: 0.3810\n",
      "Epoch 107/200 - SSL Loss: 0.0339, CaSSle Loss: 0.4339, Total Loss: 0.3810\n",
      "Epoch 108/200 - SSL Loss: 0.0294, CaSSle Loss: 0.4335, Total Loss: 0.3763\n",
      "Epoch 109/200 - SSL Loss: 0.0287, CaSSle Loss: 0.4335, Total Loss: 0.3755\n",
      "Epoch 110/200 - SSL Loss: 0.0314, CaSSle Loss: 0.4331, Total Loss: 0.3779\n",
      "Epoch 111/200 - SSL Loss: 0.0290, CaSSle Loss: 0.4333, Total Loss: 0.3756\n",
      "Epoch 112/200 - SSL Loss: 0.0286, CaSSle Loss: 0.4331, Total Loss: 0.3751\n",
      "Epoch 113/200 - SSL Loss: 0.0268, CaSSle Loss: 0.4329, Total Loss: 0.3731\n",
      "Epoch 114/200 - SSL Loss: 0.0260, CaSSle Loss: 0.4330, Total Loss: 0.3724\n",
      "Epoch 115/200 - SSL Loss: 0.0254, CaSSle Loss: 0.4327, Total Loss: 0.3715\n",
      "Epoch 116/200 - SSL Loss: 0.0236, CaSSle Loss: 0.4325, Total Loss: 0.3696\n",
      "Epoch 117/200 - SSL Loss: 0.0277, CaSSle Loss: 0.4327, Total Loss: 0.3738\n",
      "Epoch 118/200 - SSL Loss: 0.0239, CaSSle Loss: 0.4327, Total Loss: 0.3701\n",
      "Epoch 119/200 - SSL Loss: 0.0245, CaSSle Loss: 0.4325, Total Loss: 0.3705\n",
      "Epoch 120/200 - SSL Loss: 0.0253, CaSSle Loss: 0.4324, Total Loss: 0.3712\n",
      "Epoch 121/200 - SSL Loss: 0.0239, CaSSle Loss: 0.4324, Total Loss: 0.3698\n",
      "Epoch 122/200 - SSL Loss: 0.0200, CaSSle Loss: 0.4323, Total Loss: 0.3658\n",
      "Epoch 123/200 - SSL Loss: 0.0240, CaSSle Loss: 0.4321, Total Loss: 0.3697\n",
      "Epoch 124/200 - SSL Loss: 0.0216, CaSSle Loss: 0.4318, Total Loss: 0.3670\n",
      "Epoch 125/200 - SSL Loss: 0.0203, CaSSle Loss: 0.4320, Total Loss: 0.3659\n",
      "Epoch 126/200 - SSL Loss: 0.0212, CaSSle Loss: 0.4321, Total Loss: 0.3669\n",
      "Epoch 127/200 - SSL Loss: 0.0237, CaSSle Loss: 0.4318, Total Loss: 0.3691\n",
      "Epoch 128/200 - SSL Loss: 0.0220, CaSSle Loss: 0.4320, Total Loss: 0.3677\n",
      "Epoch 129/200 - SSL Loss: 0.0212, CaSSle Loss: 0.4319, Total Loss: 0.3668\n",
      "Epoch 130/200 - SSL Loss: 0.0196, CaSSle Loss: 0.4320, Total Loss: 0.3652\n",
      "Epoch 131/200 - SSL Loss: 0.0183, CaSSle Loss: 0.4318, Total Loss: 0.3637\n",
      "Epoch 132/200 - SSL Loss: 0.0194, CaSSle Loss: 0.4318, Total Loss: 0.3648\n",
      "Epoch 133/200 - SSL Loss: 0.0193, CaSSle Loss: 0.4315, Total Loss: 0.3645\n",
      "Epoch 134/200 - SSL Loss: 0.0198, CaSSle Loss: 0.4315, Total Loss: 0.3650\n",
      "Epoch 135/200 - SSL Loss: 0.0204, CaSSle Loss: 0.4317, Total Loss: 0.3658\n",
      "Epoch 136/200 - SSL Loss: 0.0198, CaSSle Loss: 0.4317, Total Loss: 0.3652\n",
      "Epoch 137/200 - SSL Loss: 0.0207, CaSSle Loss: 0.4316, Total Loss: 0.3659\n",
      "Epoch 138/200 - SSL Loss: 0.0189, CaSSle Loss: 0.4317, Total Loss: 0.3643\n",
      "Epoch 139/200 - SSL Loss: 0.0186, CaSSle Loss: 0.4313, Total Loss: 0.3637\n",
      "Epoch 140/200 - SSL Loss: 0.0190, CaSSle Loss: 0.4313, Total Loss: 0.3641\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 5 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 73.60%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 75.70%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 81.80%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 74.10%\n",
      "  Evaluating on classes from Task 5: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 80.90%\n",
      "Calculating R_i for task with classes: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 37.50%\n",
      "Random network accuracy on task: 37.50%\n",
      "\n",
      "===== Training Task 6/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.6806, CaSSle Loss: 0.6659, Total Loss: 2.2133\n",
      "Epoch 2/200 - SSL Loss: 1.1076, CaSSle Loss: 0.5832, Total Loss: 1.5742\n",
      "Epoch 3/200 - SSL Loss: 0.9793, CaSSle Loss: 0.5408, Total Loss: 1.4119\n",
      "Epoch 4/200 - SSL Loss: 0.8786, CaSSle Loss: 0.5180, Total Loss: 1.2930\n",
      "Epoch 5/200 - SSL Loss: 0.8046, CaSSle Loss: 0.5040, Total Loss: 1.2078\n",
      "Epoch 6/200 - SSL Loss: 0.7294, CaSSle Loss: 0.4943, Total Loss: 1.1248\n",
      "Epoch 7/200 - SSL Loss: 0.6733, CaSSle Loss: 0.4873, Total Loss: 1.0631\n",
      "Epoch 8/200 - SSL Loss: 0.6225, CaSSle Loss: 0.4820, Total Loss: 1.0081\n",
      "Epoch 9/200 - SSL Loss: 0.5694, CaSSle Loss: 0.4779, Total Loss: 0.9517\n",
      "Epoch 10/200 - SSL Loss: 0.5252, CaSSle Loss: 0.4749, Total Loss: 0.9051\n",
      "Epoch 11/200 - SSL Loss: 0.4762, CaSSle Loss: 0.4723, Total Loss: 0.8540\n",
      "Epoch 12/200 - SSL Loss: 0.4444, CaSSle Loss: 0.4711, Total Loss: 0.8213\n",
      "Epoch 13/200 - SSL Loss: 0.4103, CaSSle Loss: 0.4693, Total Loss: 0.7857\n",
      "Epoch 14/200 - SSL Loss: 0.3844, CaSSle Loss: 0.4684, Total Loss: 0.7591\n",
      "Epoch 15/200 - SSL Loss: 0.3518, CaSSle Loss: 0.4673, Total Loss: 0.7257\n",
      "Epoch 16/200 - SSL Loss: 0.3248, CaSSle Loss: 0.4662, Total Loss: 0.6978\n",
      "Epoch 17/200 - SSL Loss: 0.3143, CaSSle Loss: 0.4656, Total Loss: 0.6868\n",
      "Epoch 18/200 - SSL Loss: 0.2828, CaSSle Loss: 0.4654, Total Loss: 0.6551\n",
      "Epoch 19/200 - SSL Loss: 0.2756, CaSSle Loss: 0.4652, Total Loss: 0.6477\n",
      "Epoch 20/200 - SSL Loss: 0.2573, CaSSle Loss: 0.4651, Total Loss: 0.6294\n",
      "Epoch 21/200 - SSL Loss: 0.2496, CaSSle Loss: 0.4648, Total Loss: 0.6214\n",
      "Epoch 22/200 - SSL Loss: 0.2307, CaSSle Loss: 0.4647, Total Loss: 0.6025\n",
      "Epoch 23/200 - SSL Loss: 0.2112, CaSSle Loss: 0.4642, Total Loss: 0.5826\n",
      "Epoch 24/200 - SSL Loss: 0.2029, CaSSle Loss: 0.4639, Total Loss: 0.5740\n",
      "Epoch 25/200 - SSL Loss: 0.2046, CaSSle Loss: 0.4641, Total Loss: 0.5759\n",
      "Epoch 26/200 - SSL Loss: 0.1979, CaSSle Loss: 0.4641, Total Loss: 0.5692\n",
      "Epoch 27/200 - SSL Loss: 0.1832, CaSSle Loss: 0.4638, Total Loss: 0.5542\n",
      "Epoch 28/200 - SSL Loss: 0.1747, CaSSle Loss: 0.4638, Total Loss: 0.5458\n",
      "Epoch 29/200 - SSL Loss: 0.1604, CaSSle Loss: 0.4635, Total Loss: 0.5312\n",
      "Epoch 30/200 - SSL Loss: 0.1585, CaSSle Loss: 0.4636, Total Loss: 0.5294\n",
      "Epoch 31/200 - SSL Loss: 0.1451, CaSSle Loss: 0.4637, Total Loss: 0.5161\n",
      "Epoch 32/200 - SSL Loss: 0.1500, CaSSle Loss: 0.4635, Total Loss: 0.5208\n",
      "Epoch 33/200 - SSL Loss: 0.1471, CaSSle Loss: 0.4635, Total Loss: 0.5179\n",
      "Epoch 34/200 - SSL Loss: 0.1488, CaSSle Loss: 0.4640, Total Loss: 0.5200\n",
      "Epoch 35/200 - SSL Loss: 0.1408, CaSSle Loss: 0.4636, Total Loss: 0.5117\n",
      "Epoch 36/200 - SSL Loss: 0.1358, CaSSle Loss: 0.4637, Total Loss: 0.5068\n",
      "Epoch 37/200 - SSL Loss: 0.1322, CaSSle Loss: 0.4634, Total Loss: 0.5029\n",
      "Epoch 38/200 - SSL Loss: 0.1323, CaSSle Loss: 0.4634, Total Loss: 0.5030\n",
      "Epoch 39/200 - SSL Loss: 0.1266, CaSSle Loss: 0.4635, Total Loss: 0.4974\n",
      "Epoch 40/200 - SSL Loss: 0.1197, CaSSle Loss: 0.4632, Total Loss: 0.4902\n",
      "Epoch 41/200 - SSL Loss: 0.1183, CaSSle Loss: 0.4631, Total Loss: 0.4888\n",
      "Epoch 42/200 - SSL Loss: 0.1101, CaSSle Loss: 0.4632, Total Loss: 0.4807\n",
      "Epoch 43/200 - SSL Loss: 0.1103, CaSSle Loss: 0.4635, Total Loss: 0.4810\n",
      "Epoch 44/200 - SSL Loss: 0.1089, CaSSle Loss: 0.4632, Total Loss: 0.4795\n",
      "Epoch 45/200 - SSL Loss: 0.1023, CaSSle Loss: 0.4631, Total Loss: 0.4728\n",
      "Epoch 46/200 - SSL Loss: 0.1004, CaSSle Loss: 0.4633, Total Loss: 0.4710\n",
      "Epoch 47/200 - SSL Loss: 0.1011, CaSSle Loss: 0.4631, Total Loss: 0.4716\n",
      "Epoch 48/200 - SSL Loss: 0.0997, CaSSle Loss: 0.4631, Total Loss: 0.4702\n",
      "Epoch 49/200 - SSL Loss: 0.1034, CaSSle Loss: 0.4631, Total Loss: 0.4739\n",
      "Epoch 50/200 - SSL Loss: 0.0972, CaSSle Loss: 0.4631, Total Loss: 0.4677\n",
      "Epoch 51/200 - SSL Loss: 0.0932, CaSSle Loss: 0.4630, Total Loss: 0.4636\n",
      "Epoch 52/200 - SSL Loss: 0.0974, CaSSle Loss: 0.4631, Total Loss: 0.4679\n",
      "Epoch 53/200 - SSL Loss: 0.0992, CaSSle Loss: 0.4633, Total Loss: 0.4698\n",
      "Epoch 54/200 - SSL Loss: 0.0916, CaSSle Loss: 0.4633, Total Loss: 0.4622\n",
      "Epoch 55/200 - SSL Loss: 0.0940, CaSSle Loss: 0.4632, Total Loss: 0.4645\n",
      "Epoch 56/200 - SSL Loss: 0.0842, CaSSle Loss: 0.4627, Total Loss: 0.4543\n",
      "Epoch 57/200 - SSL Loss: 0.0860, CaSSle Loss: 0.4631, Total Loss: 0.4564\n",
      "Epoch 58/200 - SSL Loss: 0.0830, CaSSle Loss: 0.4628, Total Loss: 0.4532\n",
      "Epoch 59/200 - SSL Loss: 0.0943, CaSSle Loss: 0.4628, Total Loss: 0.4645\n",
      "Epoch 60/200 - SSL Loss: 0.0933, CaSSle Loss: 0.4632, Total Loss: 0.4639\n",
      "Epoch 61/200 - SSL Loss: 0.0794, CaSSle Loss: 0.4627, Total Loss: 0.4496\n",
      "Epoch 62/200 - SSL Loss: 0.0773, CaSSle Loss: 0.4629, Total Loss: 0.4476\n",
      "Epoch 63/200 - SSL Loss: 0.0782, CaSSle Loss: 0.4628, Total Loss: 0.4485\n",
      "Epoch 64/200 - SSL Loss: 0.0736, CaSSle Loss: 0.4624, Total Loss: 0.4435\n",
      "Epoch 65/200 - SSL Loss: 0.0785, CaSSle Loss: 0.4630, Total Loss: 0.4490\n",
      "Epoch 66/200 - SSL Loss: 0.0720, CaSSle Loss: 0.4626, Total Loss: 0.4421\n",
      "Epoch 67/200 - SSL Loss: 0.0770, CaSSle Loss: 0.4629, Total Loss: 0.4474\n",
      "Epoch 68/200 - SSL Loss: 0.0782, CaSSle Loss: 0.4624, Total Loss: 0.4481\n",
      "Epoch 69/200 - SSL Loss: 0.0720, CaSSle Loss: 0.4625, Total Loss: 0.4420\n",
      "Epoch 70/200 - SSL Loss: 0.0752, CaSSle Loss: 0.4627, Total Loss: 0.4453\n",
      "Epoch 71/200 - SSL Loss: 0.0764, CaSSle Loss: 0.4627, Total Loss: 0.4466\n",
      "Epoch 72/200 - SSL Loss: 0.0711, CaSSle Loss: 0.4627, Total Loss: 0.4413\n",
      "Epoch 73/200 - SSL Loss: 0.0734, CaSSle Loss: 0.4626, Total Loss: 0.4434\n",
      "Epoch 74/200 - SSL Loss: 0.0774, CaSSle Loss: 0.4634, Total Loss: 0.4481\n",
      "Epoch 75/200 - SSL Loss: 0.0666, CaSSle Loss: 0.4629, Total Loss: 0.4369\n",
      "Epoch 76/200 - SSL Loss: 0.0670, CaSSle Loss: 0.4625, Total Loss: 0.4369\n",
      "Epoch 77/200 - SSL Loss: 0.0725, CaSSle Loss: 0.4628, Total Loss: 0.4427\n",
      "Epoch 78/200 - SSL Loss: 0.0755, CaSSle Loss: 0.4627, Total Loss: 0.4457\n",
      "Epoch 79/200 - SSL Loss: 0.0687, CaSSle Loss: 0.4626, Total Loss: 0.4388\n",
      "Epoch 80/200 - SSL Loss: 0.0656, CaSSle Loss: 0.4621, Total Loss: 0.4353\n",
      "Epoch 81/200 - SSL Loss: 0.0713, CaSSle Loss: 0.4626, Total Loss: 0.4413\n",
      "Epoch 82/200 - SSL Loss: 0.0618, CaSSle Loss: 0.4626, Total Loss: 0.4319\n",
      "Epoch 83/200 - SSL Loss: 0.0682, CaSSle Loss: 0.4627, Total Loss: 0.4384\n",
      "Epoch 84/200 - SSL Loss: 0.0626, CaSSle Loss: 0.4626, Total Loss: 0.4326\n",
      "Epoch 85/200 - SSL Loss: 0.0583, CaSSle Loss: 0.4622, Total Loss: 0.4280\n",
      "Epoch 86/200 - SSL Loss: 0.0595, CaSSle Loss: 0.4621, Total Loss: 0.4292\n",
      "Epoch 87/200 - SSL Loss: 0.0627, CaSSle Loss: 0.4625, Total Loss: 0.4327\n",
      "Epoch 88/200 - SSL Loss: 0.0599, CaSSle Loss: 0.4622, Total Loss: 0.4296\n",
      "Epoch 89/200 - SSL Loss: 0.0639, CaSSle Loss: 0.4622, Total Loss: 0.4336\n",
      "Epoch 90/200 - SSL Loss: 0.0646, CaSSle Loss: 0.4627, Total Loss: 0.4348\n",
      "Epoch 91/200 - SSL Loss: 0.0658, CaSSle Loss: 0.4624, Total Loss: 0.4358\n",
      "Epoch 92/200 - SSL Loss: 0.0614, CaSSle Loss: 0.4625, Total Loss: 0.4314\n",
      "Epoch 93/200 - SSL Loss: 0.0629, CaSSle Loss: 0.4625, Total Loss: 0.4329\n",
      "Epoch 94/200 - SSL Loss: 0.0585, CaSSle Loss: 0.4625, Total Loss: 0.4285\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 6 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 75.00%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 76.20%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 79.70%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 73.20%\n",
      "  Evaluating on classes from Task 5: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 80.10%\n",
      "  Evaluating on classes from Task 6: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Linear evaluation accuracy on 10 classes: 78.70%\n",
      "Calculating R_i for task with classes: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Linear evaluation accuracy on 10 classes: 34.10%\n",
      "Random network accuracy on task: 34.10%\n",
      "\n",
      "===== Training Task 7/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.4485, CaSSle Loss: 0.6801, Total Loss: 1.9925\n",
      "Epoch 2/200 - SSL Loss: 0.9988, CaSSle Loss: 0.6020, Total Loss: 1.4804\n",
      "Epoch 3/200 - SSL Loss: 0.8783, CaSSle Loss: 0.5637, Total Loss: 1.3292\n",
      "Epoch 4/200 - SSL Loss: 0.7665, CaSSle Loss: 0.5408, Total Loss: 1.1992\n",
      "Epoch 5/200 - SSL Loss: 0.6947, CaSSle Loss: 0.5257, Total Loss: 1.1153\n",
      "Epoch 6/200 - SSL Loss: 0.6390, CaSSle Loss: 0.5158, Total Loss: 1.0516\n",
      "Epoch 7/200 - SSL Loss: 0.5713, CaSSle Loss: 0.5082, Total Loss: 0.9778\n",
      "Epoch 8/200 - SSL Loss: 0.5167, CaSSle Loss: 0.5021, Total Loss: 0.9184\n",
      "Epoch 9/200 - SSL Loss: 0.4749, CaSSle Loss: 0.4974, Total Loss: 0.8728\n",
      "Epoch 10/200 - SSL Loss: 0.4397, CaSSle Loss: 0.4939, Total Loss: 0.8349\n",
      "Epoch 11/200 - SSL Loss: 0.3987, CaSSle Loss: 0.4912, Total Loss: 0.7916\n",
      "Epoch 12/200 - SSL Loss: 0.3616, CaSSle Loss: 0.4881, Total Loss: 0.7521\n",
      "Epoch 13/200 - SSL Loss: 0.3255, CaSSle Loss: 0.4863, Total Loss: 0.7146\n",
      "Epoch 14/200 - SSL Loss: 0.3093, CaSSle Loss: 0.4852, Total Loss: 0.6975\n",
      "Epoch 15/200 - SSL Loss: 0.2860, CaSSle Loss: 0.4838, Total Loss: 0.6731\n",
      "Epoch 16/200 - SSL Loss: 0.2673, CaSSle Loss: 0.4827, Total Loss: 0.6535\n",
      "Epoch 17/200 - SSL Loss: 0.2594, CaSSle Loss: 0.4826, Total Loss: 0.6455\n",
      "Epoch 18/200 - SSL Loss: 0.2403, CaSSle Loss: 0.4814, Total Loss: 0.6254\n",
      "Epoch 19/200 - SSL Loss: 0.2215, CaSSle Loss: 0.4811, Total Loss: 0.6063\n",
      "Epoch 20/200 - SSL Loss: 0.2050, CaSSle Loss: 0.4807, Total Loss: 0.5895\n",
      "Epoch 21/200 - SSL Loss: 0.2058, CaSSle Loss: 0.4808, Total Loss: 0.5905\n",
      "Epoch 22/200 - SSL Loss: 0.1929, CaSSle Loss: 0.4801, Total Loss: 0.5769\n",
      "Epoch 23/200 - SSL Loss: 0.1810, CaSSle Loss: 0.4805, Total Loss: 0.5654\n",
      "Epoch 24/200 - SSL Loss: 0.1649, CaSSle Loss: 0.4798, Total Loss: 0.5488\n",
      "Epoch 25/200 - SSL Loss: 0.1579, CaSSle Loss: 0.4796, Total Loss: 0.5415\n",
      "Epoch 26/200 - SSL Loss: 0.1565, CaSSle Loss: 0.4795, Total Loss: 0.5401\n",
      "Epoch 27/200 - SSL Loss: 0.1515, CaSSle Loss: 0.4797, Total Loss: 0.5353\n",
      "Epoch 28/200 - SSL Loss: 0.1452, CaSSle Loss: 0.4796, Total Loss: 0.5289\n",
      "Epoch 29/200 - SSL Loss: 0.1425, CaSSle Loss: 0.4795, Total Loss: 0.5261\n",
      "Epoch 30/200 - SSL Loss: 0.1384, CaSSle Loss: 0.4792, Total Loss: 0.5218\n",
      "Epoch 31/200 - SSL Loss: 0.1324, CaSSle Loss: 0.4791, Total Loss: 0.5157\n",
      "Epoch 32/200 - SSL Loss: 0.1234, CaSSle Loss: 0.4791, Total Loss: 0.5067\n",
      "Epoch 33/200 - SSL Loss: 0.1209, CaSSle Loss: 0.4788, Total Loss: 0.5039\n",
      "Epoch 34/200 - SSL Loss: 0.1234, CaSSle Loss: 0.4787, Total Loss: 0.5063\n",
      "Epoch 35/200 - SSL Loss: 0.1188, CaSSle Loss: 0.4785, Total Loss: 0.5016\n",
      "Epoch 36/200 - SSL Loss: 0.1126, CaSSle Loss: 0.4786, Total Loss: 0.4954\n",
      "Epoch 37/200 - SSL Loss: 0.1215, CaSSle Loss: 0.4790, Total Loss: 0.5047\n",
      "Epoch 38/200 - SSL Loss: 0.1179, CaSSle Loss: 0.4789, Total Loss: 0.5009\n",
      "Epoch 39/200 - SSL Loss: 0.1065, CaSSle Loss: 0.4785, Total Loss: 0.4893\n",
      "Epoch 40/200 - SSL Loss: 0.1076, CaSSle Loss: 0.4784, Total Loss: 0.4904\n",
      "Epoch 41/200 - SSL Loss: 0.1008, CaSSle Loss: 0.4785, Total Loss: 0.4835\n",
      "Epoch 42/200 - SSL Loss: 0.0976, CaSSle Loss: 0.4785, Total Loss: 0.4804\n",
      "Epoch 43/200 - SSL Loss: 0.0990, CaSSle Loss: 0.4785, Total Loss: 0.4818\n",
      "Epoch 44/200 - SSL Loss: 0.0939, CaSSle Loss: 0.4781, Total Loss: 0.4764\n",
      "Epoch 45/200 - SSL Loss: 0.0938, CaSSle Loss: 0.4782, Total Loss: 0.4764\n",
      "Epoch 46/200 - SSL Loss: 0.0959, CaSSle Loss: 0.4783, Total Loss: 0.4786\n",
      "Epoch 47/200 - SSL Loss: 0.0992, CaSSle Loss: 0.4786, Total Loss: 0.4821\n",
      "Epoch 48/200 - SSL Loss: 0.0883, CaSSle Loss: 0.4778, Total Loss: 0.4706\n",
      "Epoch 49/200 - SSL Loss: 0.0852, CaSSle Loss: 0.4778, Total Loss: 0.4674\n",
      "Epoch 50/200 - SSL Loss: 0.0887, CaSSle Loss: 0.4785, Total Loss: 0.4714\n",
      "Epoch 51/200 - SSL Loss: 0.0836, CaSSle Loss: 0.4779, Total Loss: 0.4660\n",
      "Epoch 52/200 - SSL Loss: 0.0853, CaSSle Loss: 0.4779, Total Loss: 0.4676\n",
      "Epoch 53/200 - SSL Loss: 0.0806, CaSSle Loss: 0.4776, Total Loss: 0.4626\n",
      "Epoch 54/200 - SSL Loss: 0.0856, CaSSle Loss: 0.4782, Total Loss: 0.4681\n",
      "Epoch 55/200 - SSL Loss: 0.0751, CaSSle Loss: 0.4776, Total Loss: 0.4572\n",
      "Epoch 56/200 - SSL Loss: 0.0776, CaSSle Loss: 0.4779, Total Loss: 0.4599\n",
      "Epoch 57/200 - SSL Loss: 0.0780, CaSSle Loss: 0.4777, Total Loss: 0.4602\n",
      "Epoch 58/200 - SSL Loss: 0.0772, CaSSle Loss: 0.4777, Total Loss: 0.4594\n",
      "Epoch 59/200 - SSL Loss: 0.0761, CaSSle Loss: 0.4778, Total Loss: 0.4583\n",
      "Epoch 60/200 - SSL Loss: 0.0778, CaSSle Loss: 0.4777, Total Loss: 0.4600\n",
      "Epoch 61/200 - SSL Loss: 0.0723, CaSSle Loss: 0.4778, Total Loss: 0.4545\n",
      "Epoch 62/200 - SSL Loss: 0.0757, CaSSle Loss: 0.4774, Total Loss: 0.4576\n",
      "Epoch 63/200 - SSL Loss: 0.0702, CaSSle Loss: 0.4772, Total Loss: 0.4520\n",
      "Epoch 64/200 - SSL Loss: 0.0706, CaSSle Loss: 0.4778, Total Loss: 0.4528\n",
      "Epoch 65/200 - SSL Loss: 0.0742, CaSSle Loss: 0.4774, Total Loss: 0.4561\n",
      "Epoch 66/200 - SSL Loss: 0.0745, CaSSle Loss: 0.4780, Total Loss: 0.4569\n",
      "Epoch 67/200 - SSL Loss: 0.0709, CaSSle Loss: 0.4778, Total Loss: 0.4531\n",
      "Epoch 68/200 - SSL Loss: 0.0646, CaSSle Loss: 0.4770, Total Loss: 0.4461\n",
      "Epoch 69/200 - SSL Loss: 0.0637, CaSSle Loss: 0.4776, Total Loss: 0.4458\n",
      "Epoch 70/200 - SSL Loss: 0.0621, CaSSle Loss: 0.4773, Total Loss: 0.4439\n",
      "Epoch 71/200 - SSL Loss: 0.0651, CaSSle Loss: 0.4771, Total Loss: 0.4467\n",
      "Epoch 72/200 - SSL Loss: 0.0615, CaSSle Loss: 0.4770, Total Loss: 0.4430\n",
      "Epoch 73/200 - SSL Loss: 0.0585, CaSSle Loss: 0.4772, Total Loss: 0.4402\n",
      "Epoch 74/200 - SSL Loss: 0.0598, CaSSle Loss: 0.4772, Total Loss: 0.4416\n",
      "Epoch 75/200 - SSL Loss: 0.0650, CaSSle Loss: 0.4767, Total Loss: 0.4464\n",
      "Epoch 76/200 - SSL Loss: 0.0619, CaSSle Loss: 0.4769, Total Loss: 0.4434\n",
      "Epoch 77/200 - SSL Loss: 0.0595, CaSSle Loss: 0.4772, Total Loss: 0.4412\n",
      "Epoch 78/200 - SSL Loss: 0.0607, CaSSle Loss: 0.4771, Total Loss: 0.4423\n",
      "Epoch 79/200 - SSL Loss: 0.0643, CaSSle Loss: 0.4774, Total Loss: 0.4462\n",
      "Epoch 80/200 - SSL Loss: 0.0592, CaSSle Loss: 0.4775, Total Loss: 0.4412\n",
      "Epoch 81/200 - SSL Loss: 0.0613, CaSSle Loss: 0.4770, Total Loss: 0.4429\n",
      "Epoch 82/200 - SSL Loss: 0.0588, CaSSle Loss: 0.4772, Total Loss: 0.4406\n",
      "Epoch 83/200 - SSL Loss: 0.0573, CaSSle Loss: 0.4768, Total Loss: 0.4387\n",
      "Epoch 84/200 - SSL Loss: 0.0572, CaSSle Loss: 0.4769, Total Loss: 0.4387\n",
      "Epoch 85/200 - SSL Loss: 0.0602, CaSSle Loss: 0.4772, Total Loss: 0.4420\n",
      "Epoch 86/200 - SSL Loss: 0.0564, CaSSle Loss: 0.4768, Total Loss: 0.4378\n",
      "Epoch 87/200 - SSL Loss: 0.0548, CaSSle Loss: 0.4765, Total Loss: 0.4360\n",
      "Epoch 88/200 - SSL Loss: 0.0531, CaSSle Loss: 0.4768, Total Loss: 0.4346\n",
      "Epoch 89/200 - SSL Loss: 0.0593, CaSSle Loss: 0.4772, Total Loss: 0.4410\n",
      "Epoch 90/200 - SSL Loss: 0.0625, CaSSle Loss: 0.4772, Total Loss: 0.4443\n",
      "Epoch 91/200 - SSL Loss: 0.0556, CaSSle Loss: 0.4776, Total Loss: 0.4377\n",
      "Epoch 92/200 - SSL Loss: 0.0475, CaSSle Loss: 0.4764, Total Loss: 0.4287\n",
      "Epoch 93/200 - SSL Loss: 0.0560, CaSSle Loss: 0.4767, Total Loss: 0.4373\n",
      "Epoch 94/200 - SSL Loss: 0.0594, CaSSle Loss: 0.4773, Total Loss: 0.4412\n",
      "Epoch 95/200 - SSL Loss: 0.0531, CaSSle Loss: 0.4772, Total Loss: 0.4348\n",
      "Epoch 96/200 - SSL Loss: 0.0512, CaSSle Loss: 0.4767, Total Loss: 0.4326\n",
      "Epoch 97/200 - SSL Loss: 0.0566, CaSSle Loss: 0.4775, Total Loss: 0.4386\n",
      "Epoch 98/200 - SSL Loss: 0.0524, CaSSle Loss: 0.4770, Total Loss: 0.4340\n",
      "Epoch 99/200 - SSL Loss: 0.0506, CaSSle Loss: 0.4764, Total Loss: 0.4317\n",
      "Epoch 100/200 - SSL Loss: 0.0530, CaSSle Loss: 0.4767, Total Loss: 0.4344\n",
      "Epoch 101/200 - SSL Loss: 0.0367, CaSSle Loss: 0.4724, Total Loss: 0.4147\n",
      "Epoch 102/200 - SSL Loss: 0.0308, CaSSle Loss: 0.4714, Total Loss: 0.4079\n",
      "Epoch 103/200 - SSL Loss: 0.0301, CaSSle Loss: 0.4710, Total Loss: 0.4069\n",
      "Epoch 104/200 - SSL Loss: 0.0280, CaSSle Loss: 0.4709, Total Loss: 0.4047\n",
      "Epoch 105/200 - SSL Loss: 0.0224, CaSSle Loss: 0.4705, Total Loss: 0.3987\n",
      "Epoch 106/200 - SSL Loss: 0.0240, CaSSle Loss: 0.4703, Total Loss: 0.4002\n",
      "Epoch 107/200 - SSL Loss: 0.0205, CaSSle Loss: 0.4698, Total Loss: 0.3963\n",
      "Epoch 108/200 - SSL Loss: 0.0203, CaSSle Loss: 0.4699, Total Loss: 0.3962\n",
      "Epoch 109/200 - SSL Loss: 0.0184, CaSSle Loss: 0.4697, Total Loss: 0.3942\n",
      "Epoch 110/200 - SSL Loss: 0.0208, CaSSle Loss: 0.4697, Total Loss: 0.3966\n",
      "Epoch 111/200 - SSL Loss: 0.0194, CaSSle Loss: 0.4696, Total Loss: 0.3950\n",
      "Epoch 112/200 - SSL Loss: 0.0184, CaSSle Loss: 0.4693, Total Loss: 0.3938\n",
      "Epoch 113/200 - SSL Loss: 0.0205, CaSSle Loss: 0.4695, Total Loss: 0.3961\n",
      "Epoch 114/200 - SSL Loss: 0.0175, CaSSle Loss: 0.4693, Total Loss: 0.3929\n",
      "Epoch 115/200 - SSL Loss: 0.0179, CaSSle Loss: 0.4693, Total Loss: 0.3933\n",
      "Epoch 116/200 - SSL Loss: 0.0165, CaSSle Loss: 0.4691, Total Loss: 0.3917\n",
      "Epoch 117/200 - SSL Loss: 0.0139, CaSSle Loss: 0.4691, Total Loss: 0.3891\n",
      "Epoch 118/200 - SSL Loss: 0.0193, CaSSle Loss: 0.4691, Total Loss: 0.3946\n",
      "Epoch 119/200 - SSL Loss: 0.0167, CaSSle Loss: 0.4688, Total Loss: 0.3917\n",
      "Epoch 120/200 - SSL Loss: 0.0154, CaSSle Loss: 0.4689, Total Loss: 0.3906\n",
      "Epoch 121/200 - SSL Loss: 0.0153, CaSSle Loss: 0.4688, Total Loss: 0.3903\n",
      "Epoch 122/200 - SSL Loss: 0.0184, CaSSle Loss: 0.4689, Total Loss: 0.3935\n",
      "Epoch 123/200 - SSL Loss: 0.0161, CaSSle Loss: 0.4688, Total Loss: 0.3911\n",
      "Epoch 124/200 - SSL Loss: 0.0141, CaSSle Loss: 0.4686, Total Loss: 0.3890\n",
      "Epoch 125/200 - SSL Loss: 0.0153, CaSSle Loss: 0.4687, Total Loss: 0.3902\n",
      "Epoch 126/200 - SSL Loss: 0.0167, CaSSle Loss: 0.4688, Total Loss: 0.3917\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 7 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 74.20%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 75.50%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 79.80%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 73.60%\n",
      "  Evaluating on classes from Task 5: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 79.90%\n",
      "  Evaluating on classes from Task 6: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Linear evaluation accuracy on 10 classes: 77.90%\n",
      "  Evaluating on classes from Task 7: [24, 5, 6, 67, 82, 19, 79, 43, 90, 20]\n",
      "Linear evaluation accuracy on 10 classes: 81.20%\n",
      "Calculating R_i for task with classes: [24, 5, 6, 67, 82, 19, 79, 43, 90, 20]\n",
      "Linear evaluation accuracy on 10 classes: 39.20%\n",
      "Random network accuracy on task: 39.20%\n",
      "\n",
      "===== Training Task 8/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.2645, CaSSle Loss: 0.6590, Total Loss: 1.7917\n",
      "Epoch 2/200 - SSL Loss: 0.8348, CaSSle Loss: 0.5710, Total Loss: 1.2915\n",
      "Epoch 3/200 - SSL Loss: 0.7061, CaSSle Loss: 0.5314, Total Loss: 1.1313\n",
      "Epoch 4/200 - SSL Loss: 0.6182, CaSSle Loss: 0.5092, Total Loss: 1.0256\n",
      "Epoch 5/200 - SSL Loss: 0.5499, CaSSle Loss: 0.4950, Total Loss: 0.9459\n",
      "Epoch 6/200 - SSL Loss: 0.4863, CaSSle Loss: 0.4846, Total Loss: 0.8740\n",
      "Epoch 7/200 - SSL Loss: 0.4251, CaSSle Loss: 0.4772, Total Loss: 0.8068\n",
      "Epoch 8/200 - SSL Loss: 0.3859, CaSSle Loss: 0.4717, Total Loss: 0.7633\n",
      "Epoch 9/200 - SSL Loss: 0.3468, CaSSle Loss: 0.4665, Total Loss: 0.7200\n",
      "Epoch 10/200 - SSL Loss: 0.3149, CaSSle Loss: 0.4627, Total Loss: 0.6851\n",
      "Epoch 11/200 - SSL Loss: 0.2813, CaSSle Loss: 0.4597, Total Loss: 0.6491\n",
      "Epoch 12/200 - SSL Loss: 0.2544, CaSSle Loss: 0.4572, Total Loss: 0.6201\n",
      "Epoch 13/200 - SSL Loss: 0.2352, CaSSle Loss: 0.4554, Total Loss: 0.5995\n",
      "Epoch 14/200 - SSL Loss: 0.2149, CaSSle Loss: 0.4538, Total Loss: 0.5780\n",
      "Epoch 15/200 - SSL Loss: 0.1929, CaSSle Loss: 0.4527, Total Loss: 0.5551\n",
      "Epoch 16/200 - SSL Loss: 0.1844, CaSSle Loss: 0.4522, Total Loss: 0.5462\n",
      "Epoch 17/200 - SSL Loss: 0.1628, CaSSle Loss: 0.4509, Total Loss: 0.5235\n",
      "Epoch 18/200 - SSL Loss: 0.1671, CaSSle Loss: 0.4513, Total Loss: 0.5282\n",
      "Epoch 19/200 - SSL Loss: 0.1530, CaSSle Loss: 0.4504, Total Loss: 0.5133\n",
      "Epoch 20/200 - SSL Loss: 0.1429, CaSSle Loss: 0.4493, Total Loss: 0.5023\n",
      "Epoch 21/200 - SSL Loss: 0.1253, CaSSle Loss: 0.4497, Total Loss: 0.4851\n",
      "Epoch 22/200 - SSL Loss: 0.1322, CaSSle Loss: 0.4493, Total Loss: 0.4917\n",
      "Epoch 23/200 - SSL Loss: 0.1113, CaSSle Loss: 0.4488, Total Loss: 0.4703\n",
      "Epoch 24/200 - SSL Loss: 0.1105, CaSSle Loss: 0.4486, Total Loss: 0.4694\n",
      "Epoch 25/200 - SSL Loss: 0.1046, CaSSle Loss: 0.4481, Total Loss: 0.4630\n",
      "Epoch 26/200 - SSL Loss: 0.1049, CaSSle Loss: 0.4481, Total Loss: 0.4634\n",
      "Epoch 27/200 - SSL Loss: 0.0996, CaSSle Loss: 0.4479, Total Loss: 0.4579\n",
      "Epoch 28/200 - SSL Loss: 0.0949, CaSSle Loss: 0.4478, Total Loss: 0.4531\n",
      "Epoch 29/200 - SSL Loss: 0.0912, CaSSle Loss: 0.4476, Total Loss: 0.4493\n",
      "Epoch 30/200 - SSL Loss: 0.0911, CaSSle Loss: 0.4475, Total Loss: 0.4492\n",
      "Epoch 31/200 - SSL Loss: 0.0879, CaSSle Loss: 0.4472, Total Loss: 0.4456\n",
      "Epoch 32/200 - SSL Loss: 0.0753, CaSSle Loss: 0.4469, Total Loss: 0.4328\n",
      "Epoch 33/200 - SSL Loss: 0.0793, CaSSle Loss: 0.4468, Total Loss: 0.4367\n",
      "Epoch 34/200 - SSL Loss: 0.0832, CaSSle Loss: 0.4469, Total Loss: 0.4408\n",
      "Epoch 35/200 - SSL Loss: 0.0762, CaSSle Loss: 0.4469, Total Loss: 0.4337\n",
      "Epoch 36/200 - SSL Loss: 0.0716, CaSSle Loss: 0.4468, Total Loss: 0.4290\n",
      "Epoch 37/200 - SSL Loss: 0.0763, CaSSle Loss: 0.4471, Total Loss: 0.4341\n",
      "Epoch 38/200 - SSL Loss: 0.0661, CaSSle Loss: 0.4470, Total Loss: 0.4237\n",
      "Epoch 39/200 - SSL Loss: 0.0718, CaSSle Loss: 0.4476, Total Loss: 0.4299\n",
      "Epoch 40/200 - SSL Loss: 0.0651, CaSSle Loss: 0.4466, Total Loss: 0.4224\n",
      "Epoch 41/200 - SSL Loss: 0.0631, CaSSle Loss: 0.4459, Total Loss: 0.4198\n",
      "Epoch 42/200 - SSL Loss: 0.0645, CaSSle Loss: 0.4461, Total Loss: 0.4214\n",
      "Epoch 43/200 - SSL Loss: 0.0654, CaSSle Loss: 0.4465, Total Loss: 0.4226\n",
      "Epoch 44/200 - SSL Loss: 0.0630, CaSSle Loss: 0.4462, Total Loss: 0.4200\n",
      "Epoch 45/200 - SSL Loss: 0.0640, CaSSle Loss: 0.4464, Total Loss: 0.4211\n",
      "Epoch 46/200 - SSL Loss: 0.0663, CaSSle Loss: 0.4465, Total Loss: 0.4236\n",
      "Epoch 47/200 - SSL Loss: 0.0602, CaSSle Loss: 0.4462, Total Loss: 0.4172\n",
      "Epoch 48/200 - SSL Loss: 0.0542, CaSSle Loss: 0.4462, Total Loss: 0.4112\n",
      "Epoch 49/200 - SSL Loss: 0.0607, CaSSle Loss: 0.4467, Total Loss: 0.4181\n",
      "Epoch 50/200 - SSL Loss: 0.0529, CaSSle Loss: 0.4460, Total Loss: 0.4097\n",
      "Epoch 51/200 - SSL Loss: 0.0560, CaSSle Loss: 0.4459, Total Loss: 0.4127\n",
      "Epoch 52/200 - SSL Loss: 0.0558, CaSSle Loss: 0.4460, Total Loss: 0.4125\n",
      "Epoch 53/200 - SSL Loss: 0.0565, CaSSle Loss: 0.4464, Total Loss: 0.4136\n",
      "Epoch 54/200 - SSL Loss: 0.0576, CaSSle Loss: 0.4462, Total Loss: 0.4146\n",
      "Epoch 55/200 - SSL Loss: 0.0558, CaSSle Loss: 0.4463, Total Loss: 0.4129\n",
      "Epoch 56/200 - SSL Loss: 0.0517, CaSSle Loss: 0.4458, Total Loss: 0.4084\n",
      "Epoch 57/200 - SSL Loss: 0.0554, CaSSle Loss: 0.4459, Total Loss: 0.4121\n",
      "Epoch 58/200 - SSL Loss: 0.0558, CaSSle Loss: 0.4463, Total Loss: 0.4129\n",
      "Epoch 59/200 - SSL Loss: 0.0467, CaSSle Loss: 0.4457, Total Loss: 0.4032\n",
      "Epoch 60/200 - SSL Loss: 0.0571, CaSSle Loss: 0.4459, Total Loss: 0.4138\n",
      "Epoch 61/200 - SSL Loss: 0.0522, CaSSle Loss: 0.4462, Total Loss: 0.4092\n",
      "Epoch 62/200 - SSL Loss: 0.0510, CaSSle Loss: 0.4458, Total Loss: 0.4076\n",
      "Epoch 63/200 - SSL Loss: 0.0516, CaSSle Loss: 0.4457, Total Loss: 0.4081\n",
      "Epoch 64/200 - SSL Loss: 0.0449, CaSSle Loss: 0.4454, Total Loss: 0.4013\n",
      "Epoch 65/200 - SSL Loss: 0.0419, CaSSle Loss: 0.4454, Total Loss: 0.3982\n",
      "Epoch 66/200 - SSL Loss: 0.0448, CaSSle Loss: 0.4450, Total Loss: 0.4008\n",
      "Epoch 67/200 - SSL Loss: 0.0454, CaSSle Loss: 0.4453, Total Loss: 0.4016\n",
      "Epoch 68/200 - SSL Loss: 0.0463, CaSSle Loss: 0.4457, Total Loss: 0.4029\n",
      "Epoch 69/200 - SSL Loss: 0.0498, CaSSle Loss: 0.4454, Total Loss: 0.4061\n",
      "Epoch 70/200 - SSL Loss: 0.0514, CaSSle Loss: 0.4456, Total Loss: 0.4079\n",
      "Epoch 71/200 - SSL Loss: 0.0467, CaSSle Loss: 0.4457, Total Loss: 0.4033\n",
      "Epoch 72/200 - SSL Loss: 0.0446, CaSSle Loss: 0.4452, Total Loss: 0.4007\n",
      "Epoch 73/200 - SSL Loss: 0.0457, CaSSle Loss: 0.4453, Total Loss: 0.4020\n",
      "Epoch 74/200 - SSL Loss: 0.0400, CaSSle Loss: 0.4455, Total Loss: 0.3964\n",
      "Epoch 75/200 - SSL Loss: 0.0408, CaSSle Loss: 0.4450, Total Loss: 0.3968\n",
      "Epoch 76/200 - SSL Loss: 0.0487, CaSSle Loss: 0.4455, Total Loss: 0.4051\n",
      "Epoch 77/200 - SSL Loss: 0.0379, CaSSle Loss: 0.4451, Total Loss: 0.3939\n",
      "Epoch 78/200 - SSL Loss: 0.0401, CaSSle Loss: 0.4449, Total Loss: 0.3960\n",
      "Epoch 79/200 - SSL Loss: 0.0407, CaSSle Loss: 0.4448, Total Loss: 0.3965\n",
      "Epoch 80/200 - SSL Loss: 0.0478, CaSSle Loss: 0.4451, Total Loss: 0.4038\n",
      "Epoch 81/200 - SSL Loss: 0.0427, CaSSle Loss: 0.4454, Total Loss: 0.3991\n",
      "Epoch 82/200 - SSL Loss: 0.0376, CaSSle Loss: 0.4449, Total Loss: 0.3935\n",
      "Epoch 83/200 - SSL Loss: 0.0377, CaSSle Loss: 0.4446, Total Loss: 0.3933\n",
      "Epoch 84/200 - SSL Loss: 0.0393, CaSSle Loss: 0.4448, Total Loss: 0.3952\n",
      "Epoch 85/200 - SSL Loss: 0.0403, CaSSle Loss: 0.4446, Total Loss: 0.3960\n",
      "Epoch 86/200 - SSL Loss: 0.0345, CaSSle Loss: 0.4443, Total Loss: 0.3899\n",
      "Epoch 87/200 - SSL Loss: 0.0412, CaSSle Loss: 0.4449, Total Loss: 0.3971\n",
      "Epoch 88/200 - SSL Loss: 0.0337, CaSSle Loss: 0.4447, Total Loss: 0.3895\n",
      "Epoch 89/200 - SSL Loss: 0.0391, CaSSle Loss: 0.4443, Total Loss: 0.3945\n",
      "Epoch 90/200 - SSL Loss: 0.0439, CaSSle Loss: 0.4452, Total Loss: 0.4000\n",
      "Epoch 91/200 - SSL Loss: 0.0377, CaSSle Loss: 0.4451, Total Loss: 0.3937\n",
      "Epoch 92/200 - SSL Loss: 0.0401, CaSSle Loss: 0.4450, Total Loss: 0.3961\n",
      "Epoch 93/200 - SSL Loss: 0.0360, CaSSle Loss: 0.4445, Total Loss: 0.3917\n",
      "Epoch 94/200 - SSL Loss: 0.0371, CaSSle Loss: 0.4447, Total Loss: 0.3928\n",
      "Epoch 95/200 - SSL Loss: 0.0415, CaSSle Loss: 0.4448, Total Loss: 0.3973\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 8 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 72.70%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 77.10%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 79.90%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 71.50%\n",
      "  Evaluating on classes from Task 5: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 80.50%\n",
      "  Evaluating on classes from Task 6: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Linear evaluation accuracy on 10 classes: 76.80%\n",
      "  Evaluating on classes from Task 7: [24, 5, 6, 67, 82, 19, 79, 43, 90, 20]\n",
      "Linear evaluation accuracy on 10 classes: 80.60%\n",
      "  Evaluating on classes from Task 8: [0, 95, 57, 93, 53, 89, 25, 71, 84, 77]\n",
      "Linear evaluation accuracy on 10 classes: 79.00%\n",
      "Calculating R_i for task with classes: [0, 95, 57, 93, 53, 89, 25, 71, 84, 77]\n",
      "Linear evaluation accuracy on 10 classes: 37.70%\n",
      "Random network accuracy on task: 37.70%\n",
      "\n",
      "===== Training Task 9/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.4107, CaSSle Loss: 0.6717, Total Loss: 1.9480\n",
      "Epoch 2/200 - SSL Loss: 0.9645, CaSSle Loss: 0.5926, Total Loss: 1.4386\n",
      "Epoch 3/200 - SSL Loss: 0.8356, CaSSle Loss: 0.5507, Total Loss: 1.2761\n",
      "Epoch 4/200 - SSL Loss: 0.7332, CaSSle Loss: 0.5270, Total Loss: 1.1548\n",
      "Epoch 5/200 - SSL Loss: 0.6591, CaSSle Loss: 0.5125, Total Loss: 1.0691\n",
      "Epoch 6/200 - SSL Loss: 0.5922, CaSSle Loss: 0.5033, Total Loss: 0.9949\n",
      "Epoch 7/200 - SSL Loss: 0.5321, CaSSle Loss: 0.4957, Total Loss: 0.9286\n",
      "Epoch 8/200 - SSL Loss: 0.4839, CaSSle Loss: 0.4905, Total Loss: 0.8764\n",
      "Epoch 9/200 - SSL Loss: 0.4351, CaSSle Loss: 0.4867, Total Loss: 0.8245\n",
      "Epoch 10/200 - SSL Loss: 0.3883, CaSSle Loss: 0.4830, Total Loss: 0.7747\n",
      "Epoch 11/200 - SSL Loss: 0.3525, CaSSle Loss: 0.4804, Total Loss: 0.7368\n",
      "Epoch 12/200 - SSL Loss: 0.3232, CaSSle Loss: 0.4785, Total Loss: 0.7060\n",
      "Epoch 13/200 - SSL Loss: 0.3005, CaSSle Loss: 0.4770, Total Loss: 0.6820\n",
      "Epoch 14/200 - SSL Loss: 0.2659, CaSSle Loss: 0.4760, Total Loss: 0.6467\n",
      "Epoch 15/200 - SSL Loss: 0.2383, CaSSle Loss: 0.4750, Total Loss: 0.6184\n",
      "Epoch 16/200 - SSL Loss: 0.2209, CaSSle Loss: 0.4744, Total Loss: 0.6005\n",
      "Epoch 17/200 - SSL Loss: 0.2066, CaSSle Loss: 0.4733, Total Loss: 0.5853\n",
      "Epoch 18/200 - SSL Loss: 0.1920, CaSSle Loss: 0.4733, Total Loss: 0.5706\n",
      "Epoch 19/200 - SSL Loss: 0.1725, CaSSle Loss: 0.4725, Total Loss: 0.5505\n",
      "Epoch 20/200 - SSL Loss: 0.1648, CaSSle Loss: 0.4721, Total Loss: 0.5425\n",
      "Epoch 21/200 - SSL Loss: 0.1545, CaSSle Loss: 0.4716, Total Loss: 0.5318\n",
      "Epoch 22/200 - SSL Loss: 0.1440, CaSSle Loss: 0.4711, Total Loss: 0.5209\n",
      "Epoch 23/200 - SSL Loss: 0.1365, CaSSle Loss: 0.4714, Total Loss: 0.5136\n",
      "Epoch 24/200 - SSL Loss: 0.1368, CaSSle Loss: 0.4714, Total Loss: 0.5139\n",
      "Epoch 25/200 - SSL Loss: 0.1308, CaSSle Loss: 0.4711, Total Loss: 0.5077\n",
      "Epoch 26/200 - SSL Loss: 0.1222, CaSSle Loss: 0.4709, Total Loss: 0.4990\n",
      "Epoch 27/200 - SSL Loss: 0.1133, CaSSle Loss: 0.4706, Total Loss: 0.4898\n",
      "Epoch 28/200 - SSL Loss: 0.1055, CaSSle Loss: 0.4706, Total Loss: 0.4819\n",
      "Epoch 29/200 - SSL Loss: 0.1073, CaSSle Loss: 0.4705, Total Loss: 0.4837\n",
      "Epoch 30/200 - SSL Loss: 0.1017, CaSSle Loss: 0.4705, Total Loss: 0.4781\n",
      "Epoch 31/200 - SSL Loss: 0.1010, CaSSle Loss: 0.4702, Total Loss: 0.4772\n",
      "Epoch 32/200 - SSL Loss: 0.0940, CaSSle Loss: 0.4700, Total Loss: 0.4700\n",
      "Epoch 33/200 - SSL Loss: 0.0925, CaSSle Loss: 0.4701, Total Loss: 0.4686\n",
      "Epoch 34/200 - SSL Loss: 0.0906, CaSSle Loss: 0.4700, Total Loss: 0.4666\n",
      "Epoch 35/200 - SSL Loss: 0.0872, CaSSle Loss: 0.4699, Total Loss: 0.4631\n",
      "Epoch 36/200 - SSL Loss: 0.0841, CaSSle Loss: 0.4700, Total Loss: 0.4601\n",
      "Epoch 37/200 - SSL Loss: 0.0878, CaSSle Loss: 0.4701, Total Loss: 0.4639\n",
      "Epoch 38/200 - SSL Loss: 0.0841, CaSSle Loss: 0.4697, Total Loss: 0.4599\n",
      "Epoch 39/200 - SSL Loss: 0.0858, CaSSle Loss: 0.4698, Total Loss: 0.4616\n",
      "Epoch 40/200 - SSL Loss: 0.0772, CaSSle Loss: 0.4694, Total Loss: 0.4527\n",
      "Epoch 41/200 - SSL Loss: 0.0736, CaSSle Loss: 0.4692, Total Loss: 0.4490\n",
      "Epoch 42/200 - SSL Loss: 0.0730, CaSSle Loss: 0.4693, Total Loss: 0.4484\n",
      "Epoch 43/200 - SSL Loss: 0.0629, CaSSle Loss: 0.4691, Total Loss: 0.4382\n",
      "Epoch 44/200 - SSL Loss: 0.0676, CaSSle Loss: 0.4689, Total Loss: 0.4427\n",
      "Epoch 45/200 - SSL Loss: 0.0718, CaSSle Loss: 0.4691, Total Loss: 0.4470\n",
      "Epoch 46/200 - SSL Loss: 0.0718, CaSSle Loss: 0.4689, Total Loss: 0.4469\n",
      "Epoch 47/200 - SSL Loss: 0.0711, CaSSle Loss: 0.4694, Total Loss: 0.4466\n",
      "Epoch 48/200 - SSL Loss: 0.0645, CaSSle Loss: 0.4692, Total Loss: 0.4398\n",
      "Epoch 49/200 - SSL Loss: 0.0617, CaSSle Loss: 0.4691, Total Loss: 0.4369\n",
      "Epoch 50/200 - SSL Loss: 0.0610, CaSSle Loss: 0.4694, Total Loss: 0.4365\n",
      "Epoch 51/200 - SSL Loss: 0.0622, CaSSle Loss: 0.4692, Total Loss: 0.4375\n",
      "Epoch 52/200 - SSL Loss: 0.0599, CaSSle Loss: 0.4688, Total Loss: 0.4350\n",
      "Epoch 53/200 - SSL Loss: 0.0644, CaSSle Loss: 0.4689, Total Loss: 0.4395\n",
      "Epoch 54/200 - SSL Loss: 0.0635, CaSSle Loss: 0.4691, Total Loss: 0.4388\n",
      "Epoch 55/200 - SSL Loss: 0.0581, CaSSle Loss: 0.4690, Total Loss: 0.4333\n",
      "Epoch 56/200 - SSL Loss: 0.0609, CaSSle Loss: 0.4688, Total Loss: 0.4360\n",
      "Epoch 57/200 - SSL Loss: 0.0638, CaSSle Loss: 0.4690, Total Loss: 0.4390\n",
      "Epoch 58/200 - SSL Loss: 0.0598, CaSSle Loss: 0.4687, Total Loss: 0.4347\n",
      "Epoch 59/200 - SSL Loss: 0.0541, CaSSle Loss: 0.4690, Total Loss: 0.4293\n",
      "Epoch 60/200 - SSL Loss: 0.0512, CaSSle Loss: 0.4685, Total Loss: 0.4260\n",
      "Epoch 61/200 - SSL Loss: 0.0523, CaSSle Loss: 0.4686, Total Loss: 0.4272\n",
      "Epoch 62/200 - SSL Loss: 0.0531, CaSSle Loss: 0.4686, Total Loss: 0.4280\n",
      "Epoch 63/200 - SSL Loss: 0.0556, CaSSle Loss: 0.4685, Total Loss: 0.4305\n",
      "Epoch 64/200 - SSL Loss: 0.0515, CaSSle Loss: 0.4687, Total Loss: 0.4265\n",
      "Epoch 65/200 - SSL Loss: 0.0454, CaSSle Loss: 0.4682, Total Loss: 0.4200\n",
      "Epoch 66/200 - SSL Loss: 0.0605, CaSSle Loss: 0.4688, Total Loss: 0.4356\n",
      "Epoch 67/200 - SSL Loss: 0.0516, CaSSle Loss: 0.4685, Total Loss: 0.4264\n",
      "Epoch 68/200 - SSL Loss: 0.0561, CaSSle Loss: 0.4689, Total Loss: 0.4313\n",
      "Epoch 69/200 - SSL Loss: 0.0476, CaSSle Loss: 0.4688, Total Loss: 0.4227\n",
      "Epoch 70/200 - SSL Loss: 0.0459, CaSSle Loss: 0.4683, Total Loss: 0.4205\n",
      "Epoch 71/200 - SSL Loss: 0.0465, CaSSle Loss: 0.4681, Total Loss: 0.4210\n",
      "Epoch 72/200 - SSL Loss: 0.0536, CaSSle Loss: 0.4688, Total Loss: 0.4286\n",
      "Epoch 73/200 - SSL Loss: 0.0495, CaSSle Loss: 0.4689, Total Loss: 0.4246\n",
      "Epoch 74/200 - SSL Loss: 0.0525, CaSSle Loss: 0.4684, Total Loss: 0.4272\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 9 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 73.00%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 75.80%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 79.10%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 73.30%\n",
      "  Evaluating on classes from Task 5: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 78.60%\n",
      "  Evaluating on classes from Task 6: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Linear evaluation accuracy on 10 classes: 76.70%\n",
      "  Evaluating on classes from Task 7: [24, 5, 6, 67, 82, 19, 79, 43, 90, 20]\n",
      "Linear evaluation accuracy on 10 classes: 79.70%\n",
      "  Evaluating on classes from Task 8: [0, 95, 57, 93, 53, 89, 25, 71, 84, 77]\n",
      "Linear evaluation accuracy on 10 classes: 77.80%\n",
      "  Evaluating on classes from Task 9: [64, 29, 27, 88, 97, 4, 54, 75, 11, 69]\n",
      "Linear evaluation accuracy on 10 classes: 75.10%\n",
      "Calculating R_i for task with classes: [64, 29, 27, 88, 97, 4, 54, 75, 11, 69]\n",
      "Linear evaluation accuracy on 10 classes: 30.20%\n",
      "Random network accuracy on task: 30.20%\n",
      "\n",
      "===== Training Task 10/10 =====\n",
      "Frozen encoder (f_t-1) loaded and parameters frozen: True\n",
      "Distilling from frozen teacher encoder (f_t-1): True\n",
      "Epoch 1/200 - SSL Loss: 1.1752, CaSSle Loss: 0.6776, Total Loss: 1.7173\n",
      "Epoch 2/200 - SSL Loss: 0.7808, CaSSle Loss: 0.5825, Total Loss: 1.2468\n",
      "Epoch 3/200 - SSL Loss: 0.6522, CaSSle Loss: 0.5400, Total Loss: 1.0842\n",
      "Epoch 4/200 - SSL Loss: 0.5692, CaSSle Loss: 0.5177, Total Loss: 0.9834\n",
      "Epoch 5/200 - SSL Loss: 0.5022, CaSSle Loss: 0.5033, Total Loss: 0.9049\n",
      "Epoch 6/200 - SSL Loss: 0.4457, CaSSle Loss: 0.4930, Total Loss: 0.8401\n",
      "Epoch 7/200 - SSL Loss: 0.3924, CaSSle Loss: 0.4865, Total Loss: 0.7816\n",
      "Epoch 8/200 - SSL Loss: 0.3567, CaSSle Loss: 0.4814, Total Loss: 0.7418\n",
      "Epoch 9/200 - SSL Loss: 0.3247, CaSSle Loss: 0.4772, Total Loss: 0.7065\n",
      "Epoch 10/200 - SSL Loss: 0.2886, CaSSle Loss: 0.4737, Total Loss: 0.6676\n",
      "Epoch 11/200 - SSL Loss: 0.2622, CaSSle Loss: 0.4708, Total Loss: 0.6388\n",
      "Epoch 12/200 - SSL Loss: 0.2318, CaSSle Loss: 0.4689, Total Loss: 0.6069\n",
      "Epoch 13/200 - SSL Loss: 0.2094, CaSSle Loss: 0.4665, Total Loss: 0.5827\n",
      "Epoch 14/200 - SSL Loss: 0.2003, CaSSle Loss: 0.4654, Total Loss: 0.5726\n",
      "Epoch 15/200 - SSL Loss: 0.1807, CaSSle Loss: 0.4649, Total Loss: 0.5527\n",
      "Epoch 16/200 - SSL Loss: 0.1768, CaSSle Loss: 0.4641, Total Loss: 0.5481\n",
      "Epoch 17/200 - SSL Loss: 0.1502, CaSSle Loss: 0.4630, Total Loss: 0.5206\n",
      "Epoch 18/200 - SSL Loss: 0.1485, CaSSle Loss: 0.4624, Total Loss: 0.5184\n",
      "Epoch 19/200 - SSL Loss: 0.1391, CaSSle Loss: 0.4622, Total Loss: 0.5089\n",
      "Epoch 20/200 - SSL Loss: 0.1240, CaSSle Loss: 0.4617, Total Loss: 0.4934\n",
      "Epoch 21/200 - SSL Loss: 0.1281, CaSSle Loss: 0.4610, Total Loss: 0.4969\n",
      "Epoch 22/200 - SSL Loss: 0.1125, CaSSle Loss: 0.4603, Total Loss: 0.4807\n",
      "Epoch 23/200 - SSL Loss: 0.1083, CaSSle Loss: 0.4599, Total Loss: 0.4762\n",
      "Epoch 24/200 - SSL Loss: 0.0999, CaSSle Loss: 0.4597, Total Loss: 0.4677\n",
      "Epoch 25/200 - SSL Loss: 0.0970, CaSSle Loss: 0.4602, Total Loss: 0.4652\n",
      "Epoch 26/200 - SSL Loss: 0.0976, CaSSle Loss: 0.4599, Total Loss: 0.4655\n",
      "Epoch 27/200 - SSL Loss: 0.0904, CaSSle Loss: 0.4595, Total Loss: 0.4580\n",
      "Epoch 28/200 - SSL Loss: 0.0935, CaSSle Loss: 0.4592, Total Loss: 0.4608\n",
      "Epoch 29/200 - SSL Loss: 0.0899, CaSSle Loss: 0.4592, Total Loss: 0.4572\n",
      "Epoch 30/200 - SSL Loss: 0.0851, CaSSle Loss: 0.4590, Total Loss: 0.4522\n",
      "Epoch 31/200 - SSL Loss: 0.0794, CaSSle Loss: 0.4587, Total Loss: 0.4463\n",
      "Epoch 32/200 - SSL Loss: 0.0768, CaSSle Loss: 0.4583, Total Loss: 0.4434\n",
      "Epoch 33/200 - SSL Loss: 0.0771, CaSSle Loss: 0.4583, Total Loss: 0.4437\n",
      "Epoch 34/200 - SSL Loss: 0.0732, CaSSle Loss: 0.4583, Total Loss: 0.4398\n",
      "Epoch 35/200 - SSL Loss: 0.0718, CaSSle Loss: 0.4581, Total Loss: 0.4382\n",
      "Epoch 36/200 - SSL Loss: 0.0691, CaSSle Loss: 0.4580, Total Loss: 0.4355\n",
      "Epoch 37/200 - SSL Loss: 0.0766, CaSSle Loss: 0.4581, Total Loss: 0.4431\n",
      "Epoch 38/200 - SSL Loss: 0.0703, CaSSle Loss: 0.4581, Total Loss: 0.4368\n",
      "Epoch 39/200 - SSL Loss: 0.0635, CaSSle Loss: 0.4578, Total Loss: 0.4298\n",
      "Epoch 40/200 - SSL Loss: 0.0677, CaSSle Loss: 0.4583, Total Loss: 0.4344\n",
      "Epoch 41/200 - SSL Loss: 0.0619, CaSSle Loss: 0.4576, Total Loss: 0.4279\n",
      "Epoch 42/200 - SSL Loss: 0.0639, CaSSle Loss: 0.4575, Total Loss: 0.4298\n",
      "Epoch 43/200 - SSL Loss: 0.0567, CaSSle Loss: 0.4573, Total Loss: 0.4225\n",
      "Epoch 44/200 - SSL Loss: 0.0576, CaSSle Loss: 0.4571, Total Loss: 0.4232\n",
      "Epoch 45/200 - SSL Loss: 0.0580, CaSSle Loss: 0.4571, Total Loss: 0.4237\n",
      "Epoch 46/200 - SSL Loss: 0.0638, CaSSle Loss: 0.4573, Total Loss: 0.4297\n",
      "Epoch 47/200 - SSL Loss: 0.0529, CaSSle Loss: 0.4571, Total Loss: 0.4186\n",
      "Epoch 48/200 - SSL Loss: 0.0514, CaSSle Loss: 0.4567, Total Loss: 0.4168\n",
      "Epoch 49/200 - SSL Loss: 0.0480, CaSSle Loss: 0.4566, Total Loss: 0.4133\n",
      "Epoch 50/200 - SSL Loss: 0.0462, CaSSle Loss: 0.4566, Total Loss: 0.4115\n",
      "Epoch 51/200 - SSL Loss: 0.0551, CaSSle Loss: 0.4569, Total Loss: 0.4206\n",
      "Epoch 52/200 - SSL Loss: 0.0482, CaSSle Loss: 0.4567, Total Loss: 0.4136\n",
      "Epoch 53/200 - SSL Loss: 0.0486, CaSSle Loss: 0.4570, Total Loss: 0.4142\n",
      "Epoch 54/200 - SSL Loss: 0.0521, CaSSle Loss: 0.4573, Total Loss: 0.4180\n",
      "Epoch 55/200 - SSL Loss: 0.0498, CaSSle Loss: 0.4570, Total Loss: 0.4154\n",
      "Epoch 56/200 - SSL Loss: 0.0563, CaSSle Loss: 0.4575, Total Loss: 0.4222\n",
      "Epoch 57/200 - SSL Loss: 0.0543, CaSSle Loss: 0.4571, Total Loss: 0.4200\n",
      "Epoch 58/200 - SSL Loss: 0.0425, CaSSle Loss: 0.4565, Total Loss: 0.4078\n",
      "Epoch 59/200 - SSL Loss: 0.0445, CaSSle Loss: 0.4561, Total Loss: 0.4094\n",
      "Epoch 60/200 - SSL Loss: 0.0437, CaSSle Loss: 0.4563, Total Loss: 0.4087\n",
      "Epoch 61/200 - SSL Loss: 0.0433, CaSSle Loss: 0.4561, Total Loss: 0.4082\n",
      "Epoch 62/200 - SSL Loss: 0.0493, CaSSle Loss: 0.4567, Total Loss: 0.4146\n",
      "Epoch 63/200 - SSL Loss: 0.0440, CaSSle Loss: 0.4565, Total Loss: 0.4092\n",
      "Epoch 64/200 - SSL Loss: 0.0475, CaSSle Loss: 0.4570, Total Loss: 0.4131\n",
      "Epoch 65/200 - SSL Loss: 0.0425, CaSSle Loss: 0.4561, Total Loss: 0.4073\n",
      "Epoch 66/200 - SSL Loss: 0.0433, CaSSle Loss: 0.4562, Total Loss: 0.4083\n",
      "Epoch 67/200 - SSL Loss: 0.0412, CaSSle Loss: 0.4567, Total Loss: 0.4065\n",
      "Epoch 68/200 - SSL Loss: 0.0427, CaSSle Loss: 0.4557, Total Loss: 0.4073\n",
      "Epoch 69/200 - SSL Loss: 0.0442, CaSSle Loss: 0.4561, Total Loss: 0.4091\n",
      "Epoch 70/200 - SSL Loss: 0.0372, CaSSle Loss: 0.4561, Total Loss: 0.4020\n",
      "Epoch 71/200 - SSL Loss: 0.0452, CaSSle Loss: 0.4559, Total Loss: 0.4099\n",
      "Epoch 72/200 - SSL Loss: 0.0425, CaSSle Loss: 0.4560, Total Loss: 0.4072\n",
      "Epoch 73/200 - SSL Loss: 0.0391, CaSSle Loss: 0.4560, Total Loss: 0.4038\n",
      "Epoch 74/200 - SSL Loss: 0.0414, CaSSle Loss: 0.4565, Total Loss: 0.4066\n",
      "Epoch 75/200 - SSL Loss: 0.0510, CaSSle Loss: 0.4565, Total Loss: 0.4161\n",
      "Epoch 76/200 - SSL Loss: 0.0454, CaSSle Loss: 0.4566, Total Loss: 0.4107\n",
      "Epoch 77/200 - SSL Loss: 0.0348, CaSSle Loss: 0.4556, Total Loss: 0.3993\n",
      "Epoch 78/200 - SSL Loss: 0.0360, CaSSle Loss: 0.4556, Total Loss: 0.4005\n",
      "Epoch 79/200 - SSL Loss: 0.0415, CaSSle Loss: 0.4558, Total Loss: 0.4061\n",
      "Epoch 80/200 - SSL Loss: 0.0370, CaSSle Loss: 0.4558, Total Loss: 0.4016\n",
      "Epoch 81/200 - SSL Loss: 0.0342, CaSSle Loss: 0.4559, Total Loss: 0.3989\n",
      "Epoch 82/200 - SSL Loss: 0.0316, CaSSle Loss: 0.4553, Total Loss: 0.3959\n",
      "Epoch 83/200 - SSL Loss: 0.0302, CaSSle Loss: 0.4555, Total Loss: 0.3947\n",
      "Epoch 84/200 - SSL Loss: 0.0368, CaSSle Loss: 0.4556, Total Loss: 0.4013\n",
      "Epoch 85/200 - SSL Loss: 0.0351, CaSSle Loss: 0.4558, Total Loss: 0.3998\n",
      "Epoch 86/200 - SSL Loss: 0.0372, CaSSle Loss: 0.4555, Total Loss: 0.4016\n",
      "Epoch 87/200 - SSL Loss: 0.0370, CaSSle Loss: 0.4556, Total Loss: 0.4015\n",
      "Epoch 88/200 - SSL Loss: 0.0397, CaSSle Loss: 0.4560, Total Loss: 0.4045\n",
      "Epoch 89/200 - SSL Loss: 0.0321, CaSSle Loss: 0.4555, Total Loss: 0.3965\n",
      "Epoch 90/200 - SSL Loss: 0.0304, CaSSle Loss: 0.4552, Total Loss: 0.3945\n",
      "Epoch 91/200 - SSL Loss: 0.0379, CaSSle Loss: 0.4559, Total Loss: 0.4026\n",
      "Epoch 92/200 - SSL Loss: 0.0367, CaSSle Loss: 0.4559, Total Loss: 0.4015\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Evaluating after Task 10 ---\n",
      "  Evaluating on classes from Task 1: [42, 41, 91, 9, 65, 50, 1, 70, 15, 78]\n",
      "Linear evaluation accuracy on 10 classes: 75.20%\n",
      "  Evaluating on classes from Task 2: [73, 10, 55, 56, 72, 45, 48, 92, 76, 37]\n",
      "Linear evaluation accuracy on 10 classes: 76.10%\n",
      "  Evaluating on classes from Task 3: [30, 21, 32, 96, 80, 49, 83, 26, 87, 33]\n",
      "Linear evaluation accuracy on 10 classes: 79.60%\n",
      "  Evaluating on classes from Task 4: [8, 47, 59, 63, 74, 44, 98, 52, 85, 12]\n",
      "Linear evaluation accuracy on 10 classes: 73.80%\n",
      "  Evaluating on classes from Task 5: [36, 23, 39, 40, 18, 66, 61, 60, 7, 34]\n",
      "Linear evaluation accuracy on 10 classes: 79.90%\n",
      "  Evaluating on classes from Task 6: [99, 46, 2, 51, 16, 38, 58, 68, 22, 62]\n",
      "Linear evaluation accuracy on 10 classes: 78.50%\n",
      "  Evaluating on classes from Task 7: [24, 5, 6, 67, 82, 19, 79, 43, 90, 20]\n",
      "Linear evaluation accuracy on 10 classes: 80.60%\n",
      "  Evaluating on classes from Task 8: [0, 95, 57, 93, 53, 89, 25, 71, 84, 77]\n",
      "Linear evaluation accuracy on 10 classes: 79.00%\n",
      "  Evaluating on classes from Task 9: [64, 29, 27, 88, 97, 4, 54, 75, 11, 69]\n",
      "Linear evaluation accuracy on 10 classes: 75.00%\n",
      "  Evaluating on classes from Task 10: [86, 13, 17, 28, 31, 35, 94, 3, 14, 81]\n",
      "Linear evaluation accuracy on 10 classes: 80.50%\n",
      "Calculating R_i for task with classes: [86, 13, 17, 28, 31, 35, 94, 3, 14, 81]\n",
      "Linear evaluation accuracy on 10 classes: 35.20%\n",
      "Random network accuracy on task: 35.20%\n",
      "\n",
      "Final Average Accuracy (A): 77.82%\n",
      "Final Forgetting (F): 0.78%\n",
      "Final Backward Transfer (BT): 0.02%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Evaluation Function\n",
    "def evaluate_model(feature_extractor: torch.nn.Module,\n",
    "                   all_seen_classes: List[int],\n",
    "                   cifar100_train_full: datasets.CIFAR100,\n",
    "                   cifar100_test_full: datasets.CIFAR100,\n",
    "                   base_transform, # Use the same base transform as RotNet\n",
    "                   batch_size: int = 128,\n",
    "                   linear_eval_epochs: int = 10,\n",
    "                   device: torch.device = torch.device(\"cuda\")):\n",
    "\n",
    "    # freeze feature extractor\n",
    "    feature_extractor.eval()\n",
    "    for param in feature_extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Data for Linear Classifier Training\n",
    "    class LinearEvalDataset(Dataset):\n",
    "        def __init__(self, original_dataset, class_list, transform):\n",
    "            self.data = []\n",
    "            self.targets = []\n",
    "            self.transform = transform\n",
    "\n",
    "            for i in range(len(original_dataset)):\n",
    "                img, label = original_dataset[i]\n",
    "                if label in class_list:\n",
    "                    if isinstance(img, np.ndarray):\n",
    "                        img = Image.fromarray(img)\n",
    "                    self.data.append(img)\n",
    "                    self.targets.append(label)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img = self.data[idx]\n",
    "            label = self.targets[idx]\n",
    "            img = self.transform(img) # Apply base_transform for feature extraction\n",
    "            return img, label\n",
    "\n",
    "    train_linear_dataset = LinearEvalDataset(cifar100_train_full, all_seen_classes, base_transform)\n",
    "    train_linear_loader = DataLoader(train_linear_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                     num_workers=os.cpu_count() // 2 if os.cpu_count() else 0, pin_memory=True)\n",
    "\n",
    "\n",
    "    # Feature extractor output dim\n",
    "    dummy_input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE).to(device)\n",
    "    with torch.no_grad():\n",
    "        features_dim = feature_extractor(dummy_input).view(dummy_input.size(0), -1).shape[1]\n",
    "\n",
    "    num_output_classes = len(all_seen_classes)\n",
    "    linear_classifier = nn.Linear(features_dim, num_output_classes).to(device)\n",
    "\n",
    "    # Map CIFAR-100 original labels to a contiguous range for the classifier's output\n",
    "    label_to_contiguous_map = {label: i for i, label in enumerate(sorted(all_seen_classes))}\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(linear_classifier.parameters(), lr=0.001)\n",
    "\n",
    "    # 3. Train Linear Classifier\n",
    "    linear_classifier.train()\n",
    "    for epoch in range(linear_eval_epochs):\n",
    "        for img_batch, label_batch in train_linear_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            label_batch = torch.tensor([label_to_contiguous_map[l.item()] for l in label_batch]).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad(): # Ensure feature extractor remains frozen\n",
    "                features = feature_extractor(img_batch).view(img_batch.size(0), -1)\n",
    "\n",
    "            outputs = linear_classifier(features)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 4. Evaluate Linear Classifier on Test Data\n",
    "    linear_classifier.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    test_linear_dataset = LinearEvalDataset(cifar100_test_full, all_seen_classes, base_transform)\n",
    "    test_linear_loader = DataLoader(test_linear_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                   num_workers=os.cpu_count() // 2 if os.cpu_count() else 0, pin_memory=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_batch, label_batch in test_linear_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            label_batch = torch.tensor([label_to_contiguous_map[l.item()] for l in label_batch]).to(device)\n",
    "\n",
    "            features = feature_extractor(img_batch).view(img_batch.size(0), -1)\n",
    "            outputs = linear_classifier(features)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += label_batch.size(0)\n",
    "            total_correct += (predicted == label_batch).sum().item()\n",
    "\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f\"Linear evaluation accuracy on {len(all_seen_classes)} classes: {accuracy:.2f}%\")\n",
    "\n",
    "    # Restore feature extractor to training mode if it's going to be used for more training\n",
    "    for param in feature_extractor.parameters():\n",
    "        param.requires_grad = True # Re-enable gradients for next task's training\n",
    "    feature_extractor.train() # Set backbone back to train mode\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Baseline for Forward Transfer (R_i) a randomly initialized linear classifier\n",
    "def get_random_accuracy(num_classes_in_task: int,\n",
    "                        cifar100_train_full: datasets.CIFAR100,\n",
    "                        cifar100_test_full: datasets.CIFAR100,\n",
    "                        base_transform,\n",
    "                        target_class_list: List[int],\n",
    "                        batch_size: int = 128,\n",
    "                        linear_eval_epochs: int = 10,\n",
    "                        device: torch.device = torch.device(\"cpu\")):\n",
    "\n",
    "    print(f\"Calculating R_i for task with classes: {target_class_list}\")\n",
    "    # Create a randomly initialized ResNet18 backbone\n",
    "    random_resnet18_backbone = models.resnet18(weights=None) # No pretrained weights\n",
    "    random_resnet18_backbone.fc = nn.Identity() # Remove the default classification head\n",
    "    random_resnet18_backbone.to(device)\n",
    "\n",
    "\n",
    "    # Then evaluate using the same function\n",
    "    random_acc = evaluate_model(random_resnet18_backbone,\n",
    "                                 target_class_list,\n",
    "                                 cifar100_train_full,\n",
    "                                 cifar100_test_full,\n",
    "                                 base_transform,\n",
    "                                 batch_size,\n",
    "                                 linear_eval_epochs,\n",
    "                                 device)\n",
    "    print(f\"Random network accuracy on task: {random_acc:.2f}%\")\n",
    "    return random_acc\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"Random seed set to {seed}\")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "# Transforms\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.7, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "cifar100_train_full = datasets.CIFAR100(root='./data', train=True, download=True)\n",
    "cifar100_test_full = datasets.CIFAR100(root='./data', train=False, download=True)\n",
    "\n",
    "# Task Split\n",
    "all_classes_shuffled = list(range(NUM_TOTAL_CLASSES))\n",
    "random.shuffle(all_classes_shuffled)\n",
    "\n",
    "task_class_splits = [all_classes_shuffled[i:i + NUM_CLASSES_PER_TASK] for i in range(0, NUM_TOTAL_CLASSES, NUM_CLASSES_PER_TASK)]\n",
    "\n",
    "task_datasets = []\n",
    "for i, class_list in enumerate(task_class_splits):\n",
    "    print(f\"Task {i+1} includes classes: {class_list}\")\n",
    "    task_dataset = RotNetCifar100TaskDataset(cifar100_train_full, class_list, base_transform)\n",
    "    task_datasets.append(task_dataset)\n",
    "\n",
    "# Init Model\n",
    "resnet18_backbone = models.resnet18(weights=None)\n",
    "resnet18_backbone.fc = nn.Identity()\n",
    "\n",
    "base_ssl_model_instance = RotNetModel( num_rot_classes=NUM_ROT_CLASSES).to(DEVICE)\n",
    "prev_encoder_state_dict = None\n",
    "\n",
    "# Training Loop\n",
    "all_task_accuracies = []\n",
    "random_accuracies_Ri = {}\n",
    "\n",
    "for task_id, current_task_dataset in enumerate(task_datasets):\n",
    "    print(f\"\\n===== Training Task {task_id + 1}/{len(task_datasets)} =====\")\n",
    "\n",
    "    current_task_loader = DataLoader(\n",
    "        current_task_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=os.cpu_count() // 2 if os.cpu_count() else 0, pin_memory=True\n",
    "    )\n",
    "\n",
    "    trainer = CaSSleTrainer(\n",
    "        base_ssl_model=base_ssl_model_instance,\n",
    "        ca_predictor_hidden_dim=256,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        lambda_cassle=LAMBDA_CASSLE,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    #Save previouse encoder\n",
    "    if prev_encoder_state_dict:\n",
    "        trainer.set_previous_frozen_encoder(prev_encoder_state_dict)\n",
    "    #Train encoder on current task and save its state_dict\n",
    "    prev_encoder_state_dict = trainer.train_task(current_task_loader, NUM_EPOCHS_PER_TASK)\n",
    "\n",
    "    print(f\"\\n--- Evaluating after Task {task_id + 1} ---\")\n",
    "    current_seen_classes = sorted(set().union(*task_class_splits[:task_id + 1]))\n",
    "    accuracies_after_this_task = []\n",
    "\n",
    "    #Evaluate model for each task seen so far\n",
    "    for eval_task_idx in range(task_id + 1):\n",
    "        eval_task_classes = task_class_splits[eval_task_idx]\n",
    "        print(f\"  Evaluating on classes from Task {eval_task_idx+1}: {eval_task_classes}\")\n",
    "\n",
    "        acc_jk = evaluate_model(\n",
    "            base_ssl_model_instance.backbone,\n",
    "            eval_task_classes,\n",
    "            cifar100_train_full,\n",
    "            cifar100_test_full,\n",
    "            base_transform,\n",
    "            LINEAR_EVAL_BATCH_SIZE,\n",
    "            LINEAR_EVAL_EPOCHS,\n",
    "            DEVICE\n",
    "        )\n",
    "        accuracies_after_this_task.append(acc_jk)\n",
    "\n",
    "        #calculate random baseline accuracy fo reach task\n",
    "        if eval_task_idx not in random_accuracies_Ri:\n",
    "            random_accuracies_Ri[eval_task_idx] = get_random_accuracy(\n",
    "                NUM_CLASSES_PER_TASK,\n",
    "                cifar100_train_full,\n",
    "                cifar100_test_full,\n",
    "                base_transform,\n",
    "                eval_task_classes,\n",
    "                LINEAR_EVAL_BATCH_SIZE,\n",
    "                LINEAR_EVAL_EPOCHS,\n",
    "                DEVICE\n",
    "            )\n",
    "\n",
    "    all_task_accuracies.append(accuracies_after_this_task)\n",
    "\n",
    "\n",
    "T = len(task_datasets)\n",
    "\n",
    "# Average Accuracy\n",
    "final_accuracies_row = all_task_accuracies[T-1]\n",
    "avg_accuracy = sum(final_accuracies_row) / T\n",
    "print(f\"\\nFinal Average Accuracy (A): {avg_accuracy:.2f}%\")\n",
    "\n",
    "# Forgetting\n",
    "forgetting = 0\n",
    "if T > 1:\n",
    "    for i in range(T - 1):\n",
    "        max_acc = max(all_task_accuracies[t][i] for t in range(T) if i < len(all_task_accuracies[t]))\n",
    "        final_acc = all_task_accuracies[T-1][i]\n",
    "        forgetting += (max_acc - final_acc)\n",
    "    forgetting /= (T - 1)\n",
    "print(f\"Final Forgetting (F): {forgetting:.2f}%\")\n",
    "\n",
    "# Backward Transfer (BT)\n",
    "backward_transfer = 0\n",
    "count = 0\n",
    "\n",
    "if T > 1:\n",
    "    for new_task in range(1, T):\n",
    "        for old_task in range(new_task):\n",
    "            if old_task < len(all_task_accuracies[new_task - 1]) and old_task < len(all_task_accuracies[new_task]):\n",
    "                acc_before = all_task_accuracies[new_task - 1][old_task]\n",
    "                acc_after = all_task_accuracies[new_task][old_task]\n",
    "                backward_transfer += (acc_after - acc_before)\n",
    "                count += 1\n",
    "            else:\n",
    "                print(f\"Skipping BT for old_task {old_task+1}, new_task {new_task+1}: missing data\")\n",
    "\n",
    "    backward_transfer /= count if count > 0 else 1\n",
    "else:\n",
    "    backward_transfer = 0\n",
    "\n",
    "print(f\"Final Backward Transfer (BT): {backward_transfer:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
